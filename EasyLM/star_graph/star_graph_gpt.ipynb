{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "import time\n",
    "from jax_smi import initialise_tracking\n",
    "initialise_tracking()\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asetlur/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainConfig(gpt2_model_type='gpt2-large', seed=555, out_dir='out', shuffle_buffer_size=128, eval_interval=500, eval_steps=16, eval_only=False, keep_checkpoints=3, batch_size=64, train_steps=6250, weight_decay=0.01, grad_clip=1.0, gradient_accumulation_steps=1, betas=(0.9, 0.95), learning_rate=StaticLRConfig(init_value=1e-05), wandb=WandbConfig(entity='ars22', project='star_graph', name='gpt2', mode='online', notes=''), model=GPTConfig(block_size=1024, vocab_size=50257, num_layers=12, num_heads=12, num_embeds=768, dropout_rate=0.1, use_bias=True, dtype=None), remat=False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import dataclass, field, asdict\n",
    "from typing import Tuple, Optional, Union\n",
    "from EasyLM.models.gpt2.gpt2_model import GPT, GPTConfig, get_pretrained_params\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class WandbConfig:\n",
    "    \"\"\"\n",
    "    wandb logging configuration\n",
    "    \"\"\"\n",
    "    entity: str = 'ars22'\n",
    "    \"\"\"username or team name where you're sending runs\"\"\"\n",
    "    project: str = 'star_graph'\n",
    "    \"\"\"project name\"\"\"\n",
    "    name: str = 'gpt2'\n",
    "    \"\"\"experiment name\"\"\"\n",
    "    mode: str = 'online'\n",
    "    \"\"\"'offline', 'online', or 'disabled'\"\"\"\n",
    "    notes: str = ''\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class CosineDecayScheduleConfig:\n",
    "    init_value: float = 0.0\n",
    "    peak_value: float = 2.5e-4\n",
    "    warmup_steps: int = 2000\n",
    "    decay_steps: int = 150000\n",
    "    end_value: float = 1e-5\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class StaticLRConfig:\n",
    "    init_value: float = 1e-5\n",
    "\n",
    "\n",
    "@dataclass(frozen=False)\n",
    "class TrainConfig:\n",
    "    gpt2_model_type: str = 'gpt2-large' # gpt2 model type\n",
    "    seed: int = 555\n",
    "    out_dir: str = 'out'                        # output directory for checkpoints (can be gcs path)\n",
    "    shuffle_buffer_size: int = 128\n",
    "    eval_interval: int = 500\n",
    "    eval_steps: int = 16        # evaluate for this number of steps (per-device)\n",
    "    eval_only: bool = False     # if True, script exits right after the first eval\n",
    "    keep_checkpoints: int = 3   # number of historical checkpoints to keep\n",
    "    batch_size: int = 64        # per-device batch size\n",
    "    train_steps: int = 6250   # total number of training iterations\n",
    "    weight_decay: float = 1e-2  # not applied to bias and embedding parameters\n",
    "    grad_clip: float = 1.0      # gradient norm clipping magnitude\n",
    "    gradient_accumulation_steps: int = 1    # used to simulate larger batch sizes\n",
    "    betas: Tuple[float, float] = (0.9, 0.95) # adamw optimizer betas\n",
    "    # learning_rate: CosineDecayScheduleConfig = field(default_factory=CosineDecayScheduleConfig)\n",
    "    learning_rate: StaticLRConfig = field(default_factory=StaticLRConfig)\n",
    "    wandb: WandbConfig = field(default_factory=WandbConfig) # wandb logging\n",
    "    model: GPTConfig = field(default_factory=GPTConfig)     # gpt model config\n",
    "    remat: bool = False    # set to True to rematerialize gradients during backward pass\n",
    "\n",
    "\n",
    "def get_default_config() -> TrainConfig:\n",
    "    return TrainConfig()\n",
    "\n",
    "config = get_default_config()\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 16:27:32.136272: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib\n",
      "2024-04-24 16:27:32.805504: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib\n",
      "2024-04-24 16:27:32.805589: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib\n",
      "2024-04-24 16:27:32.805596: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax\n",
    "from flax.core import FrozenDict, frozen_dict\n",
    "from flax.training import checkpoints\n",
    "from flax.training.train_state import TrainState\n",
    "from flax.jax_utils import replicate, unreplicate\n",
    "import optax\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss_and_accuracy(logits, tokens, valid=None):\n",
    "    if valid is None:\n",
    "        valid = jnp.ones(tokens.shape[:2])\n",
    "    valid = valid.astype(jnp.float32)\n",
    "    valid_text_length = jnp.maximum(jnp.sum(valid, axis=-1), 1e-10)\n",
    "    logits = logits.astype(jnp.float32)  # for numerical stability\n",
    "    token_log_prob = jnp.squeeze(\n",
    "        jnp.take_along_axis(\n",
    "            jax.nn.log_softmax(logits, axis=-1),\n",
    "            jnp.expand_dims(tokens, -1),\n",
    "            axis=-1,\n",
    "        ),\n",
    "        -1,\n",
    "    )\n",
    "    token_log_prob = jnp.where(valid > 0.0, token_log_prob, jnp.array(0.0))\n",
    "    loss = -(jnp.sum(token_log_prob) / jnp.sum(valid))\n",
    "    # old: loss = -jnp.mean(jnp.sum(token_log_prob, axis=-1) / valid_text_length)\n",
    "    # changed to match hf implementation\n",
    "    correct = jnp.where(\n",
    "        valid > 0.0,\n",
    "        jnp.argmax(logits, axis=-1) == tokens,\n",
    "        jnp.array(False)\n",
    "    )\n",
    "    accuracy = jnp.mean(jnp.sum(correct, axis=-1) / valid_text_length)\n",
    "    return loss, accuracy\n",
    "\n",
    "\n",
    "@partial(jax.pmap, axis_name='batch', in_axes=(0, 0, 0, 0))\n",
    "def train_step(state: TrainState, input_tokens: jnp.ndarray, target_tokens: jnp.ndarray, dropout_key) -> Tuple[jnp.ndarray, TrainState]:\n",
    "    dropout_key = jax.random.fold_in(dropout_key, state.step)\n",
    "    def loss_fn(params: FrozenDict) -> jnp.ndarray:\n",
    "        logits = state.apply_fn(params, input_tokens, False, rngs={'dropout': dropout_key})\n",
    "        return cross_entropy_loss_and_accuracy(\n",
    "            logits, target_tokens, (target_tokens > 0).astype(jnp.int32))\n",
    "    # per-device loss and grads\n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    (loss, acc), grads = grad_fn(state.params)\n",
    "    # average gradients across devices\n",
    "    grads = jax.lax.pmean(grads, axis_name=\"batch\")\n",
    "    loss = jax.lax.pmean(loss, axis_name=\"batch\")\n",
    "    acc = jax.lax.pmean(acc, axis_name=\"batch\")\n",
    "    new_state = state.apply_gradients(grads=grads)\n",
    "    return loss, acc, new_state\n",
    "\n",
    "\n",
    "@partial(jax.pmap, axis_name='batch', in_axes=(0, 0, 0))\n",
    "def eval_step(state: TrainState, input_tokens: jnp.ndarray, target_tokens: jnp.ndarray) -> jnp.ndarray:\n",
    "    logits = state.apply_fn(state.params, input_tokens, True)\n",
    "    loss, acc = cross_entropy_loss_and_accuracy(\n",
    "            logits, target_tokens, (target_tokens > 0).astype(jnp.int32))\n",
    "    loss = jax.lax.pmean(loss, axis_name=\"batch\")\n",
    "    acc = jax.lax.pmean(acc, axis_name=\"batch\")\n",
    "    return loss, acc\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(state: TrainState, loader: DataLoader) -> jnp.ndarray:\n",
    "    losses = []\n",
    "    accs = []\n",
    "    for batch in loader:\n",
    "        input_tokens, target_tokens = batch\n",
    "        input_tokens = jnp.array(input_tokens)\n",
    "        target_tokens = jnp.array(target_tokens)\n",
    "        input_tokens = input_tokens.reshape(jax.local_device_count(), -1, input_tokens.shape[-1])\n",
    "        target_tokens = target_tokens.reshape(jax.local_device_count(), -1, target_tokens.shape[-1])\n",
    "        loss, acc = eval_step(state, input_tokens, target_tokens)\n",
    "        losses.append(loss)\n",
    "        accs.append(acc)\n",
    "    return jnp.mean(jnp.stack(losses)), jnp.mean(jnp.stack(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "def prefix_target_list(filename=None):\n",
    "    \"\"\"\n",
    "    Load graphs and split them into prefix and target and return the list\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        prefix = line.strip().split('=')[0] + '='\n",
    "        target = line.strip().split('=')[1]\n",
    "        target = target.split(',')[1]\n",
    "        data_list.append((prefix, target))\n",
    "    return data_list\n",
    "\n",
    "\n",
    "class Graphs(Dataset):\n",
    "    def __init__(self, tokenizer, n_samples, data_path):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.n_samples = n_samples\n",
    "        self.data_path = data_path\n",
    "        self.eval_mode = False\n",
    "        self.data_file = prefix_target_list(self.data_path)\n",
    "        self.tokenized, self.num_prefix_tokens, self.num_target_tokens = self.tokenize(self.data_file[:n_samples])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokenized)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.eval_mode:\n",
    "            # In eval mode return the entire sequence\n",
    "            return self.tokenized[idx].to(self.device)\n",
    "\n",
    "        # Create inputs\n",
    "        x = self.tokenized[idx].clone()\n",
    "        y = torch.cat([-torch.ones((self.num_prefix_tokens - 1, )),\n",
    "                       x[self.num_prefix_tokens:].clone()])\n",
    "        return x[:-1], y.long()\n",
    "\n",
    "    def tokenize(self, data_list):\n",
    "        \"\"\"\n",
    "        Takes a list of prefix-target pairs, tokenizes and concatenates them\n",
    "        \"\"\"\n",
    "        out = []\n",
    "        prefix_len = len(self.tokenizer.encode(data_list[0][0]))\n",
    "        target_len = len(self.tokenizer.encode(data_list[0][1]))\n",
    "        same_len = True\n",
    "\n",
    "        for prefix, target in data_list:\n",
    "            prefix = torch.tensor(self.tokenizer.encode(prefix))\n",
    "            target = torch.tensor(self.tokenizer.encode(target))\n",
    "            if not (len(prefix) == prefix_len and len(target) == target_len):\n",
    "                same_len = False\n",
    "            seq = torch.concatenate([prefix, target], dim=-1).long()\n",
    "            out.append(seq)\n",
    "\n",
    "        # Check if all prefixes and all targets have the same length\n",
    "        if not same_len:\n",
    "            print('Not all prefixes or targets have the same length!!')\n",
    "        else:\n",
    "            print('Equal sequence lengths!')\n",
    "\n",
    "        return out, prefix_len, target_len\n",
    "\n",
    "    def eval(self):\n",
    "        # Switch to \"eval\" mode when generating sequences without teacher-forcing\n",
    "        self.eval_mode = True\n",
    "\n",
    "    def train(self):\n",
    "        # Switch back to \"train\" mode for teacher-forcing\n",
    "        self.eval_mode = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equal sequence lengths!\n",
      "Equal sequence lengths!\n",
      "(tensor([17, 11, 23, 91, 24, 11, 15, 91, 17, 11, 22, 91, 21, 11, 19, 91, 19, 11,\n",
      "        18, 91, 22, 11, 21, 91, 23, 11, 24, 91, 15, 11, 16, 14, 17, 11, 18, 28]), tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 22])) 2,8|9,0|2,7|6,4|4,3|7,6|8,9|0,1/2,3= 7\n"
     ]
    }
   ],
   "source": [
    "# LOAD TOKENIZER\n",
    "from transformers import AutoTokenizer # type: ignore\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# LOAD DATASET\n",
    "data_path = 'deg_2_path_5_nodes_10'\n",
    "train_path, test_path = data_path + '_train_200000.txt', data_path + '_test_20000.txt'\n",
    "train_data = Graphs(tokenizer=tokenizer, n_samples=20000, data_path=train_path)\n",
    "test_data = Graphs(tokenizer=tokenizer, n_samples=200, data_path=test_path)\n",
    "train_data.train()\n",
    "\n",
    "# sanity check\n",
    "print(train_data[0], tokenizer.decode(train_data[0][0]), tokenizer.decode(train_data[0][1][-train_data.num_target_tokens:]))\n",
    "\n",
    "# LOAD DATALOADER\n",
    "train_loader = DataLoader(train_data, batch_size=config.batch_size, shuffle=True, drop_last=True) \n",
    "test_loader = DataLoader(test_data, batch_size=config.batch_size, shuffle=False, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer vocab size:  50257 36 1\n"
     ]
    }
   ],
   "source": [
    "print(\"tokenizer vocab size: \", tokenizer.vocab_size, train_data.num_prefix_tokens, train_data.num_target_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_decay_mask(params: FrozenDict) -> FrozenDict:\n",
    "    \"\"\" pytree mask for non-bias parameters \"\"\"\n",
    "    flat_params = flax.traverse_util.flatten_dict(params)\n",
    "    flat_param_mask = {k: k[-1] not in ('bias', 'embedding', 'scale') for k in flat_params.keys()}\n",
    "    param_mask = flax.traverse_util.unflatten_dict(flat_param_mask)\n",
    "    return frozen_dict.freeze(param_mask)\n",
    "\n",
    "def init_train_state(key, config: TrainConfig, learning_rate) -> TrainState:\n",
    "\n",
    "    if config.remat:\n",
    "        model = flax.linen.remat(GPT,\n",
    "            static_argnums=(2,),\n",
    "            policy=jax.checkpoint_policies.checkpoint_dots_with_no_batch_dims)(config.model)\n",
    "    else:\n",
    "        config.model, params = get_pretrained_params(config.gpt2_model_type)\n",
    "        model = GPT(config.model)    \n",
    "        model.init(key)\n",
    "\n",
    "    optimizer = optax.chain(\n",
    "        # Apply weight decay only to non-bias parameters\n",
    "        optax.clip_by_global_norm(config.grad_clip),\n",
    "        optax.adamw(learning_rate, *config.betas, weight_decay=config.weight_decay, mask=param_decay_mask(params)),\n",
    "        optax.apply_every(config.gradient_accumulation_steps),\n",
    "    )\n",
    "\n",
    "    train_state = TrainState.create(\n",
    "        apply_fn=model.apply,\n",
    "        params=params,\n",
    "        tx=optimizer)\n",
    "\n",
    "    return train_state\n",
    "\n",
    "def count_params(params: FrozenDict) -> int:\n",
    "    p = jax.tree_util.tree_map(lambda a: a.size if isinstance(a, jnp.ndarray) else 0, params)\n",
    "    return jax.tree_util.tree_reduce(lambda a, b: a + b, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====  init parameters ============\n",
    "key = jax.random.PRNGKey(config.seed)\n",
    "key, key_params, key_dropout = jax.random.split(key, 3)\n",
    "# make sure dropout keys are different for each device (local and global)\n",
    "key_dropout = jax.random.fold_in(key_dropout, jax.process_index())\n",
    "keys_dropout = jax.random.split(key_dropout, jax.local_device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from pretrained gpt: gpt2-large\n"
     ]
    }
   ],
   "source": [
    "learning_rate = config.learning_rate.init_value\n",
    "train_state = init_train_state(key_params, config, learning_rate)\n",
    "num_params = count_params(train_state.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 774,030,080\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total parameters: {num_params:,}\") # 774,030,080 for gpt2-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replicate model\n",
    "train_state = replicate(train_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    def __init__(self):\n",
    "        self.num = 0\n",
    "        self.val = 0\n",
    "\n",
    "    def update(self, val, num):\n",
    "        self.val += val * num\n",
    "        self.num += num\n",
    "\n",
    "    def get(self, percentage=False):\n",
    "        val = self.val / self.num * 100 if percentage else self.val / self.num\n",
    "        return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training:   0%|          | 0/6250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 0.15650126338005066 train acc: 94.125 val loss: 1.3534506559371948 val acc: 0.5052083730697632: 100%|██████████| 6250/6250 [20:00<00:00,  5.20it/s]           \n"
     ]
    }
   ],
   "source": [
    "train_iter = iter(train_loader)\n",
    "pbar = tqdm(range(config.train_steps), total=config.train_steps, desc='training')\n",
    "train_loss, train_acc = AverageMeter(), AverageMeter()\n",
    "val_loss, val_acc = jnp.inf, 0.\n",
    "for step in pbar:\n",
    "    try:\n",
    "        input_tokens, target_tokens = next(train_iter)\n",
    "    except StopIteration:\n",
    "        train_iter = iter(train_loader)\n",
    "    input_tokens = jnp.array(input_tokens)\n",
    "    target_tokens = jnp.array(target_tokens) \n",
    "    input_tokens = input_tokens.reshape(jax.device_count(), -1, input_tokens.shape[-1])\n",
    "    target_tokens = target_tokens.reshape(jax.device_count(), -1, target_tokens.shape[-1])\n",
    "    loss, acc, train_state = train_step(train_state, input_tokens, target_tokens, keys_dropout)\n",
    "    train_loss.update(loss.mean(), input_tokens.shape[1] * jax.device_count())  \n",
    "    train_acc.update(acc.mean(), input_tokens.shape[1] * jax.device_count())    \n",
    "    if step % 100 == 0:\n",
    "        pbar.set_description(f'train loss: {train_loss.get()} train acc: {train_acc.get(percentage=True)} val loss: {val_loss} val acc: {val_acc}')\n",
    "    if step % config.eval_interval == 0:\n",
    "        val_loss, val_acc = evaluate(train_state, test_loader)\n",
    "        train_loss, train_acc = AverageMeter(), AverageMeter()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'FlaxGPT2LMHeadModel' has no attribute 'from_flax'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FlaxGPT2LMHeadModel\n\u001b[0;32m----> 3\u001b[0m \u001b[43mFlaxGPT2LMHeadModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_flax\u001b[49m(train_state\u001b[38;5;241m.\u001b[39mparams, config\u001b[38;5;241m.\u001b[39mmodel)\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt2-deg2-path5-nodes10\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'FlaxGPT2LMHeadModel' has no attribute 'from_flax'"
     ]
    }
   ],
   "source": [
    "from transformers import FlaxGPT2LMHeadModel\n",
    "\n",
    "FlaxGPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method FlaxPreTrainedModel.from_pretrained of <class 'transformers.models.gpt2.modeling_flax_gpt2.FlaxGPT2LMHeadModel'>>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "init() got an unexpected keyword argument 'method'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FlaxGPT2LMHeadModel\n\u001b[1;32m      2\u001b[0m hf_model \u001b[38;5;241m=\u001b[39m GPT(\n\u001b[1;32m      3\u001b[0m             config\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[1;32m      4\u001b[0m             \u001b[38;5;66;03m# input_shape=(1, train_data.num_prefix_tokens),\u001b[39;00m\n\u001b[1;32m      5\u001b[0m             \u001b[38;5;66;03m# seed=22,\u001b[39;00m\n\u001b[1;32m      6\u001b[0m             \u001b[38;5;66;03m# _do_init=False\u001b[39;00m\n\u001b[1;32m      7\u001b[0m             )\n\u001b[0;32m----> 8\u001b[0m \u001b[43mhf_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcan_generate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/flax/linen/module.py:418\u001b[0m, in \u001b[0;36mwrap_method_once.<locals>.wrapped_module_method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], Module):\n\u001b[1;32m    417\u001b[0m   \u001b[38;5;28mself\u001b[39m, args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m], args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 418\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_wrapped_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    420\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/flax/linen/module.py:854\u001b[0m, in \u001b[0;36mModule._call_wrapped_method\u001b[0;34m(self, fun, args, kwargs)\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_named_call:\n\u001b[1;32m    853\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m jax\u001b[38;5;241m.\u001b[39mnamed_scope(_derive_profiling_name(\u001b[38;5;28mself\u001b[39m, fun)):\n\u001b[0;32m--> 854\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    856\u001b[0m   y \u001b[38;5;241m=\u001b[39m fun(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: init() got an unexpected keyword argument 'method'"
     ]
    }
   ],
   "source": [
    "from transformers import FlaxGPT2LMHeadModel\n",
    "hf_model = GPT(\n",
    "            config=config.model,\n",
    "            # input_shape=(1, train_data.num_prefix_tokens),\n",
    "            # seed=22,\n",
    "            # _do_init=False\n",
    "            )\n",
    "hf_model.init(key_params, method='can_generate')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "\"GPT\" object has no attribute \"can_generate\". If \"can_generate\" is defined in '.setup()', remember these fields are only accessible from inside 'init' or 'apply'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mhf_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcan_generate\u001b[49m()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/flax/linen/module.py:931\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    929\u001b[0m   msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m If \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is defined in \u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m.setup()\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m, remember these fields \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mare only accessible from inside \u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124minit\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m or \u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 931\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(msg)\n",
      "\u001b[0;31mAttributeError\u001b[0m: \"GPT\" object has no attribute \"can_generate\". If \"can_generate\" is defined in '.setup()', remember these fields are only accessible from inside 'init' or 'apply'."
     ]
    }
   ],
   "source": [
    "hf_model.can_generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_state = unreplicate(train_state)\n",
    "FlaxGPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input type must be an integer or unsigned integer.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mhf_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_prefix_tokens\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 6 frame]\u001b[0m\n",
      "File \u001b[0;32m~/EasyLM/EasyLM/star_graph/../../EasyLM/models/gpt2/gpt2_model.py:101\u001b[0m, in \u001b[0;36mGPT.__call__\u001b[0;34m(self, idx, deterministic)\u001b[0m\n\u001b[1;32m     98\u001b[0m wte \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mEmbed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mvocab_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_embeds, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdtype, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwte\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     99\u001b[0m wpe \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mEmbed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mblock_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_embeds, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdtype, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwpe\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 101\u001b[0m token_embed \u001b[38;5;241m=\u001b[39m \u001b[43mwte\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m      \u001b[38;5;66;03m# [B, T, num_embeds]\u001b[39;00m\n\u001b[1;32m    102\u001b[0m pos_embed \u001b[38;5;241m=\u001b[39m wpe(pos)        \u001b[38;5;66;03m# [1, T, num_embeds]\u001b[39;00m\n\u001b[1;32m    103\u001b[0m x \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdropout_rate)(token_embed \u001b[38;5;241m+\u001b[39m pos_embed, deterministic)\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/flax/linen/linear.py:787\u001b[0m, in \u001b[0;36mEmbed.__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Embeds the inputs along the last dimension.\u001b[39;00m\n\u001b[1;32m    778\u001b[0m \n\u001b[1;32m    779\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;124;03m  with an additional `features` dimension appended.\u001b[39;00m\n\u001b[1;32m    785\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m jnp\u001b[38;5;241m.\u001b[39missubdtype(inputs\u001b[38;5;241m.\u001b[39mdtype, jnp\u001b[38;5;241m.\u001b[39minteger):\n\u001b[0;32m--> 787\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput type must be an integer or unsigned integer.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Use take because fancy indexing numpy arrays with JAX indices does not\u001b[39;00m\n\u001b[1;32m    789\u001b[0m \u001b[38;5;66;03m# work correctly.\u001b[39;00m\n\u001b[1;32m    790\u001b[0m embedding, \u001b[38;5;241m=\u001b[39m promote_dtype(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, inexact\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: Input type must be an integer or unsigned integer."
     ]
    }
   ],
   "source": [
    "hf_model.apply(train_state.params, jnp.ones((1, train_data.num_prefix_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, FlaxGPT2LMHeadModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
    "model = FlaxGPT2LMHeadModel.from_pretrained(\"openai-community/gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"np\")\n",
    "outputs = model.generate(**inputs,\n",
    "    num_beams=5,\n",
    "    max_new_tokens=1,\n",
    "    num_return_sequences=5,\n",
    "    temperature=1.0,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Config {\n",
       "  \"activation_function\": \"gelu_new\",\n",
       "  \"architectures\": [\n",
       "    \"GPT2LMHeadModel\"\n",
       "  ],\n",
       "  \"attn_pdrop\": 0.1,\n",
       "  \"bos_token_id\": 50256,\n",
       "  \"embd_pdrop\": 0.1,\n",
       "  \"eos_token_id\": 50256,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"model_type\": \"gpt2\",\n",
       "  \"n_ctx\": 1024,\n",
       "  \"n_embd\": 768,\n",
       "  \"n_head\": 12,\n",
       "  \"n_inner\": null,\n",
       "  \"n_layer\": 12,\n",
       "  \"n_positions\": 1024,\n",
       "  \"reorder_and_upcast_attn\": false,\n",
       "  \"resid_pdrop\": 0.1,\n",
       "  \"scale_attn_by_inverse_layer_idx\": false,\n",
       "  \"scale_attn_weights\": true,\n",
       "  \"summary_activation\": null,\n",
       "  \"summary_first_dropout\": 0.1,\n",
       "  \"summary_proj_to_labels\": true,\n",
       "  \"summary_type\": \"cls_index\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"task_specific_params\": {\n",
       "    \"text-generation\": {\n",
       "      \"do_sample\": true,\n",
       "      \"max_length\": 50\n",
       "    }\n",
       "  },\n",
       "  \"transformers_version\": \"4.31.0\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50257\n",
       "}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTConfig(block_size=1024, vocab_size=50257, num_layers=36, num_heads=20, num_embeds=1280, dropout_rate=0.1, use_bias=True, dtype=None)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(model.config), type(config.model)\n",
    "model.config.n_layer = 36\n",
    "model.config.n_head = 20\n",
    "model.config.n_embd = 1280\n",
    "# model.config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GPTConfig' object has no attribute 'to_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[117], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43munfreeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GPTConfig' object has no attribute 'to_dict'"
     ]
    }
   ],
   "source": [
    "unfreeze(config.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoTokenizer, FlaxGPT2LMHeadModel\n",
    "# hf_model = FlaxGPT2LMHeadModel(\n",
    "#     config.model,\n",
    "#     input_shape=(1, train_data.num_prefix_tokens),\n",
    "#     seed=22,\n",
    "#     _do_init=False\n",
    "# )\n",
    "hf_model = FlaxGPT2LMHeadModel.from_pretrained(\"openai-community/gpt2-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[17, 11, 23, 91, 24, 11, 15, 91, 17, 11, 22, 91, 21, 11, 19, 91, 19, 11,\n",
       "         18, 91, 22, 11, 21, 91, 23, 11, 24, 91, 15, 11, 16, 14, 17, 11, 18, 28]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = input_tokens.reshape(-1, 36)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenDict({\n",
       "    0: {\n",
       "        attn: {\n",
       "            c_attn: {\n",
       "                bias: Array([-0.00806067, -0.08205216,  0.17712198, ..., -0.03094645,\n",
       "                       -0.02834609,  0.0028557 ], dtype=float32),\n",
       "                kernel: Array([[ 0.16554965,  0.12297295,  0.10031797, ..., -0.00807998,\n",
       "                         0.0106448 , -0.01827521],\n",
       "                       [-0.23444045,  0.14132349,  0.07059898, ..., -0.0105182 ,\n",
       "                         0.02387178, -0.01008427],\n",
       "                       [ 0.1062863 , -0.03969869,  0.10846853, ..., -0.00417321,\n",
       "                         0.01832751, -0.00796596],\n",
       "                       ...,\n",
       "                       [ 0.00202721,  0.12571906, -0.07979144, ...,  0.00236412,\n",
       "                         0.03511722,  0.02043647],\n",
       "                       [-0.11458338, -0.08969299, -0.09247336, ...,  0.00126929,\n",
       "                         0.00066453, -0.0041295 ],\n",
       "                       [ 0.02215027, -0.01706643, -0.04627626, ...,  0.02902106,\n",
       "                         0.02582104, -0.0327217 ]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([-0.01144728,  0.0365472 , -0.00156556, ...,  0.02736477,\n",
       "                       -0.00746843,  0.03922034], dtype=float32),\n",
       "                kernel: Array([[ 0.01133492,  0.01151626, -0.02100956, ..., -0.01405654,\n",
       "                        -0.00335612,  0.02988927],\n",
       "                       [-0.01268945, -0.02229757, -0.05776289, ...,  0.07052165,\n",
       "                        -0.04539669, -0.01878756],\n",
       "                       [ 0.03793592,  0.01945222,  0.03890876, ...,  0.00468673,\n",
       "                         0.04275589, -0.0749495 ],\n",
       "                       ...,\n",
       "                       [-0.01771595,  0.01020293,  0.01688005, ...,  0.03490546,\n",
       "                         0.01065123,  0.00949867],\n",
       "                       [-0.00328715, -0.01875043,  0.01664503, ...,  0.00446178,\n",
       "                        -0.01593386, -0.02856372],\n",
       "                       [ 0.02454931,  0.00220935, -0.01772885, ...,  0.01188086,\n",
       "                         0.0213084 , -0.03635458]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "        ln_1: {\n",
       "            bias: Array([ 0.01123354, -0.01417697,  0.00650295, ..., -0.01851034,\n",
       "                   -0.01368136, -0.02099491], dtype=float32),\n",
       "            scale: Array([0.28894216, 0.28614348, 0.3010614 , ..., 0.2696827 , 0.2500453 ,\n",
       "                   0.17852534], dtype=float32),\n",
       "        },\n",
       "        ln_2: {\n",
       "            bias: Array([-0.03590904, -0.03210072,  0.00026501, ...,  0.09937602,\n",
       "                   -0.1393274 , -0.01080626], dtype=float32),\n",
       "            scale: Array([0.5264808 , 0.39997444, 0.36181778, ..., 0.44054303, 0.3055512 ,\n",
       "                   0.18258318], dtype=float32),\n",
       "        },\n",
       "        mlp: {\n",
       "            c_fc: {\n",
       "                bias: Array([-0.06916936, -0.07838885, -0.06607128, ..., -0.1051634 ,\n",
       "                       -0.08991828, -0.06540737], dtype=float32),\n",
       "                kernel: Array([[-0.05826445,  0.05596583, -0.04735798, ..., -0.03835429,\n",
       "                        -0.09354223, -0.12613678],\n",
       "                       [-0.02078129, -0.02883946,  0.04853408, ..., -0.00435286,\n",
       "                        -0.11046726,  0.08467893],\n",
       "                       [-0.08321944,  0.04720354,  0.05368477, ...,  0.01881366,\n",
       "                         0.03279455, -0.10345227],\n",
       "                       ...,\n",
       "                       [-0.06757478, -0.07983246,  0.02246903, ..., -0.06725591,\n",
       "                        -0.00235579, -0.03377793],\n",
       "                       [ 0.08242241,  0.03676083, -0.00670699, ...,  0.06006376,\n",
       "                         0.04302322,  0.02327235],\n",
       "                       [ 0.00864029,  0.0176181 ,  0.0452676 , ..., -0.00238721,\n",
       "                        -0.02418141,  0.01996941]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([ 0.00972492, -0.01897503,  0.0156537 , ...,  0.05783964,\n",
       "                        0.07669863, -0.010941  ], dtype=float32),\n",
       "                kernel: Array([[-0.01274799,  0.02626904, -0.00082694, ..., -0.02880153,\n",
       "                         0.03149987,  0.00739569],\n",
       "                       [ 0.01002527, -0.01385257,  0.0118017 , ..., -0.03952581,\n",
       "                        -0.00903307,  0.02651956],\n",
       "                       [-0.01568741, -0.00441044,  0.00713749, ..., -0.00524011,\n",
       "                        -0.00363431, -0.00045721],\n",
       "                       ...,\n",
       "                       [-0.03739459,  0.02904921, -0.04266255, ...,  0.02816904,\n",
       "                         0.04983811,  0.05676064],\n",
       "                       [ 0.01019448,  0.01065494, -0.00303075, ...,  0.02857824,\n",
       "                        -0.00311145,  0.04820529],\n",
       "                       [-0.03020904, -0.00878521, -0.02111002, ..., -0.04214809,\n",
       "                        -0.00373292,  0.00824505]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "    1: {\n",
       "        attn: {\n",
       "            c_attn: {\n",
       "                bias: Array([-0.15221442,  0.01095768, -0.23043919, ..., -0.00835071,\n",
       "                        0.03358821,  0.01850057], dtype=float32),\n",
       "                kernel: Array([[ 0.05648328, -0.00820094,  0.0184177 , ...,  0.03831045,\n",
       "                         0.03213073,  0.02756165],\n",
       "                       [-0.00723719, -0.05333716,  0.02396652, ..., -0.01274015,\n",
       "                         0.02572118, -0.01649939],\n",
       "                       [ 0.00342849,  0.10700248,  0.10875006, ..., -0.02115568,\n",
       "                        -0.01257164, -0.08181655],\n",
       "                       ...,\n",
       "                       [ 0.00542727,  0.04644989,  0.08896411, ...,  0.01239162,\n",
       "                         0.02527379, -0.05462379],\n",
       "                       [ 0.04328296,  0.00314054, -0.03231358, ..., -0.02769008,\n",
       "                        -0.01280828,  0.02894634],\n",
       "                       [-0.00496276,  0.07774284,  0.0854713 , ..., -0.03763867,\n",
       "                         0.01962829,  0.00598486]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([-0.04615428,  0.017907  , -0.01985262, ...,  0.03903442,\n",
       "                        0.02395037,  0.02489467], dtype=float32),\n",
       "                kernel: Array([[ 0.00078996, -0.03916684,  0.04177172, ..., -0.00443744,\n",
       "                         0.04831451,  0.00962692],\n",
       "                       [-0.02006885, -0.04995507, -0.00773344, ...,  0.00564303,\n",
       "                         0.00035719, -0.02479497],\n",
       "                       [-0.01078508, -0.04603594,  0.0243956 , ..., -0.03822174,\n",
       "                        -0.01219875, -0.00359934],\n",
       "                       ...,\n",
       "                       [ 0.01995835, -0.0357382 , -0.03967066, ...,  0.00707609,\n",
       "                         0.01422159,  0.01574153],\n",
       "                       [-0.04572298,  0.01973083, -0.02893983, ...,  0.00773961,\n",
       "                         0.02075595,  0.0260431 ],\n",
       "                       [ 0.03402839, -0.00668523,  0.00700167, ..., -0.00115951,\n",
       "                        -0.02514695, -0.01453887]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "        ln_1: {\n",
       "            bias: Array([-0.02744458, -0.03141211, -0.00919125, ..., -0.08943131,\n",
       "                   -0.0028525 , -0.04665478], dtype=float32),\n",
       "            scale: Array([0.32519576, 0.29430196, 0.30102807, ..., 0.29273573, 0.31316203,\n",
       "                   0.24549317], dtype=float32),\n",
       "        },\n",
       "        ln_2: {\n",
       "            bias: Array([-0.05924468, -0.13904998,  0.030359  , ..., -0.06406971,\n",
       "                    0.08530246,  0.0532798 ], dtype=float32),\n",
       "            scale: Array([0.5187359 , 0.56037366, 0.50791335, ..., 0.47782436, 0.5095422 ,\n",
       "                   0.4608667 ], dtype=float32),\n",
       "        },\n",
       "        mlp: {\n",
       "            c_fc: {\n",
       "                bias: Array([-0.07522187, -0.05820139, -0.06714217, ..., -0.0582825 ,\n",
       "                       -0.04431867, -0.05334959], dtype=float32),\n",
       "                kernel: Array([[-0.0703942 ,  0.01365506,  0.04085029, ..., -0.10386319,\n",
       "                         0.05268864, -0.01472998],\n",
       "                       [ 0.12879956,  0.0080748 ,  0.01101163, ...,  0.00658144,\n",
       "                         0.04330568, -0.08233353],\n",
       "                       [ 0.06688353,  0.07956184, -0.01715781, ..., -0.08282135,\n",
       "                         0.05210731,  0.08956587],\n",
       "                       ...,\n",
       "                       [-0.03726161,  0.06388754,  0.02094175, ..., -0.07959186,\n",
       "                         0.05303093,  0.00329315],\n",
       "                       [ 0.07952193, -0.05651461, -0.02610541, ..., -0.00235022,\n",
       "                        -0.01674673,  0.02773261],\n",
       "                       [ 0.02265811, -0.03944816, -0.02741184, ..., -0.03755923,\n",
       "                        -0.00838341,  0.04821151]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([-0.02518303, -0.03152892,  0.0166734 , ...,  0.0337945 ,\n",
       "                        0.08174776,  0.02485966], dtype=float32),\n",
       "                kernel: Array([[-0.05596184,  0.07087243,  0.04496761, ..., -0.00850271,\n",
       "                         0.04207072, -0.02529795],\n",
       "                       [-0.02415441,  0.01400976,  0.02816896, ..., -0.03867916,\n",
       "                        -0.03825453, -0.06184343],\n",
       "                       [-0.02115076,  0.01171318, -0.06511842, ...,  0.04453088,\n",
       "                        -0.0122576 , -0.00622782],\n",
       "                       ...,\n",
       "                       [-0.00683815, -0.01605837, -0.0849003 , ..., -0.01226597,\n",
       "                         0.05680716, -0.00716699],\n",
       "                       [ 0.00016359, -0.03679368,  0.00314977, ..., -0.00375592,\n",
       "                        -0.06710148,  0.0506695 ],\n",
       "                       [-0.00996248, -0.07275025, -0.01918012, ..., -0.0437047 ,\n",
       "                        -0.00232847,  0.00581692]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "    10: {\n",
       "        attn: {\n",
       "            c_attn: {\n",
       "                bias: Array([-0.04080461, -0.07718921, -0.15175544, ..., -0.0220191 ,\n",
       "                        0.00996731, -0.00490939], dtype=float32),\n",
       "                kernel: Array([[-0.00479335, -0.00132569, -0.04203443, ...,  0.04508255,\n",
       "                         0.00790615,  0.0202021 ],\n",
       "                       [-0.01202896, -0.05051075,  0.04272674, ..., -0.07448006,\n",
       "                         0.0148204 , -0.01263014],\n",
       "                       [ 0.04470937, -0.0774451 ,  0.06933478, ..., -0.01431647,\n",
       "                         0.00207525, -0.03490788],\n",
       "                       ...,\n",
       "                       [-0.17054637,  0.04291749, -0.04544777, ..., -0.06788059,\n",
       "                        -0.0069812 ,  0.03388384],\n",
       "                       [-0.07155348, -0.05328591,  0.01813143, ..., -0.04170485,\n",
       "                        -0.02220802, -0.01291933],\n",
       "                       [ 0.07825941,  0.01665433,  0.00520321, ...,  0.00979957,\n",
       "                        -0.02899147, -0.04879507]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([ 0.00650678, -0.02772267, -0.04727175, ...,  0.01179967,\n",
       "                       -0.03915552, -0.0050743 ], dtype=float32),\n",
       "                kernel: Array([[ 0.03063137,  0.02845792,  0.00240159, ..., -0.00018538,\n",
       "                         0.09022441,  0.01936903],\n",
       "                       [ 0.02345913,  0.03615752,  0.03355216, ...,  0.00961557,\n",
       "                         0.02655307,  0.00951734],\n",
       "                       [ 0.0199417 ,  0.00896413,  0.03303835, ...,  0.0110226 ,\n",
       "                         0.00855461, -0.03826226],\n",
       "                       ...,\n",
       "                       [-0.03387058, -0.04939462,  0.01545185, ..., -0.08127665,\n",
       "                         0.04799291,  0.00282397],\n",
       "                       [-0.01989695, -0.03137016,  0.01526937, ..., -0.05886317,\n",
       "                         0.00660869,  0.07253707],\n",
       "                       [ 0.03661846, -0.05735151,  0.09407931, ...,  0.01290271,\n",
       "                         0.01282345,  0.09664333]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "        ln_1: {\n",
       "            bias: Array([-0.06141328,  0.00859376,  0.02491324, ..., -0.09833977,\n",
       "                   -0.05845266, -0.01735953], dtype=float32),\n",
       "            scale: Array([0.5137233 , 0.56979156, 0.5624747 , ..., 0.50404686, 0.5669546 ,\n",
       "                   0.517687  ], dtype=float32),\n",
       "        },\n",
       "        ln_2: {\n",
       "            bias: Array([-0.03892346, -0.02554949, -0.00836867, ...,  0.0477081 ,\n",
       "                   -0.02907988,  0.02176111], dtype=float32),\n",
       "            scale: Array([0.57963824, 0.62132114, 0.62432706, ..., 0.61740416, 0.5914682 ,\n",
       "                   0.58374333], dtype=float32),\n",
       "        },\n",
       "        mlp: {\n",
       "            c_fc: {\n",
       "                bias: Array([-0.04945495,  0.01051492, -0.01495147, ..., -0.05225803,\n",
       "                       -0.02489247, -0.05665023], dtype=float32),\n",
       "                kernel: Array([[-0.01785805,  0.01508116, -0.05762998, ..., -0.01115686,\n",
       "                        -0.02296064,  0.00452235],\n",
       "                       [-0.02689639, -0.02354559,  0.04601995, ..., -0.01112436,\n",
       "                         0.07838295, -0.00160224],\n",
       "                       [ 0.01566927,  0.01166441,  0.00149262, ...,  0.00089247,\n",
       "                         0.09065341, -0.06437218],\n",
       "                       ...,\n",
       "                       [-0.04589159,  0.02365166, -0.01944812, ...,  0.03789217,\n",
       "                        -0.020658  , -0.03684991],\n",
       "                       [ 0.01831101, -0.01951984, -0.04429929, ..., -0.01661546,\n",
       "                         0.01301058,  0.02674057],\n",
       "                       [ 0.03881139, -0.04226046, -0.06425739, ...,  0.0638937 ,\n",
       "                        -0.09095677, -0.00689567]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([-0.01966968,  0.01288934, -0.03721309, ...,  0.01364874,\n",
       "                        0.0628769 ,  0.00912754], dtype=float32),\n",
       "                kernel: Array([[-0.03900837,  0.03282987, -0.03972655, ..., -0.00122669,\n",
       "                        -0.07839051,  0.09027483],\n",
       "                       [ 0.00055024,  0.03367782, -0.01416857, ..., -0.03295363,\n",
       "                        -0.01269747,  0.0029632 ],\n",
       "                       [ 0.03986463, -0.01264496, -0.01394006, ...,  0.00390149,\n",
       "                        -0.05020611,  0.01596411],\n",
       "                       ...,\n",
       "                       [ 0.01185579, -0.03495461,  0.01480764, ..., -0.04205432,\n",
       "                        -0.02039161, -0.03563129],\n",
       "                       [ 0.04320986, -0.02958493,  0.02765253, ..., -0.03178728,\n",
       "                        -0.09124048, -0.00643804],\n",
       "                       [ 0.0158034 , -0.02507996, -0.00090553, ..., -0.05512653,\n",
       "                         0.03718148, -0.05068055]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "    11: {\n",
       "        attn: {\n",
       "            c_attn: {\n",
       "                bias: Array([ 0.08216132, -0.2787813 ,  0.00240535, ..., -0.02939795,\n",
       "                       -0.04381726,  0.03517448], dtype=float32),\n",
       "                kernel: Array([[-2.3641534e-02,  4.8397236e-02,  7.3503517e-02, ...,\n",
       "                         3.5170823e-02, -1.0740984e-03, -2.9485349e-02],\n",
       "                       [ 4.7159624e-06, -1.1939659e-02,  1.0503781e-01, ...,\n",
       "                        -4.8753638e-02, -1.1644880e-02,  4.2994633e-02],\n",
       "                       [ 3.5593044e-02,  1.1499417e-02, -4.0781781e-02, ...,\n",
       "                        -4.0952768e-02,  3.3861399e-02,  3.0423608e-02],\n",
       "                       ...,\n",
       "                       [ 2.3100436e-02, -6.0298208e-02,  4.7042143e-02, ...,\n",
       "                        -4.1135564e-03,  1.4285636e-02,  1.6399583e-02],\n",
       "                       [ 5.1647082e-02, -1.7622488e-02,  6.6187464e-02, ...,\n",
       "                        -6.4344198e-02,  1.5939150e-02, -3.8249495e-03],\n",
       "                       [ 6.0339592e-02,  1.1173524e-02, -1.8148858e-03, ...,\n",
       "                         1.5407859e-02, -8.2472162e-03, -5.2519396e-02]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([ 0.02843465, -0.02680702, -0.01752011, ...,  0.04422934,\n",
       "                       -0.0533591 , -0.01508961], dtype=float32),\n",
       "                kernel: Array([[-0.07068628, -0.07268307,  0.04269625, ...,  0.00270801,\n",
       "                        -0.02614275, -0.01743949],\n",
       "                       [-0.04725822,  0.04434793,  0.00130237, ...,  0.01302077,\n",
       "                        -0.13991177, -0.02293073],\n",
       "                       [-0.08465846,  0.0723771 ,  0.02100891, ..., -0.01132751,\n",
       "                        -0.00132156,  0.02864205],\n",
       "                       ...,\n",
       "                       [ 0.03447222,  0.02388291, -0.05652814, ..., -0.02078103,\n",
       "                         0.05708794, -0.05843983],\n",
       "                       [ 0.00572036, -0.00387417,  0.0380336 , ..., -0.0357677 ,\n",
       "                         0.0235411 ,  0.07345138],\n",
       "                       [ 0.00492027,  0.05657439, -0.0037644 , ..., -0.00816522,\n",
       "                        -0.07441767, -0.03691623]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "        ln_1: {\n",
       "            bias: Array([-0.04531281, -0.00116194,  0.01328455, ..., -0.08040501,\n",
       "                   -0.03843191, -0.01640207], dtype=float32),\n",
       "            scale: Array([0.5306269 , 0.60082746, 0.59228843, ..., 0.5359313 , 0.57682073,\n",
       "                   0.5358808 ], dtype=float32),\n",
       "        },\n",
       "        ln_2: {\n",
       "            bias: Array([-0.02953761, -0.02844948,  0.00662402, ...,  0.03107951,\n",
       "                   -0.03752177, -0.00972608], dtype=float32),\n",
       "            scale: Array([0.5842558 , 0.6259466 , 0.61913276, ..., 0.60055494, 0.60199314,\n",
       "                   0.5799073 ], dtype=float32),\n",
       "        },\n",
       "        mlp: {\n",
       "            c_fc: {\n",
       "                bias: Array([-0.0224683 , -0.0446638 , -0.02085384, ..., -0.04234136,\n",
       "                       -0.01850928, -0.02669665], dtype=float32),\n",
       "                kernel: Array([[-0.04481823, -0.00666006,  0.0592739 , ...,  0.00427937,\n",
       "                         0.10478002,  0.0703317 ],\n",
       "                       [-0.0267386 , -0.02322425,  0.07347081, ...,  0.07984737,\n",
       "                         0.0534104 ,  0.00641609],\n",
       "                       [-0.05182305, -0.01090039,  0.00767706, ..., -0.05703215,\n",
       "                        -0.02470314,  0.047876  ],\n",
       "                       ...,\n",
       "                       [ 0.02627215, -0.01555202,  0.00571381, ..., -0.11239578,\n",
       "                        -0.09141164, -0.00065436],\n",
       "                       [ 0.03095721,  0.10020607,  0.03333818, ..., -0.05400025,\n",
       "                        -0.02335504, -0.07823371],\n",
       "                       [-0.04139381, -0.04041535, -0.04743649, ...,  0.01311496,\n",
       "                        -0.0444278 ,  0.03646507]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([-0.03138011,  0.01918339, -0.02343526, ...,  0.06360199,\n",
       "                        0.07930812,  0.01002682], dtype=float32),\n",
       "                kernel: Array([[ 0.06328346,  0.04802571,  0.00973613, ..., -0.06457866,\n",
       "                        -0.02343956, -0.04323669],\n",
       "                       [-0.08780432, -0.00079652,  0.01067618, ...,  0.00576174,\n",
       "                        -0.06552052,  0.07537213],\n",
       "                       [-0.04725235,  0.04497549,  0.0088134 , ..., -0.01054425,\n",
       "                         0.00491123, -0.00473899],\n",
       "                       ...,\n",
       "                       [ 0.02598622,  0.02766568,  0.0641607 , ...,  0.04874231,\n",
       "                         0.03094967, -0.04911152],\n",
       "                       [ 0.07454233, -0.01582464,  0.05552405, ...,  0.00572374,\n",
       "                         0.02921151, -0.05030822],\n",
       "                       [-0.02923473,  0.02092226, -0.00599086, ...,  0.06672021,\n",
       "                        -0.03474342,  0.01365133]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "    12: {\n",
       "        attn: {\n",
       "            c_attn: {\n",
       "                bias: Array([ 0.12299426, -0.184287  ,  0.26151222, ..., -0.00683284,\n",
       "                       -0.07544196,  0.00894361], dtype=float32),\n",
       "                kernel: Array([[-0.03474717,  0.00353902, -0.05712533, ..., -0.04756834,\n",
       "                        -0.02430536, -0.02936494],\n",
       "                       [-0.05852483, -0.02157543, -0.03658486, ...,  0.05035137,\n",
       "                         0.0522799 , -0.02588421],\n",
       "                       [ 0.03179704, -0.1149386 ,  0.07995942, ..., -0.03568374,\n",
       "                         0.06074085, -0.04198913],\n",
       "                       ...,\n",
       "                       [ 0.02931324, -0.10709326, -0.00146191, ...,  0.01639125,\n",
       "                         0.00131351,  0.00801613],\n",
       "                       [-0.00024241,  0.04824437,  0.04238468, ..., -0.01612266,\n",
       "                        -0.06915127,  0.01957951],\n",
       "                       [ 0.0381825 ,  0.10879927, -0.02472522, ...,  0.04368649,\n",
       "                        -0.04482374,  0.00803844]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([ 0.03974715, -0.03452854, -0.03154601, ...,  0.01496288,\n",
       "                       -0.04640816, -0.02962504], dtype=float32),\n",
       "                kernel: Array([[-0.01172845,  0.00632814, -0.02107371, ..., -0.01418296,\n",
       "                        -0.00778306, -0.03818242],\n",
       "                       [-0.06466147, -0.0394574 ,  0.02690187, ..., -0.00992361,\n",
       "                        -0.0191968 , -0.00242336],\n",
       "                       [ 0.03623599,  0.03072228, -0.04458829, ..., -0.02639194,\n",
       "                         0.01574786, -0.00121706],\n",
       "                       ...,\n",
       "                       [-0.04471008,  0.02216492, -0.02340258, ...,  0.01504582,\n",
       "                        -0.00557137, -0.00079484],\n",
       "                       [-0.00677561,  0.03572289,  0.03940831, ...,  0.0421639 ,\n",
       "                        -0.01860869,  0.07799532],\n",
       "                       [-0.04963832,  0.03140756,  0.01899813, ..., -0.00927565,\n",
       "                         0.03350029, -0.02922556]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "        ln_1: {\n",
       "            bias: Array([-0.05159141,  0.01105144,  0.00522923, ..., -0.06591412,\n",
       "                   -0.04077315,  0.00055683], dtype=float32),\n",
       "            scale: Array([0.56447566, 0.6292986 , 0.6230969 , ..., 0.5553503 , 0.6110171 ,\n",
       "                   0.54496133], dtype=float32),\n",
       "        },\n",
       "        ln_2: {\n",
       "            bias: Array([-0.02517112, -0.02514378, -0.00839094, ...,  0.04163821,\n",
       "                   -0.03537562, -0.00272218], dtype=float32),\n",
       "            scale: Array([0.5878193 , 0.63076633, 0.6026071 , ..., 0.61274195, 0.5920684 ,\n",
       "                   0.57616824], dtype=float32),\n",
       "        },\n",
       "        mlp: {\n",
       "            c_fc: {\n",
       "                bias: Array([-0.04504516, -0.00571183, -0.0468177 , ..., -0.06165791,\n",
       "                       -0.02765983, -0.01686798], dtype=float32),\n",
       "                kernel: Array([[-0.01947145,  0.06370453, -0.05394315, ...,  0.02050863,\n",
       "                        -0.00283609,  0.09302493],\n",
       "                       [ 0.10826769,  0.01827519,  0.08425028, ...,  0.07435062,\n",
       "                        -0.08223365, -0.03062759],\n",
       "                       [-0.04930572,  0.00732959,  0.05585071, ..., -0.1004809 ,\n",
       "                        -0.11361367,  0.02092138],\n",
       "                       ...,\n",
       "                       [ 0.01292847,  0.01292049, -0.0120545 , ..., -0.06885964,\n",
       "                         0.04187072, -0.00430242],\n",
       "                       [-0.03170065,  0.06560142,  0.04734454, ...,  0.03860266,\n",
       "                         0.04266933,  0.0203819 ],\n",
       "                       [-0.01496349, -0.09963284,  0.08137452, ..., -0.02364421,\n",
       "                         0.0397064 ,  0.0442394 ]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([-0.01845087,  0.0307041 , -0.02624524, ...,  0.05157044,\n",
       "                        0.06732557,  0.01303174], dtype=float32),\n",
       "                kernel: Array([[ 0.00686402, -0.01500038,  0.02175774, ...,  0.0279593 ,\n",
       "                        -0.02731259, -0.08490762],\n",
       "                       [-0.04589384,  0.01333066,  0.01347873, ...,  0.03463618,\n",
       "                        -0.06065419, -0.01927627],\n",
       "                       [ 0.01356318,  0.06413703,  0.13936496, ...,  0.0234638 ,\n",
       "                        -0.01015852,  0.10115299],\n",
       "                       ...,\n",
       "                       [ 0.04954747,  0.01615694,  0.03055972, ...,  0.12346602,\n",
       "                        -0.00590912, -0.01126262],\n",
       "                       [ 0.02965624,  0.00400169, -0.0379669 , ...,  0.07632636,\n",
       "                        -0.0136329 ,  0.02945822],\n",
       "                       [-0.0666199 , -0.00906846, -0.00801489, ..., -0.0254179 ,\n",
       "                        -0.06497089,  0.00219491]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "    13: {\n",
       "        attn: {\n",
       "            c_attn: {\n",
       "                bias: Array([-0.0795717 , -0.03023933, -0.13671741, ..., -0.02698805,\n",
       "                       -0.02192132,  0.01308422], dtype=float32),\n",
       "                kernel: Array([[-0.02415415, -0.02305377, -0.01624553, ...,  0.03782823,\n",
       "                         0.03119259,  0.03190112],\n",
       "                       [ 0.06116689, -0.01990154, -0.08277386, ...,  0.0380396 ,\n",
       "                         0.01675987, -0.04198169],\n",
       "                       [ 0.04433751,  0.02085204,  0.01533541, ...,  0.00381871,\n",
       "                        -0.03204243, -0.03576047],\n",
       "                       ...,\n",
       "                       [-0.01946968, -0.0260176 ,  0.03764519, ...,  0.02787543,\n",
       "                         0.02389436,  0.06573683],\n",
       "                       [ 0.12149373,  0.11523713,  0.04224609, ..., -0.04272938,\n",
       "                         0.02718995,  0.06937455],\n",
       "                       [ 0.08535403,  0.11083972, -0.01973135, ..., -0.02918736,\n",
       "                         0.02367611,  0.02301224]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([ 0.03123099, -0.0347474 , -0.03693533, ...,  0.01940632,\n",
       "                       -0.05731378,  0.00786146], dtype=float32),\n",
       "                kernel: Array([[ 0.01365361, -0.02699938, -0.01121048, ...,  0.02664542,\n",
       "                        -0.00524798,  0.00144671],\n",
       "                       [ 0.04910294, -0.02686666, -0.05135619, ...,  0.12989976,\n",
       "                         0.01530387,  0.03365735],\n",
       "                       [ 0.00187339, -0.069203  ,  0.03804833, ..., -0.01325484,\n",
       "                        -0.05691804,  0.06903437],\n",
       "                       ...,\n",
       "                       [ 0.00219241,  0.0155016 , -0.01194874, ..., -0.0267779 ,\n",
       "                        -0.02892381,  0.01065322],\n",
       "                       [ 0.05508557, -0.0273806 , -0.00090698, ...,  0.00507875,\n",
       "                        -0.07229756, -0.01807385],\n",
       "                       [-0.01618735, -0.04051318, -0.05699953, ...,  0.05299103,\n",
       "                         0.00624676,  0.0539774 ]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "        ln_1: {\n",
       "            bias: Array([-0.05322461,  0.01581346,  0.01472449, ..., -0.06996385,\n",
       "                   -0.0399303 , -0.00205303], dtype=float32),\n",
       "            scale: Array([0.54511493, 0.61186713, 0.5960732 , ..., 0.5309154 , 0.5986662 ,\n",
       "                   0.5449892 ], dtype=float32),\n",
       "        },\n",
       "        ln_2: {\n",
       "            bias: Array([-0.0090737 , -0.0098378 , -0.00285295, ...,  0.01649527,\n",
       "                   -0.02240202, -0.00646661], dtype=float32),\n",
       "            scale: Array([0.5842374 , 0.6113272 , 0.5938304 , ..., 0.600974  , 0.60682285,\n",
       "                   0.55696756], dtype=float32),\n",
       "        },\n",
       "        mlp: {\n",
       "            c_fc: {\n",
       "                bias: Array([-0.02252994,  0.02165669, -0.04036262, ..., -0.01902207,\n",
       "                       -0.04258557, -0.01639398], dtype=float32),\n",
       "                kernel: Array([[-0.0330304 ,  0.03866616,  0.0413758 , ..., -0.03505942,\n",
       "                        -0.0112699 ,  0.04805267],\n",
       "                       [ 0.05069845, -0.05950059,  0.03043535, ..., -0.02239985,\n",
       "                         0.04851473,  0.02236566],\n",
       "                       [-0.11180028,  0.00196735,  0.057693  , ...,  0.04116398,\n",
       "                         0.04358735,  0.01583692],\n",
       "                       ...,\n",
       "                       [-0.03732176, -0.00967757,  0.11824278, ..., -0.02827776,\n",
       "                         0.01647307,  0.0274428 ],\n",
       "                       [-0.1233115 , -0.05199094, -0.00291255, ...,  0.07022577,\n",
       "                        -0.0229232 , -0.07045428],\n",
       "                       [ 0.01138512,  0.05295819,  0.01514796, ...,  0.0168984 ,\n",
       "                         0.00742981, -0.02325214]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([-0.0083001 ,  0.03119227, -0.00175285, ...,  0.06413975,\n",
       "                        0.06854547, -0.00148985], dtype=float32),\n",
       "                kernel: Array([[-0.02870024, -0.01369158, -0.01780003, ..., -0.05608802,\n",
       "                        -0.02154804, -0.0534595 ],\n",
       "                       [-0.03268072,  0.00445412, -0.03081812, ...,  0.00635822,\n",
       "                        -0.0042883 , -0.01849338],\n",
       "                       [-0.01824117,  0.02951688,  0.01239371, ...,  0.05649399,\n",
       "                        -0.02543503,  0.08189747],\n",
       "                       ...,\n",
       "                       [ 0.01664531, -0.03242241, -0.01334182, ...,  0.02023414,\n",
       "                         0.041157  ,  0.01686631],\n",
       "                       [ 0.05035868,  0.07041977,  0.01863884, ..., -0.01447813,\n",
       "                         0.0523393 ,  0.03248092],\n",
       "                       [-0.06847898,  0.02025629, -0.04856956, ..., -0.04566676,\n",
       "                         0.02960534, -0.02913301]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "    14: {\n",
       "        attn: {\n",
       "            c_attn: {\n",
       "                bias: Array([ 0.06453055, -0.01915104, -0.06481297, ...,  0.05680315,\n",
       "                        0.06605668, -0.10764036], dtype=float32),\n",
       "                kernel: Array([[ 0.0082178 ,  0.03946479,  0.07691357, ...,  0.01533983,\n",
       "                        -0.01852934, -0.00318308],\n",
       "                       [-0.07713778,  0.0733575 , -0.1172594 , ..., -0.01787006,\n",
       "                        -0.03583342,  0.05803505],\n",
       "                       [-0.10705855,  0.09321598,  0.01190234, ..., -0.05353371,\n",
       "                         0.02076168, -0.00874316],\n",
       "                       ...,\n",
       "                       [ 0.04930817,  0.00845295, -0.03518984, ..., -0.04027263,\n",
       "                         0.02472023,  0.06573605],\n",
       "                       [-0.0944433 ,  0.00701528, -0.07689777, ..., -0.04721559,\n",
       "                        -0.03774257, -0.05152608],\n",
       "                       [-0.04372505,  0.02582836, -0.04927157, ...,  0.00992404,\n",
       "                         0.01347981,  0.02728703]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([ 0.04850525, -0.00549708, -0.03566486, ...,  0.00599957,\n",
       "                       -0.01606129, -0.00509698], dtype=float32),\n",
       "                kernel: Array([[-0.04593671,  0.00043709, -0.00949151, ..., -0.06699875,\n",
       "                        -0.03052815,  0.05392211],\n",
       "                       [ 0.01529448, -0.01327927,  0.02519834, ..., -0.03133976,\n",
       "                        -0.08716657, -0.06122991],\n",
       "                       [ 0.04940545, -0.04712491,  0.00480456, ...,  0.01158008,\n",
       "                        -0.00265821,  0.01599759],\n",
       "                       ...,\n",
       "                       [-0.07705507, -0.04451011, -0.04477504, ...,  0.01559317,\n",
       "                        -0.06536377, -0.0877334 ],\n",
       "                       [ 0.00800521, -0.01250077,  0.04832309, ...,  0.01541534,\n",
       "                        -0.06269513, -0.0522984 ],\n",
       "                       [ 0.0375923 ,  0.00076821, -0.0057794 , ..., -0.02505491,\n",
       "                        -0.01491661,  0.00698189]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "        ln_1: {\n",
       "            bias: Array([-0.05442251,  0.00884233,  0.01675545, ..., -0.07400322,\n",
       "                   -0.02734251, -0.00244954], dtype=float32),\n",
       "            scale: Array([0.5530903 , 0.5996263 , 0.56951386, ..., 0.5407996 , 0.59488213,\n",
       "                   0.54106164], dtype=float32),\n",
       "        },\n",
       "        ln_2: {\n",
       "            bias: Array([-0.03341951, -0.00097656,  0.00306579, ...,  0.00684461,\n",
       "                   -0.03720633, -0.03209241], dtype=float32),\n",
       "            scale: Array([0.59452784, 0.61324954, 0.59344107, ..., 0.6097162 , 0.58778185,\n",
       "                   0.57439363], dtype=float32),\n",
       "        },\n",
       "        mlp: {\n",
       "            c_fc: {\n",
       "                bias: Array([-0.02596903,  0.00752514, -0.04001932, ..., -0.0031556 ,\n",
       "                       -0.06545924,  0.01854854], dtype=float32),\n",
       "                kernel: Array([[ 0.01970439,  0.05776422, -0.02099072, ...,  0.01006927,\n",
       "                        -0.06289314,  0.01900682],\n",
       "                       [ 0.02754676, -0.03752163, -0.06945028, ..., -0.0042533 ,\n",
       "                         0.00339496, -0.02196901],\n",
       "                       [-0.01518052,  0.00133392, -0.00644156, ..., -0.01894532,\n",
       "                         0.02369686,  0.04718398],\n",
       "                       ...,\n",
       "                       [-0.06997391,  0.01383703, -0.00709193, ..., -0.01212369,\n",
       "                        -0.00975089,  0.08558717],\n",
       "                       [-0.01469772, -0.01597373,  0.02163299, ..., -0.02035598,\n",
       "                         0.04606923, -0.05357502],\n",
       "                       [ 0.01279896, -0.06627542, -0.00702181, ...,  0.05539121,\n",
       "                         0.00491687,  0.03543013]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([ 0.02960618,  0.038238  , -0.02396906, ...,  0.06158499,\n",
       "                        0.06511803, -0.0183966 ], dtype=float32),\n",
       "                kernel: Array([[ 0.04590288, -0.00056524,  0.02073927, ...,  0.02033798,\n",
       "                         0.02227766,  0.01956806],\n",
       "                       [-0.00327815, -0.01458263, -0.02820746, ..., -0.01646391,\n",
       "                         0.00254044,  0.00683721],\n",
       "                       [ 0.00381434,  0.01348058, -0.00685968, ...,  0.0032146 ,\n",
       "                        -0.02214511,  0.00042727],\n",
       "                       ...,\n",
       "                       [-0.04050022,  0.02066861,  0.00814438, ...,  0.00667798,\n",
       "                         0.05995517, -0.01025988],\n",
       "                       [ 0.02139532, -0.02788354, -0.01161102, ..., -0.05661378,\n",
       "                        -0.02020786,  0.0857105 ],\n",
       "                       [ 0.00076356,  0.05848559, -0.03887588, ..., -0.10396075,\n",
       "                         0.04996426, -0.03738281]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "    15: {\n",
       "        attn: {\n",
       "            c_attn: {\n",
       "                bias: Array([ 0.11870369, -0.02603221,  0.07543001, ...,  0.0404244 ,\n",
       "                       -0.01907859,  0.0178868 ], dtype=float32),\n",
       "                kernel: Array([[ 0.01695829, -0.00066185,  0.03068762, ...,  0.0270441 ,\n",
       "                        -0.00045754, -0.00852193],\n",
       "                       [ 0.0132257 ,  0.02347907, -0.02429088, ..., -0.03103915,\n",
       "                        -0.00520239, -0.00128446],\n",
       "                       [-0.02870679, -0.08449481,  0.01134414, ...,  0.03707617,\n",
       "                        -0.03432263,  0.0332634 ],\n",
       "                       ...,\n",
       "                       [-0.01137821,  0.05304015,  0.04867661, ...,  0.00397715,\n",
       "                         0.02665417,  0.0233299 ],\n",
       "                       [-0.01650468,  0.04730506,  0.003199  , ...,  0.05612289,\n",
       "                        -0.03248368, -0.01855962],\n",
       "                       [-0.00614069,  0.00934816, -0.00894008, ...,  0.0605508 ,\n",
       "                        -0.03170545, -0.02124349]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([ 0.06155164, -0.00807524, -0.00353217, ..., -0.02034208,\n",
       "                       -0.04708524,  0.04220957], dtype=float32),\n",
       "                kernel: Array([[ 0.02271142, -0.08923359,  0.10694983, ...,  0.11384722,\n",
       "                         0.07934666, -0.04798901],\n",
       "                       [ 0.11411653, -0.02415942, -0.01147235, ...,  0.08637775,\n",
       "                        -0.05839532,  0.0085742 ],\n",
       "                       [-0.03740076,  0.04529724, -0.01218154, ...,  0.03013829,\n",
       "                        -0.0642398 ,  0.00019037],\n",
       "                       ...,\n",
       "                       [-0.0114224 ,  0.00569625,  0.03726863, ..., -0.00908879,\n",
       "                         0.00070547,  0.02712916],\n",
       "                       [ 0.00974896, -0.00087258, -0.03384773, ...,  0.00219826,\n",
       "                        -0.02480491,  0.00830745],\n",
       "                       [-0.00834204, -0.02182596,  0.02740648, ...,  0.02438982,\n",
       "                        -0.0288036 , -0.04255004]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "        ln_1: {\n",
       "            bias: Array([-0.05903492,  0.02445517,  0.02823275, ..., -0.07865896,\n",
       "                   -0.02088161,  0.00704816], dtype=float32),\n",
       "            scale: Array([0.5908661 , 0.6499046 , 0.61109954, ..., 0.58359843, 0.6140175 ,\n",
       "                   0.57587576], dtype=float32),\n",
       "        },\n",
       "        ln_2: {\n",
       "            bias: Array([-0.02505448,  0.0107836 , -0.01206342, ..., -0.01238604,\n",
       "                   -0.03582573, -0.01571521], dtype=float32),\n",
       "            scale: Array([0.59376204, 0.5953941 , 0.5683013 , ..., 0.5728771 , 0.56655294,\n",
       "                   0.54999816], dtype=float32),\n",
       "        },\n",
       "        mlp: {\n",
       "            c_fc: {\n",
       "                bias: Array([ 0.01761072,  0.00519919, -0.03868632, ..., -0.08128701,\n",
       "                       -0.06210105, -0.03857879], dtype=float32),\n",
       "                kernel: Array([[-0.05338663, -0.07953092,  0.03432579, ...,  0.05949649,\n",
       "                         0.03987937, -0.02754855],\n",
       "                       [ 0.01643579,  0.0344847 ,  0.03582492, ...,  0.05397885,\n",
       "                        -0.01432002,  0.04032346],\n",
       "                       [-0.0389699 ,  0.01989581, -0.00626638, ...,  0.00839486,\n",
       "                        -0.02301051, -0.0220815 ],\n",
       "                       ...,\n",
       "                       [ 0.02679933,  0.0041804 , -0.00459622, ..., -0.07195057,\n",
       "                         0.00034157, -0.00096794],\n",
       "                       [-0.0048221 , -0.0257823 , -0.01225637, ...,  0.0519188 ,\n",
       "                         0.03650193,  0.04320331],\n",
       "                       [-0.02578768, -0.02404713,  0.00246404, ..., -0.03831728,\n",
       "                        -0.02372832,  0.00104902]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([ 0.02591235,  0.03649762, -0.03821463, ...,  0.08037983,\n",
       "                        0.05178582, -0.01730517], dtype=float32),\n",
       "                kernel: Array([[ 0.03926511, -0.06874361,  0.02263625, ...,  0.03199277,\n",
       "                         0.00505315,  0.03155097],\n",
       "                       [ 0.03686678, -0.02852915, -0.0017131 , ..., -0.00764799,\n",
       "                         0.03699066, -0.00104862],\n",
       "                       [-0.00689905,  0.00652242, -0.00095534, ..., -0.02519274,\n",
       "                        -0.02993399,  0.01641581],\n",
       "                       ...,\n",
       "                       [ 0.03164166,  0.03566644, -0.02583097, ...,  0.02206918,\n",
       "                         0.0161422 ,  0.04939253],\n",
       "                       [-0.00365049,  0.05684779,  0.01478396, ..., -0.05772783,\n",
       "                         0.01182117,  0.03102213],\n",
       "                       [-0.03082839, -0.00160683, -0.04926184, ...,  0.0288926 ,\n",
       "                         0.0171868 ,  0.01267503]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "    16: {\n",
       "        attn: {\n",
       "            c_attn: {\n",
       "                bias: Array([ 0.00639181,  0.06072955,  0.05966938, ..., -0.02196232,\n",
       "                        0.02728221, -0.04224031], dtype=float32),\n",
       "                kernel: Array([[-0.14121006, -0.00892309, -0.01498659, ...,  0.08809964,\n",
       "                         0.07396027, -0.01507906],\n",
       "                       [-0.0995715 , -0.02020713, -0.02251327, ..., -0.00812751,\n",
       "                        -0.03500175, -0.04349674],\n",
       "                       [-0.03478828,  0.03832113,  0.06457309, ...,  0.04491388,\n",
       "                        -0.02256962, -0.0189926 ],\n",
       "                       ...,\n",
       "                       [-0.0618427 , -0.04214176, -0.02061741, ...,  0.0025077 ,\n",
       "                        -0.02405658, -0.02064362],\n",
       "                       [ 0.05207313,  0.04275637, -0.14282593, ...,  0.02658203,\n",
       "                         0.06480927, -0.04351247],\n",
       "                       [ 0.10824714,  0.01231172, -0.0449175 , ..., -0.01043625,\n",
       "                        -0.07804974, -0.02235577]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([ 0.01365784, -0.03543274,  0.00737468, ..., -0.03192887,\n",
       "                       -0.05862536, -0.04197381], dtype=float32),\n",
       "                kernel: Array([[ 0.00227618,  0.04423313,  0.03317413, ..., -0.01892107,\n",
       "                         0.03902429, -0.05447616],\n",
       "                       [ 0.0066689 ,  0.00166163,  0.03472001, ..., -0.05876555,\n",
       "                        -0.02620271, -0.03302837],\n",
       "                       [-0.03581866, -0.03326593,  0.02746015, ...,  0.01593625,\n",
       "                         0.05549764,  0.07745385],\n",
       "                       ...,\n",
       "                       [-0.02139808, -0.02243333, -0.0375087 , ...,  0.0061613 ,\n",
       "                        -0.07461679, -0.06118744],\n",
       "                       [ 0.00941363,  0.00187478, -0.0468309 , ..., -0.02702579,\n",
       "                        -0.02003866,  0.11814936],\n",
       "                       [-0.05192096, -0.01904146,  0.01876338, ..., -0.00101269,\n",
       "                        -0.02746689,  0.08060726]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "        ln_1: {\n",
       "            bias: Array([-0.05347373,  0.0197357 ,  0.01911828, ..., -0.06983708,\n",
       "                   -0.03281815,  0.0083595 ], dtype=float32),\n",
       "            scale: Array([0.6288518, 0.6730779, 0.6453713, ..., 0.6248077, 0.6777339,\n",
       "                   0.61138  ], dtype=float32),\n",
       "        },\n",
       "        ln_2: {\n",
       "            bias: Array([-0.03007049,  0.01163231, -0.00316754, ..., -0.01023257,\n",
       "                   -0.03276125, -0.01160805], dtype=float32),\n",
       "            scale: Array([0.5876279 , 0.6149644 , 0.57445943, ..., 0.59050316, 0.5870263 ,\n",
       "                   0.56430227], dtype=float32),\n",
       "        },\n",
       "        mlp: {\n",
       "            c_fc: {\n",
       "                bias: Array([-0.09317587, -0.01175261, -0.08197883, ..., -0.03274189,\n",
       "                       -0.07742744,  0.02005243], dtype=float32),\n",
       "                kernel: Array([[-0.017822  , -0.08517778,  0.01205015, ..., -0.04038245,\n",
       "                         0.00630633, -0.02391509],\n",
       "                       [ 0.00684004,  0.0152402 ,  0.15025815, ..., -0.02750612,\n",
       "                        -0.01904979,  0.01954473],\n",
       "                       [-0.04440805,  0.08195857,  0.03047296, ..., -0.06033703,\n",
       "                         0.00494912,  0.06869334],\n",
       "                       ...,\n",
       "                       [-0.06777727, -0.0594143 , -0.03316203, ..., -0.00835208,\n",
       "                        -0.00824004,  0.03024664],\n",
       "                       [ 0.00645468, -0.06832165, -0.11585022, ..., -0.05398583,\n",
       "                        -0.04268971, -0.03210851],\n",
       "                       [ 0.06808531, -0.00159297,  0.03904677, ..., -0.01439121,\n",
       "                        -0.00242565, -0.05615712]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([ 0.04314801,  0.01328817,  0.00931413, ...,  0.0412062 ,\n",
       "                        0.04105235, -0.01653282], dtype=float32),\n",
       "                kernel: Array([[ 0.04773744,  0.05275173, -0.01161371, ..., -0.00400976,\n",
       "                        -0.05444683, -0.03394293],\n",
       "                       [ 0.03553684,  0.0043891 , -0.01890667, ...,  0.0093612 ,\n",
       "                         0.04311431, -0.02186408],\n",
       "                       [-0.06437965,  0.03343188, -0.01551422, ..., -0.00938171,\n",
       "                         0.0149162 , -0.05418832],\n",
       "                       ...,\n",
       "                       [ 0.01126252,  0.0188484 ,  0.01573417, ...,  0.00117915,\n",
       "                         0.07920576,  0.02808164],\n",
       "                       [-0.00771779, -0.00489788,  0.04154193, ..., -0.01699074,\n",
       "                        -0.00913087, -0.02376481],\n",
       "                       [ 0.02335511, -0.04917582, -0.02138946, ..., -0.09690929,\n",
       "                         0.06635803,  0.0830724 ]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "    17: {\n",
       "        attn: {\n",
       "            c_attn: {\n",
       "                bias: Array([ 0.00071998, -0.01613391, -0.17948712, ...,  0.03203903,\n",
       "                       -0.03187186, -0.02652574], dtype=float32),\n",
       "                kernel: Array([[-0.0694878 ,  0.00511119,  0.0235035 , ...,  0.05141085,\n",
       "                         0.06567886, -0.01100306],\n",
       "                       [-0.02267662,  0.02891707, -0.05175071, ..., -0.01247945,\n",
       "                         0.04179609, -0.01529089],\n",
       "                       [-0.0218662 ,  0.07674875,  0.00438768, ...,  0.070268  ,\n",
       "                        -0.04421805,  0.07775529],\n",
       "                       ...,\n",
       "                       [ 0.02389856,  0.07066046,  0.02549063, ..., -0.02283295,\n",
       "                         0.00716813,  0.0054342 ],\n",
       "                       [-0.02551269,  0.05618586, -0.01834482, ...,  0.05318658,\n",
       "                         0.01886856, -0.05218965],\n",
       "                       [ 0.00437198, -0.0746797 , -0.05115125, ..., -0.04718084,\n",
       "                         0.04188555,  0.01378343]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([ 0.03710582,  0.01488926,  0.00043902, ...,  0.01430085,\n",
       "                       -0.06104692,  0.00816788], dtype=float32),\n",
       "                kernel: Array([[-0.00104211, -0.06221245, -0.0392938 , ...,  0.01794017,\n",
       "                         0.03631407, -0.02966659],\n",
       "                       [-0.03845032, -0.01819961, -0.07782465, ..., -0.05829426,\n",
       "                         0.06949405,  0.07311673],\n",
       "                       [ 0.09464583, -0.02653394, -0.00236862, ...,  0.0115894 ,\n",
       "                        -0.01325264, -0.04875922],\n",
       "                       ...,\n",
       "                       [ 0.05194234, -0.08182575, -0.00753003, ..., -0.10167006,\n",
       "                         0.05943133, -0.02249562],\n",
       "                       [-0.00864504,  0.02910644,  0.01934505, ...,  0.02609634,\n",
       "                         0.03283202, -0.07679246],\n",
       "                       [-0.11790969,  0.00981039, -0.03934215, ...,  0.05205064,\n",
       "                        -0.0783403 ,  0.13516563]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "        ln_1: {\n",
       "            bias: Array([-0.06407583,  0.01826599,  0.02924397, ..., -0.06410074,\n",
       "                   -0.03086299,  0.015144  ], dtype=float32),\n",
       "            scale: Array([0.6298144 , 0.68957406, 0.6504488 , ..., 0.6105818 , 0.67192054,\n",
       "                   0.62316364], dtype=float32),\n",
       "        },\n",
       "        ln_2: {\n",
       "            bias: Array([-0.0216234 ,  0.02913268, -0.00479058, ...,  0.0118608 ,\n",
       "                   -0.03834556, -0.00860099], dtype=float32),\n",
       "            scale: Array([0.5796966 , 0.57898664, 0.56945974, ..., 0.58569205, 0.5745175 ,\n",
       "                   0.561906  ], dtype=float32),\n",
       "        },\n",
       "        mlp: {\n",
       "            c_fc: {\n",
       "                bias: Array([-0.09649502, -0.0619862 , -0.01133945, ..., -0.03724038,\n",
       "                       -0.04673901, -0.0683657 ], dtype=float32),\n",
       "                kernel: Array([[-0.00823311, -0.05463004,  0.01058197, ..., -0.02467003,\n",
       "                         0.00305868, -0.07250676],\n",
       "                       [ 0.02088449,  0.00608623,  0.00769907, ...,  0.00042661,\n",
       "                        -0.0362816 , -0.02317362],\n",
       "                       [ 0.12649634,  0.01536449, -0.00515037, ...,  0.01656415,\n",
       "                        -0.0811836 ,  0.00608859],\n",
       "                       ...,\n",
       "                       [-0.13625021, -0.07646053, -0.02296142, ...,  0.01003534,\n",
       "                        -0.0302237 ,  0.00240231],\n",
       "                       [-0.00840722, -0.09415565, -0.08553265, ...,  0.08099767,\n",
       "                        -0.03769673, -0.02334525],\n",
       "                       [ 0.01470582,  0.07074888,  0.04022543, ...,  0.01751145,\n",
       "                         0.01721232,  0.02392718]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([ 0.0412831 , -0.00320452,  0.00179836, ...,  0.07294285,\n",
       "                        0.082392  ,  0.00344256], dtype=float32),\n",
       "                kernel: Array([[ 0.07221501,  0.0411965 ,  0.05427493, ..., -0.07199755,\n",
       "                         0.03508595, -0.01981303],\n",
       "                       [ 0.03732076,  0.06074315, -0.04898985, ...,  0.05305368,\n",
       "                        -0.07415018, -0.00991256],\n",
       "                       [ 0.02742233, -0.00054666, -0.01818961, ...,  0.03069664,\n",
       "                        -0.09340369, -0.06589653],\n",
       "                       ...,\n",
       "                       [-0.05096033,  0.06271947, -0.22732338, ..., -0.04441112,\n",
       "                         0.05656873, -0.00853197],\n",
       "                       [-0.02999182,  0.01816451, -0.03870193, ...,  0.04861374,\n",
       "                        -0.06708219, -0.06374143],\n",
       "                       [-0.04031462, -0.00538038,  0.03670885, ...,  0.00683587,\n",
       "                        -0.00513926, -0.05965139]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "    18: {\n",
       "        attn: {\n",
       "            c_attn: {\n",
       "                bias: Array([-0.03233382,  0.07745958, -0.03822937, ..., -0.03616275,\n",
       "                       -0.021165  ,  0.06062965], dtype=float32),\n",
       "                kernel: Array([[ 3.0407999e-02,  1.8394211e-02,  9.6509792e-02, ...,\n",
       "                        -3.9072759e-02, -1.3507064e-02,  4.0177632e-02],\n",
       "                       [-5.7680145e-02, -3.0793375e-03,  5.0896484e-02, ...,\n",
       "                         2.9108694e-02, -2.5975533e-02, -5.2714191e-02],\n",
       "                       [-2.7893297e-02,  2.2674371e-02,  3.2461122e-02, ...,\n",
       "                         6.1742823e-05, -3.8120244e-02, -1.1454638e-02],\n",
       "                       ...,\n",
       "                       [ 1.1341175e-02, -7.8231379e-02, -2.1751937e-03, ...,\n",
       "                         1.4846125e-02, -3.3902250e-02,  4.6803441e-02],\n",
       "                       [-5.3758495e-02,  5.9577718e-02,  1.2541381e-02, ...,\n",
       "                         1.3532378e-01,  5.7842318e-02, -8.4579736e-02],\n",
       "                       [-8.2068294e-03, -6.5364979e-02,  4.3709178e-02, ...,\n",
       "                         5.1707204e-02, -8.0014452e-02, -9.3990557e-02]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([ 0.03836748,  0.00192512, -0.00065614, ...,  0.04117418,\n",
       "                       -0.0691195 , -0.02233579], dtype=float32),\n",
       "                kernel: Array([[ 2.5510391e-02, -4.1760501e-02,  1.3402016e-01, ...,\n",
       "                         6.1267562e-02, -9.9420995e-03, -1.4646873e-02],\n",
       "                       [-9.1755413e-02, -2.8666025e-02,  5.2615952e-02, ...,\n",
       "                        -4.2940147e-02,  1.7408522e-02, -1.7211799e-01],\n",
       "                       [-2.8677123e-02, -1.4123706e-02,  6.8909168e-02, ...,\n",
       "                        -6.6422679e-02, -2.2093365e-02,  1.2281426e-01],\n",
       "                       ...,\n",
       "                       [-1.2834480e-03, -4.2936806e-02,  9.5716128e-03, ...,\n",
       "                        -8.5431755e-02, -2.3096746e-02, -1.9065773e-02],\n",
       "                       [-3.7113376e-02,  4.9143482e-02, -4.4096813e-02, ...,\n",
       "                         5.8362964e-03, -4.5485295e-02, -8.6950190e-02],\n",
       "                       [-1.2783100e-01,  6.8593904e-02,  3.2267184e-03, ...,\n",
       "                        -1.6092842e-04,  4.0718983e-03,  5.1430274e-02]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "        ln_1: {\n",
       "            bias: Array([-0.06216381,  0.02386804,  0.03016873, ..., -0.06646825,\n",
       "                   -0.01983959,  0.02264861], dtype=float32),\n",
       "            scale: Array([0.59219944, 0.66387606, 0.6154    , ..., 0.59571314, 0.66366434,\n",
       "                   0.61156833], dtype=float32),\n",
       "        },\n",
       "        ln_2: {\n",
       "            bias: Array([-0.01863284,  0.00807315,  0.01065316, ...,  0.0028079 ,\n",
       "                   -0.02941851, -0.00976996], dtype=float32),\n",
       "            scale: Array([0.5722739 , 0.5828761 , 0.55774754, ..., 0.56788266, 0.56449395,\n",
       "                   0.5504753 ], dtype=float32),\n",
       "        },\n",
       "        mlp: {\n",
       "            c_fc: {\n",
       "                bias: Array([-0.04495087, -0.03363988, -0.05435307, ...,  0.00876744,\n",
       "                       -0.00586004, -0.05331377], dtype=float32),\n",
       "                kernel: Array([[ 0.02842892, -0.09737471,  0.03395555, ...,  0.01507122,\n",
       "                        -0.0724307 , -0.03969477],\n",
       "                       [-0.01098673,  0.01364964,  0.01262944, ..., -0.03378221,\n",
       "                        -0.04665889, -0.055772  ],\n",
       "                       [ 0.00729746, -0.06209824,  0.02972732, ...,  0.00695733,\n",
       "                        -0.01541193,  0.00510645],\n",
       "                       ...,\n",
       "                       [-0.01090001, -0.02025939,  0.01477377, ..., -0.03985728,\n",
       "                         0.01705639, -0.04491648],\n",
       "                       [-0.00615723, -0.02805091, -0.04349489, ...,  0.00481636,\n",
       "                         0.05273592, -0.02314354],\n",
       "                       [ 0.06126055, -0.02600664, -0.02648555, ...,  0.00684697,\n",
       "                         0.02039047,  0.08230286]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([ 0.06682042,  0.06823798, -0.01295821, ...,  0.09248681,\n",
       "                        0.08932009,  0.00507187], dtype=float32),\n",
       "                kernel: Array([[ 0.00407092, -0.05898391,  0.0477321 , ..., -0.00181254,\n",
       "                         0.02609907,  0.0282247 ],\n",
       "                       [ 0.07703639, -0.07665151, -0.03274092, ..., -0.05748272,\n",
       "                        -0.00126754,  0.0217904 ],\n",
       "                       [-0.0569947 ,  0.01343   , -0.03147991, ..., -0.00778714,\n",
       "                        -0.00879625,  0.06349468],\n",
       "                       ...,\n",
       "                       [-0.01057037, -0.02121291, -0.03304506, ...,  0.01668421,\n",
       "                        -0.00672757, -0.00491053],\n",
       "                       [ 0.04757726,  0.04712413,  0.04192546, ..., -0.01226471,\n",
       "                        -0.03992967,  0.01124191],\n",
       "                       [ 0.0274004 , -0.01945384, -0.03179833, ..., -0.01578506,\n",
       "                         0.00120665,  0.09154343]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "    19: {\n",
       "        attn: {\n",
       "            c_attn: {\n",
       "                bias: Array([-0.0401274 ,  0.02901323,  0.02661335, ...,  0.03527719,\n",
       "                        0.03490432, -0.00405614], dtype=float32),\n",
       "                kernel: Array([[ 0.00019005, -0.01780804,  0.01688051, ...,  0.03356944,\n",
       "                        -0.01647487,  0.03101015],\n",
       "                       [-0.03453924,  0.01184113,  0.02187199, ..., -0.01548764,\n",
       "                        -0.02145131,  0.00272494],\n",
       "                       [ 0.03299376,  0.04914204,  0.03558766, ..., -0.01664197,\n",
       "                        -0.0267653 , -0.01266161],\n",
       "                       ...,\n",
       "                       [-0.02907104,  0.02744838, -0.04279735, ...,  0.01865334,\n",
       "                         0.01540189,  0.06154625],\n",
       "                       [-0.05565092,  0.02885303, -0.01284176, ...,  0.05337159,\n",
       "                         0.0785459 ,  0.0371832 ],\n",
       "                       [-0.00336347,  0.00087457, -0.04056559, ...,  0.02463733,\n",
       "                         0.03168684, -0.01386188]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([ 0.00739841,  0.02291334,  0.03135526, ..., -0.02526294,\n",
       "                       -0.08598684,  0.00910766], dtype=float32),\n",
       "                kernel: Array([[-0.02760983,  0.01559678,  0.02064831, ...,  0.04466895,\n",
       "                        -0.05330049,  0.01965371],\n",
       "                       [-0.03091451,  0.0044714 , -0.01187557, ..., -0.00932265,\n",
       "                        -0.00053786, -0.02449882],\n",
       "                       [-0.08042342,  0.02896799,  0.07027695, ...,  0.04520261,\n",
       "                        -0.01590837, -0.01211134],\n",
       "                       ...,\n",
       "                       [ 0.0560341 , -0.01195883,  0.00218084, ..., -0.00977546,\n",
       "                        -0.01980843, -0.03382503],\n",
       "                       [ 0.00727131, -0.02252855,  0.07645997, ..., -0.0041907 ,\n",
       "                        -0.03566907, -0.00203299],\n",
       "                       [ 0.08552386, -0.02970634, -0.02223345, ..., -0.02467391,\n",
       "                         0.05569396, -0.05212208]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "        ln_1: {\n",
       "            bias: Array([-0.05598013,  0.02725057,  0.02715684, ..., -0.04546311,\n",
       "                   -0.01908566,  0.02465198], dtype=float32),\n",
       "            scale: Array([0.650397  , 0.72466475, 0.661052  , ..., 0.62169325, 0.6870737 ,\n",
       "                   0.6077282 ], dtype=float32),\n",
       "        },\n",
       "        ln_2: {\n",
       "            bias: Array([-0.01278549,  0.0238925 , -0.00551667, ..., -0.00365973,\n",
       "                   -0.04121811,  0.01098477], dtype=float32),\n",
       "            scale: Array([0.5876468 , 0.5796239 , 0.56266105, ..., 0.5752572 , 0.56829894,\n",
       "                   0.55298626], dtype=float32),\n",
       "        },\n",
       "        mlp: {\n",
       "            c_fc: {\n",
       "                bias: Array([-0.03712488, -0.00483959,  0.01888742, ...,  0.011094  ,\n",
       "                       -0.00535347, -0.0355282 ], dtype=float32),\n",
       "                kernel: Array([[-0.04898314, -0.08533806, -0.03784874, ...,  0.02164795,\n",
       "                         0.05382745,  0.03733215],\n",
       "                       [-0.02420981, -0.1133064 , -0.06353888, ...,  0.02515594,\n",
       "                         0.06566998,  0.01373051],\n",
       "                       [-0.02058152, -0.06859663,  0.00588943, ..., -0.00716065,\n",
       "                        -0.04048412, -0.02344779],\n",
       "                       ...,\n",
       "                       [ 0.04016468, -0.03408762, -0.00724133, ...,  0.0544406 ,\n",
       "                        -0.06537099,  0.02472853],\n",
       "                       [ 0.01692286, -0.06482238, -0.02149581, ..., -0.0129512 ,\n",
       "                         0.03318821, -0.10786003],\n",
       "                       [ 0.08248215,  0.05786666, -0.01419573, ..., -0.03428407,\n",
       "                        -0.02426228, -0.02005746]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([ 0.07625817,  0.05946717,  0.00856928, ...,  0.09098279,\n",
       "                        0.08216641, -0.00985437], dtype=float32),\n",
       "                kernel: Array([[ 0.00731881,  0.04035351,  0.01534439, ..., -0.0646629 ,\n",
       "                        -0.0477616 , -0.05656299],\n",
       "                       [ 0.03477873,  0.1079493 ,  0.09343147, ...,  0.03663556,\n",
       "                         0.07801089,  0.02330495],\n",
       "                       [ 0.02753427,  0.03135337, -0.02987991, ..., -0.00368082,\n",
       "                         0.05333987,  0.07087154],\n",
       "                       ...,\n",
       "                       [-0.00865622, -0.02876641,  0.05867368, ..., -0.05917093,\n",
       "                         0.01006178, -0.01005119],\n",
       "                       [-0.04463806, -0.05206011,  0.03110574, ...,  0.0919769 ,\n",
       "                         0.02313102, -0.00586023],\n",
       "                       [ 0.01945604, -0.01669936,  0.04248785, ..., -0.01013781,\n",
       "                        -0.07510587,  0.08671254]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "    2: {\n",
       "        attn: {\n",
       "            c_attn: {\n",
       "                bias: Array([-0.0037225 ,  0.15930444,  0.2573417 , ...,  0.01887068,\n",
       "                        0.02606794, -0.01109411], dtype=float32),\n",
       "                kernel: Array([[ 0.10980776, -0.05454362,  0.06166609, ..., -0.02192924,\n",
       "                        -0.00167117,  0.00989037],\n",
       "                       [-0.1300498 ,  0.04957176,  0.1084214 , ...,  0.01965105,\n",
       "                        -0.00574821, -0.01381285],\n",
       "                       [-0.07457639,  0.1452709 ,  0.03950999, ..., -0.01450731,\n",
       "                        -0.00142423, -0.0572903 ],\n",
       "                       ...,\n",
       "                       [-0.00406595, -0.11489747, -0.01400878, ...,  0.02475112,\n",
       "                        -0.02712691,  0.02461493],\n",
       "                       [ 0.01723258,  0.02160291,  0.05585353, ...,  0.05609249,\n",
       "                         0.01758058, -0.01602298],\n",
       "                       [ 0.15218931,  0.04726291,  0.04153112, ..., -0.01238774,\n",
       "                        -0.01113807, -0.00501612]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([-0.04071192,  0.01917247, -0.02407753, ...,  0.03696973,\n",
       "                        0.04916125,  0.03314025], dtype=float32),\n",
       "                kernel: Array([[-0.04255762, -0.02730135,  0.00847522, ...,  0.00544292,\n",
       "                         0.01536868, -0.05019118],\n",
       "                       [-0.04553721, -0.05731921,  0.00875549, ...,  0.01654473,\n",
       "                         0.01737421, -0.04814966],\n",
       "                       [-0.01763841, -0.03783564,  0.03197577, ...,  0.04299101,\n",
       "                        -0.02586422,  0.0567428 ],\n",
       "                       ...,\n",
       "                       [ 0.00252835, -0.02596243,  0.00869395, ..., -0.00131449,\n",
       "                        -0.00879907,  0.02687705],\n",
       "                       [ 0.00436422, -0.03937696, -0.00431576, ...,  0.02424904,\n",
       "                        -0.02043504,  0.01080302],\n",
       "                       [ 0.03086645,  0.00300224, -0.0052103 , ..., -0.05171622,\n",
       "                        -0.02391203,  0.01910842]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "        ln_1: {\n",
       "            bias: Array([-0.05427139, -0.04227303, -0.01204938, ..., -0.1097537 ,\n",
       "                   -0.038862  , -0.05855361], dtype=float32),\n",
       "            scale: Array([0.43257567, 0.39508218, 0.40698084, ..., 0.38481307, 0.39379725,\n",
       "                   0.36387727], dtype=float32),\n",
       "        },\n",
       "        ln_2: {\n",
       "            bias: Array([-0.07686795, -0.08015061,  0.04440914, ..., -0.01351157,\n",
       "                    0.04127807,  0.02596069], dtype=float32),\n",
       "            scale: Array([0.5488988 , 0.61129797, 0.5718824 , ..., 0.5403103 , 0.5449772 ,\n",
       "                   0.53253084], dtype=float32),\n",
       "        },\n",
       "        mlp: {\n",
       "            c_fc: {\n",
       "                bias: Array([-0.03184173, -0.04254674, -0.03903516, ..., -0.0456565 ,\n",
       "                       -0.03783035, -0.05818734], dtype=float32),\n",
       "                kernel: Array([[ 0.00361701, -0.06078826,  0.05067868, ..., -0.01659531,\n",
       "                        -0.02866374, -0.01075793],\n",
       "                       [-0.00833721,  0.04185065,  0.00857772, ...,  0.05733208,\n",
       "                         0.02134639,  0.06363723],\n",
       "                       [ 0.03327534, -0.03287534,  0.07850912, ...,  0.10681123,\n",
       "                         0.06799982, -0.01180568],\n",
       "                       ...,\n",
       "                       [-0.02717165, -0.00975675,  0.01812913, ..., -0.07019605,\n",
       "                        -0.04283171,  0.0146985 ],\n",
       "                       [ 0.01525042,  0.04374615,  0.05969503, ..., -0.07781681,\n",
       "                         0.0394103 , -0.02346448],\n",
       "                       [ 0.01869788, -0.0071525 ,  0.01756276, ...,  0.03227198,\n",
       "                        -0.04091116, -0.00450289]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([-0.00074415, -0.05791308,  0.00324737, ...,  0.02690194,\n",
       "                        0.06472035,  0.01768493], dtype=float32),\n",
       "                kernel: Array([[-0.01464489, -0.04455912,  0.03853075, ..., -0.01765415,\n",
       "                         0.00988826,  0.03015346],\n",
       "                       [-0.08239687, -0.02611499, -0.00619018, ..., -0.01965606,\n",
       "                         0.04808074,  0.07970835],\n",
       "                       [ 0.01335014,  0.04332064,  0.08835677, ...,  0.02516834,\n",
       "                         0.01328493, -0.05045637],\n",
       "                       ...,\n",
       "                       [ 0.00113865, -0.04141659,  0.04169558, ..., -0.0497547 ,\n",
       "                        -0.05698247,  0.0104723 ],\n",
       "                       [-0.02441913,  0.04126502,  0.04025186, ..., -0.04302768,\n",
       "                         0.02664223,  0.04661097],\n",
       "                       [-0.01738968, -0.00408405,  0.01639312, ..., -0.01587048,\n",
       "                        -0.01712016,  0.00548111]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "    20: {\n",
       "        attn: {\n",
       "            c_attn: {\n",
       "                bias: Array([ 0.01694792,  0.25098097, -0.01565121, ..., -0.0442786 ,\n",
       "                       -0.03422501,  0.03552524], dtype=float32),\n",
       "                kernel: Array([[-0.11303853, -0.01801516, -0.05364752, ...,  0.02596514,\n",
       "                        -0.03330162, -0.01328234],\n",
       "                       [-0.01926287, -0.00692138, -0.02730438, ..., -0.04742912,\n",
       "                        -0.00709859,  0.11016206],\n",
       "                       [ 0.01291378, -0.19345266,  0.01798847, ..., -0.03162902,\n",
       "                         0.07761317,  0.01734852],\n",
       "                       ...,\n",
       "                       [-0.08219276, -0.02380607,  0.01715587, ...,  0.00927377,\n",
       "                        -0.03492774, -0.10055889],\n",
       "                       [-0.09597934,  0.06721583,  0.14177917, ...,  0.03236132,\n",
       "                         0.02051562, -0.0313058 ],\n",
       "                       [ 0.10796029, -0.03339291,  0.01325663, ..., -0.03116154,\n",
       "                        -0.0257631 , -0.1254568 ]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([ 0.00546844,  0.03630459, -0.00679724, ...,  0.01221455,\n",
       "                       -0.02134251,  0.0009127 ], dtype=float32),\n",
       "                kernel: Array([[ 0.09136143, -0.00123633, -0.02957047, ..., -0.01012535,\n",
       "                         0.09409264, -0.01312061],\n",
       "                       [ 0.07805918,  0.0677435 , -0.00615222, ...,  0.00591185,\n",
       "                        -0.04079337,  0.02202663],\n",
       "                       [-0.06705396, -0.0067831 , -0.04866545, ...,  0.04210012,\n",
       "                        -0.01610059, -0.07472175],\n",
       "                       ...,\n",
       "                       [ 0.00049526, -0.00284597, -0.03479579, ...,  0.07484704,\n",
       "                        -0.04543231, -0.06221571],\n",
       "                       [-0.01176717,  0.01669964, -0.01998932, ...,  0.10027952,\n",
       "                        -0.01809239,  0.08352344],\n",
       "                       [-0.09155133,  0.04719589, -0.02609931, ..., -0.04179786,\n",
       "                         0.02131862,  0.02980467]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "        ln_1: {\n",
       "            bias: Array([-0.05866297,  0.01507726,  0.02595815, ..., -0.04927147,\n",
       "                   -0.00802293,  0.04432119], dtype=float32),\n",
       "            scale: Array([0.6244476 , 0.7059541 , 0.63809097, ..., 0.62281626, 0.6580885 ,\n",
       "                   0.6227776 ], dtype=float32),\n",
       "        },\n",
       "        ln_2: {\n",
       "            bias: Array([-0.01811656,  0.04352317,  0.01986388, ...,  0.00480953,\n",
       "                   -0.01794394,  0.02052977], dtype=float32),\n",
       "            scale: Array([0.58224165, 0.590063  , 0.5733985 , ..., 0.5819521 , 0.5731372 ,\n",
       "                   0.56433916], dtype=float32),\n",
       "        },\n",
       "        mlp: {\n",
       "            c_fc: {\n",
       "                bias: Array([-0.01999176, -0.00733295, -0.043868  , ..., -0.06010745,\n",
       "                       -0.00078688, -0.05141452], dtype=float32),\n",
       "                kernel: Array([[-0.00231617, -0.02797228, -0.06634542, ..., -0.0361655 ,\n",
       "                        -0.03228201,  0.02439502],\n",
       "                       [-0.06764221,  0.03553   , -0.06718896, ...,  0.08257642,\n",
       "                         0.04516501, -0.00756475],\n",
       "                       [ 0.02321498, -0.00643497, -0.04870152, ..., -0.02624433,\n",
       "                        -0.00062786,  0.05844492],\n",
       "                       ...,\n",
       "                       [-0.01873857, -0.01909558, -0.04877323, ..., -0.07106341,\n",
       "                        -0.02916137, -0.0415982 ],\n",
       "                       [ 0.099681  , -0.04383387,  0.06836814, ..., -0.03194322,\n",
       "                        -0.09354743, -0.04406539],\n",
       "                       [ 0.04532565,  0.08614028,  0.05856068, ..., -0.02840687,\n",
       "                        -0.03381018,  0.00993332]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([ 0.07221841,  0.03157946, -0.00932815, ...,  0.06394753,\n",
       "                        0.07385833, -0.01289019], dtype=float32),\n",
       "                kernel: Array([[-0.03662813,  0.01541935, -0.04143616, ..., -0.05305426,\n",
       "                        -0.01860558, -0.04538614],\n",
       "                       [-0.00110671,  0.01975891, -0.04098935, ..., -0.02479427,\n",
       "                         0.02761779, -0.06827421],\n",
       "                       [ 0.02724246, -0.05777422,  0.02446338, ...,  0.04539379,\n",
       "                        -0.01752306,  0.00993565],\n",
       "                       ...,\n",
       "                       [-0.05994576,  0.06832061,  0.01235818, ..., -0.02685789,\n",
       "                        -0.04197541,  0.04750784],\n",
       "                       [ 0.02499192, -0.00436813,  0.02475943, ..., -0.02596772,\n",
       "                         0.01855617, -0.01372047],\n",
       "                       [ 0.09309506, -0.02400766,  0.06013433, ...,  0.03298204,\n",
       "                         0.05421961,  0.03052552]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "    21: {\n",
       "        attn: {\n",
       "            c_attn: {\n",
       "                bias: Array([ 0.02919974, -0.01221279, -0.11400568, ..., -0.03394534,\n",
       "                        0.00427628,  0.0153122 ], dtype=float32),\n",
       "                kernel: Array([[ 0.02844671,  0.09301382, -0.02017182, ...,  0.04533322,\n",
       "                         0.0702251 , -0.06500772],\n",
       "                       [-0.10619182, -0.06613749,  0.03753158, ..., -0.00134225,\n",
       "                         0.04943746,  0.02158347],\n",
       "                       [ 0.03830815,  0.0241031 ,  0.02541382, ..., -0.05271902,\n",
       "                         0.00438013, -0.02362193],\n",
       "                       ...,\n",
       "                       [-0.05457362,  0.00593679,  0.008295  , ..., -0.06388327,\n",
       "                         0.01010463,  0.00418582],\n",
       "                       [-0.07509951,  0.03588685,  0.00244437, ...,  0.02015472,\n",
       "                         0.0060806 , -0.00505623],\n",
       "                       [ 0.03455823,  0.02554026, -0.0640228 , ...,  0.02396362,\n",
       "                        -0.01011332, -0.04399174]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([ 0.01630458,  0.01890018, -0.03412191, ...,  0.02236038,\n",
       "                       -0.02232495,  0.00437316], dtype=float32),\n",
       "                kernel: Array([[ 0.03948795, -0.03785078, -0.01536541, ...,  0.0208698 ,\n",
       "                         0.07667107,  0.09581617],\n",
       "                       [ 0.00387049, -0.04527057, -0.06537642, ...,  0.01654273,\n",
       "                         0.07249746, -0.01933064],\n",
       "                       [ 0.00670753,  0.07786912,  0.03051073, ..., -0.03202053,\n",
       "                         0.03838456, -0.00117142],\n",
       "                       ...,\n",
       "                       [-0.00702715, -0.05630141, -0.07491843, ..., -0.04713988,\n",
       "                         0.07683658,  0.12342802],\n",
       "                       [ 0.05887094,  0.011359  ,  0.13479567, ...,  0.02035609,\n",
       "                         0.04081103, -0.06730566],\n",
       "                       [ 0.0104434 ,  0.00578225, -0.00243008, ...,  0.04907991,\n",
       "                         0.00637176,  0.0784311 ]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "        ln_1: {\n",
       "            bias: Array([-0.04871175,  0.02247001,  0.01290948, ..., -0.05466871,\n",
       "                   -0.01394036,  0.05167119], dtype=float32),\n",
       "            scale: Array([0.6034055 , 0.6730703 , 0.6188555 , ..., 0.61805576, 0.6372762 ,\n",
       "                   0.5989497 ], dtype=float32),\n",
       "        },\n",
       "        ln_2: {\n",
       "            bias: Array([-0.00757353,  0.03367659,  0.00477509, ..., -0.01054952,\n",
       "                   -0.02696247, -0.0167887 ], dtype=float32),\n",
       "            scale: Array([0.596448  , 0.600347  , 0.57950664, ..., 0.5904556 , 0.58764654,\n",
       "                   0.57420874], dtype=float32),\n",
       "        },\n",
       "        mlp: {\n",
       "            c_fc: {\n",
       "                bias: Array([-0.02089267, -0.03561738, -0.02525663, ..., -0.00969913,\n",
       "                       -0.0203202 , -0.04599214], dtype=float32),\n",
       "                kernel: Array([[-0.00504305, -0.05604221, -0.00181415, ..., -0.03897604,\n",
       "                        -0.03967102, -0.03027343],\n",
       "                       [-0.01916372, -0.0152874 ,  0.05617457, ..., -0.02618344,\n",
       "                         0.04377534, -0.01673732],\n",
       "                       [-0.02615963,  0.00479415,  0.01352873, ...,  0.02595214,\n",
       "                         0.05427505,  0.03058844],\n",
       "                       ...,\n",
       "                       [ 0.0179693 , -0.10039305, -0.00379706, ..., -0.0444751 ,\n",
       "                         0.05734526,  0.05574265],\n",
       "                       [ 0.10179993, -0.00086252,  0.02332641, ..., -0.0215953 ,\n",
       "                        -0.00341649,  0.01167666],\n",
       "                       [ 0.03486129,  0.01836153,  0.05000818, ..., -0.00681704,\n",
       "                        -0.022394  , -0.08277243]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([ 0.09261163,  0.00975318, -0.01558575, ...,  0.07571046,\n",
       "                        0.05401323, -0.02973478], dtype=float32),\n",
       "                kernel: Array([[-0.02022143,  0.00569107,  0.01175001, ...,  0.03252093,\n",
       "                        -0.06632023, -0.09724167],\n",
       "                       [ 0.00825289, -0.02581469, -0.03202711, ...,  0.05768035,\n",
       "                        -0.09794624,  0.0032318 ],\n",
       "                       [-0.01296987,  0.03839521, -0.04518783, ...,  0.03441418,\n",
       "                         0.00296795,  0.01897391],\n",
       "                       ...,\n",
       "                       [ 0.05119143,  0.02853582, -0.0477458 , ..., -0.00184995,\n",
       "                         0.02550353, -0.00109104],\n",
       "                       [ 0.11769976,  0.07796347, -0.01574976, ...,  0.01689333,\n",
       "                        -0.00228433,  0.05129116],\n",
       "                       [-0.02756833,  0.01577945, -0.00915658, ...,  0.0395131 ,\n",
       "                         0.01029188, -0.00063493]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "    22: {\n",
       "        attn: {\n",
       "            c_attn: {\n",
       "                bias: Array([ 0.13607493,  0.04685204, -0.04391244, ...,  0.01492716,\n",
       "                        0.01846233,  0.03275092], dtype=float32),\n",
       "                kernel: Array([[ 0.07872644,  0.01023771, -0.04312853, ..., -0.04642517,\n",
       "                        -0.03421288,  0.11493006],\n",
       "                       [ 0.02485411,  0.08548222,  0.07861849, ..., -0.00758659,\n",
       "                        -0.03166668,  0.00284876],\n",
       "                       [ 0.0014311 , -0.01269848,  0.00912594, ...,  0.05239115,\n",
       "                        -0.07837898, -0.01828803],\n",
       "                       ...,\n",
       "                       [ 0.04342844, -0.02462738,  0.03599352, ...,  0.01139068,\n",
       "                         0.06779574, -0.02455051],\n",
       "                       [-0.01145856,  0.03130099, -0.05822335, ..., -0.00712848,\n",
       "                        -0.04774257, -0.02911753],\n",
       "                       [ 0.01411857,  0.06960575, -0.01569333, ...,  0.01524067,\n",
       "                        -0.08108055, -0.03409178]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([ 0.00239929,  0.01294487,  0.01235972, ..., -0.00968236,\n",
       "                       -0.04503226, -0.05384244], dtype=float32),\n",
       "                kernel: Array([[ 0.08977881,  0.04142887,  0.10564359, ..., -0.05420395,\n",
       "                        -0.02767182, -0.0130657 ],\n",
       "                       [ 0.06843825, -0.0279256 , -0.02500243, ...,  0.04295657,\n",
       "                         0.03840125,  0.0001663 ],\n",
       "                       [ 0.04114043,  0.00044415,  0.04865029, ..., -0.01580736,\n",
       "                         0.0384939 , -0.0372007 ],\n",
       "                       ...,\n",
       "                       [ 0.07426982,  0.00960989, -0.02316997, ...,  0.01558032,\n",
       "                        -0.03408793, -0.05864759],\n",
       "                       [-0.00157117, -0.09032485, -0.05675702, ...,  0.10281228,\n",
       "                         0.01582431,  0.06869458],\n",
       "                       [-0.02996021, -0.04363362, -0.01398348, ..., -0.15164858,\n",
       "                         0.03406266,  0.02994627]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "        ln_1: {\n",
       "            bias: Array([-0.04531379,  0.03045487,  0.02616123, ..., -0.04850341,\n",
       "                   -0.01495279,  0.05896061], dtype=float32),\n",
       "            scale: Array([0.6230692 , 0.66806275, 0.6317619 , ..., 0.603238  , 0.6581266 ,\n",
       "                   0.5909449 ], dtype=float32),\n",
       "        },\n",
       "        ln_2: {\n",
       "            bias: Array([-0.02087952,  0.03995658, -0.01470069, ...,  0.00895961,\n",
       "                   -0.03156648, -0.00585172], dtype=float32),\n",
       "            scale: Array([0.60836226, 0.59570354, 0.6063196 , ..., 0.6099843 , 0.60674405,\n",
       "                   0.59255886], dtype=float32),\n",
       "        },\n",
       "        mlp: {\n",
       "            c_fc: {\n",
       "                bias: Array([-0.0570433 , -0.02322671, -0.06342912, ..., -0.00341037,\n",
       "                       -0.00786042, -0.01386776], dtype=float32),\n",
       "                kernel: Array([[ 0.08982569,  0.01895569, -0.03554734, ..., -0.00922282,\n",
       "                         0.01708793,  0.02811556],\n",
       "                       [ 0.074959  ,  0.00425424,  0.02895497, ...,  0.02839677,\n",
       "                         0.05904635,  0.00651906],\n",
       "                       [ 0.06275684,  0.03412596,  0.00227118, ..., -0.01528389,\n",
       "                        -0.028851  ,  0.05223334],\n",
       "                       ...,\n",
       "                       [-0.02999853, -0.01299154,  0.00085046, ..., -0.0227606 ,\n",
       "                        -0.06462733, -0.01680464],\n",
       "                       [ 0.03627067, -0.0451975 ,  0.06351455, ..., -0.00237602,\n",
       "                         0.0405568 , -0.04717528],\n",
       "                       [-0.02556182, -0.02516484,  0.01838954, ..., -0.01576437,\n",
       "                        -0.0267796 , -0.0571578 ]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([ 0.08661888,  0.02154408,  0.00231346, ...,  0.09936658,\n",
       "                        0.04432339, -0.03243301], dtype=float32),\n",
       "                kernel: Array([[ 0.09761712,  0.0380118 ,  0.01022819, ...,  0.00331025,\n",
       "                         0.03995302,  0.0357035 ],\n",
       "                       [-0.01547683,  0.03588755, -0.01004461, ..., -0.0039545 ,\n",
       "                         0.03064988,  0.05496456],\n",
       "                       [ 0.04384137, -0.0028001 ,  0.08869299, ...,  0.05640132,\n",
       "                         0.07671471,  0.05096716],\n",
       "                       ...,\n",
       "                       [ 0.00238317, -0.03219098,  0.05088168, ...,  0.0495422 ,\n",
       "                        -0.00387203, -0.07834072],\n",
       "                       [-0.00187271, -0.08689595, -0.0548289 , ...,  0.041515  ,\n",
       "                        -0.04509289, -0.02262975],\n",
       "                       [ 0.03674988,  0.0355045 , -0.0894437 , ...,  0.00412325,\n",
       "                         0.00772006, -0.02226596]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "    23: {\n",
       "        attn: {\n",
       "            c_attn: {\n",
       "                bias: Array([ 0.01130435, -0.2119545 , -0.06985862, ...,  0.00220974,\n",
       "                       -0.00682779, -0.01599673], dtype=float32),\n",
       "                kernel: Array([[-0.05319105,  0.01753275,  0.0068251 , ...,  0.08997379,\n",
       "                         0.03709013, -0.05603239],\n",
       "                       [-0.03606088, -0.0673921 ,  0.03333364, ...,  0.0083128 ,\n",
       "                        -0.05825535,  0.03620552],\n",
       "                       [ 0.00045205,  0.03135101, -0.06476827, ...,  0.07201437,\n",
       "                        -0.00928433,  0.0358778 ],\n",
       "                       ...,\n",
       "                       [ 0.10220575,  0.03422525,  0.13289107, ...,  0.05318826,\n",
       "                        -0.0109406 ,  0.01089965],\n",
       "                       [-0.05208635, -0.05785751,  0.03448314, ...,  0.02890046,\n",
       "                        -0.02564199, -0.01917307],\n",
       "                       [-0.02310997, -0.09195558,  0.02649854, ..., -0.01156144,\n",
       "                         0.03046608, -0.01276849]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([ 0.02220725,  0.04424297,  0.01857724, ...,  0.0359815 ,\n",
       "                       -0.0053433 ,  0.01506631], dtype=float32),\n",
       "                kernel: Array([[-0.02952477, -0.00846766,  0.07088155, ..., -0.0234778 ,\n",
       "                        -0.01688745,  0.02147029],\n",
       "                       [ 0.001619  ,  0.01171794,  0.05283532, ...,  0.11499456,\n",
       "                        -0.14075033, -0.02134434],\n",
       "                       [ 0.11324086,  0.00467748, -0.04864896, ...,  0.012159  ,\n",
       "                        -0.01168178,  0.00792744],\n",
       "                       ...,\n",
       "                       [-0.04661903,  0.00098595, -0.00937891, ..., -0.08157411,\n",
       "                        -0.03293565,  0.09749755],\n",
       "                       [ 0.00115191,  0.0698342 , -0.04090013, ...,  0.00431963,\n",
       "                        -0.02148944,  0.0063989 ],\n",
       "                       [ 0.08280032, -0.03542862, -0.02088439, ...,  0.03997981,\n",
       "                         0.08258989,  0.0454039 ]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "        ln_1: {\n",
       "            bias: Array([-0.03856424,  0.02757837,  0.02446362, ..., -0.04247794,\n",
       "                   -0.00295823,  0.05280547], dtype=float32),\n",
       "            scale: Array([0.58749133, 0.6352261 , 0.6042309 , ..., 0.5993141 , 0.6150768 ,\n",
       "                   0.5879631 ], dtype=float32),\n",
       "        },\n",
       "        ln_2: {\n",
       "            bias: Array([-0.01005258,  0.05768003, -0.01568844, ...,  0.00984851,\n",
       "                   -0.02073039,  0.00820559], dtype=float32),\n",
       "            scale: Array([0.6124049, 0.6115721, 0.6185084, ..., 0.6059691, 0.6108979,\n",
       "                   0.5885283], dtype=float32),\n",
       "        },\n",
       "        mlp: {\n",
       "            c_fc: {\n",
       "                bias: Array([-0.02993259, -0.01956174, -0.02127114, ..., -0.06169824,\n",
       "                       -0.008979  , -0.06398452], dtype=float32),\n",
       "                kernel: Array([[-0.06166868, -0.04657903, -0.02274296, ..., -0.022193  ,\n",
       "                        -0.0436533 , -0.03043951],\n",
       "                       [-0.07992615,  0.07589023,  0.08089419, ..., -0.03614556,\n",
       "                        -0.00356165,  0.07402747],\n",
       "                       [ 0.0163006 ,  0.05898637,  0.0924417 , ..., -0.06690408,\n",
       "                         0.0406982 ,  0.03552123],\n",
       "                       ...,\n",
       "                       [ 0.09782213, -0.00053469,  0.04059136, ..., -0.05366432,\n",
       "                        -0.02707705, -0.04793151],\n",
       "                       [ 0.00866576, -0.01542873,  0.01160415, ..., -0.04350932,\n",
       "                         0.01651531, -0.00725376],\n",
       "                       [ 0.0398337 ,  0.0047906 , -0.03044674, ..., -0.04213767,\n",
       "                        -0.02560407,  0.00473585]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([ 0.10084744,  0.02022708,  0.02151616, ...,  0.0892951 ,\n",
       "                        0.06733526, -0.03571665], dtype=float32),\n",
       "                kernel: Array([[ 0.04985581,  0.07883004, -0.00901213, ...,  0.02571049,\n",
       "                        -0.06257552,  0.02362835],\n",
       "                       [ 0.00954937, -0.03026714,  0.06135548, ...,  0.09132899,\n",
       "                        -0.01781857, -0.02898302],\n",
       "                       [-0.04250561, -0.03366736, -0.05901612, ..., -0.03372746,\n",
       "                        -0.09077298,  0.05186401],\n",
       "                       ...,\n",
       "                       [-0.09106388,  0.02234585, -0.01804745, ...,  0.01363148,\n",
       "                        -0.14233747, -0.04362331],\n",
       "                       [ 0.02952355, -0.01800693, -0.0233512 , ...,  0.05100125,\n",
       "                        -0.01204858,  0.04575884],\n",
       "                       [ 0.09953583, -0.01731489, -0.04036103, ...,  0.01293761,\n",
       "                        -0.01477395,  0.05601399]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "    24: {\n",
       "        attn: {\n",
       "            c_attn: {\n",
       "                bias: Array([-0.08682323, -0.08953819, -0.11071985, ...,  0.02331354,\n",
       "                       -0.02578703,  0.04642415], dtype=float32),\n",
       "                kernel: Array([[-4.0798085e-03, -6.6940702e-02, -6.5720603e-02, ...,\n",
       "                        -7.0099615e-02,  3.3964656e-02,  5.5221796e-02],\n",
       "                       [-2.8782269e-02, -4.1684538e-02, -4.9125995e-02, ...,\n",
       "                        -7.9411842e-02,  2.2540517e-02,  2.0979846e-02],\n",
       "                       [-2.6679351e-03, -3.1292882e-02,  4.7914028e-02, ...,\n",
       "                         2.1068621e-02,  2.3961950e-03, -1.4893824e-02],\n",
       "                       ...,\n",
       "                       [-3.9574956e-03,  1.2713085e-02,  6.2645577e-02, ...,\n",
       "                         4.3617687e-03,  7.6970235e-02, -4.0249113e-02],\n",
       "                       [-1.7912544e-02, -4.8080739e-05, -1.7821465e-02, ...,\n",
       "                         3.1842146e-02,  3.2799296e-02, -7.5935595e-02],\n",
       "                       [-8.6035738e-03, -8.1000246e-02,  1.6519738e-02, ...,\n",
       "                        -1.4105981e-02, -2.5064223e-03,  3.2830898e-02]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([ 0.00306068, -0.0101853 , -0.01169661, ...,  0.02975926,\n",
       "                       -0.03308051, -0.03953887], dtype=float32),\n",
       "                kernel: Array([[ 4.7471199e-02, -1.3141521e-03,  8.4509835e-02, ...,\n",
       "                        -1.1610147e-01,  4.9873631e-02, -3.4062959e-02],\n",
       "                       [-8.3750807e-02, -2.7741704e-02, -5.0398293e-03, ...,\n",
       "                        -1.0410378e-01, -2.3173122e-02,  7.5347371e-02],\n",
       "                       [-6.4737700e-02, -4.6096630e-02,  5.3840637e-02, ...,\n",
       "                         1.3343090e-02,  4.4627659e-02,  2.5758801e-02],\n",
       "                       ...,\n",
       "                       [-4.9841043e-02, -6.6350900e-02, -5.4778200e-05, ...,\n",
       "                         4.8151039e-02,  2.1904401e-02,  8.0025112e-03],\n",
       "                       [-2.1928551e-03,  1.7220614e-02, -4.7714639e-02, ...,\n",
       "                         7.5748138e-02,  1.2565204e-02, -1.7223077e-02],\n",
       "                       [ 6.8119869e-02,  1.6709473e-02, -2.5535058e-02, ...,\n",
       "                         8.4734987e-04, -4.8272781e-02,  2.6017347e-02]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "        ln_1: {\n",
       "            bias: Array([-0.07041842,  0.03658365,  0.03611098, ..., -0.05139793,\n",
       "                   -0.00183388,  0.06711528], dtype=float32),\n",
       "            scale: Array([0.60152185, 0.6454774 , 0.60627806, ..., 0.6035101 , 0.6446214 ,\n",
       "                   0.5669173 ], dtype=float32),\n",
       "        },\n",
       "        ln_2: {\n",
       "            bias: Array([ 0.0007526 ,  0.03722879, -0.00329777, ...,  0.01269235,\n",
       "                   -0.03723563, -0.00786825], dtype=float32),\n",
       "            scale: Array([0.63392276, 0.6322577 , 0.6232098 , ..., 0.6090939 , 0.6040574 ,\n",
       "                   0.60642153], dtype=float32),\n",
       "        },\n",
       "        mlp: {\n",
       "            c_fc: {\n",
       "                bias: Array([-0.01518947, -0.02644247,  0.03825267, ..., -0.0180012 ,\n",
       "                       -0.03271184,  0.23103924], dtype=float32),\n",
       "                kernel: Array([[ 0.06258313,  0.05570807,  0.039972  , ..., -0.02027707,\n",
       "                        -0.04625286, -0.02190025],\n",
       "                       [ 0.04280059,  0.04065907, -0.00347291, ...,  0.09130964,\n",
       "                         0.02542553, -0.03375586],\n",
       "                       [ 0.07635804, -0.00301646, -0.01825454, ...,  0.04780808,\n",
       "                         0.10534018, -0.01884848],\n",
       "                       ...,\n",
       "                       [ 0.05052608, -0.00749221, -0.05530138, ...,  0.00047893,\n",
       "                        -0.02239023,  0.02722043],\n",
       "                       [-0.10669386,  0.03108924, -0.06048281, ..., -0.04183437,\n",
       "                         0.02208386, -0.01503669],\n",
       "                       [ 0.0834569 , -0.03601144, -0.01764772, ..., -0.0458272 ,\n",
       "                         0.04223731, -0.0397881 ]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([ 0.09988715,  0.02506278, -0.04435882, ...,  0.1153741 ,\n",
       "                        0.05896715, -0.04909685], dtype=float32),\n",
       "                kernel: Array([[-1.11183882e-01,  4.88946959e-02, -1.15311965e-01, ...,\n",
       "                        -4.33988310e-03,  1.76954921e-02, -1.37121037e-01],\n",
       "                       [-2.27758605e-02, -6.11481853e-02, -9.47163068e-03, ...,\n",
       "                        -2.91282265e-03, -2.92960275e-02,  5.79026081e-02],\n",
       "                       [ 3.55743580e-02,  7.20156636e-03,  3.32421181e-03, ...,\n",
       "                         8.35759056e-06,  1.95386410e-02,  1.37276798e-01],\n",
       "                       ...,\n",
       "                       [ 3.13811600e-02, -4.04134616e-02,  4.68873186e-04, ...,\n",
       "                        -9.16434750e-02,  1.35253882e-02,  1.46682132e-02],\n",
       "                       [-4.44362946e-02, -3.01277749e-02,  3.00026070e-02, ...,\n",
       "                        -9.66222305e-03,  8.51506889e-02, -9.66528058e-02],\n",
       "                       [ 7.65936822e-03,  1.00845076e-01, -3.23497243e-02, ...,\n",
       "                         4.23948169e-02,  6.60993978e-02,  2.48202272e-02]],      dtype=float32),\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "    25: {\n",
       "        attn: {\n",
       "            c_attn: {\n",
       "                bias: Array([-0.1289455 ,  0.16330567, -0.13653997, ..., -0.02351029,\n",
       "                        0.02553339, -0.00962968], dtype=float32),\n",
       "                kernel: Array([[-0.04226483,  0.00967922, -0.00736656, ...,  0.00826818,\n",
       "                         0.07587086,  0.08316439],\n",
       "                       [ 0.08340012,  0.0466021 , -0.02631287, ...,  0.00098422,\n",
       "                         0.01323479,  0.03120746],\n",
       "                       [-0.02413506, -0.01285716,  0.06582233, ...,  0.02804967,\n",
       "                        -0.02344988, -0.02174537],\n",
       "                       ...,\n",
       "                       [-0.01796046,  0.04168903,  0.01571544, ..., -0.03382203,\n",
       "                         0.03717886, -0.06103807],\n",
       "                       [-0.00199184,  0.04865253,  0.02830883, ...,  0.03022796,\n",
       "                        -0.10839099, -0.00991654],\n",
       "                       [-0.02101414,  0.00481257, -0.08193987, ...,  0.02314355,\n",
       "                        -0.06680232,  0.03654501]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([ 0.04510463, -0.0124182 ,  0.02549286, ...,  0.04824359,\n",
       "                       -0.02837574, -0.05003877], dtype=float32),\n",
       "                kernel: Array([[ 2.0352980e-02,  4.5279372e-02,  2.2953384e-02, ...,\n",
       "                         3.7086832e-03, -1.1105346e-02, -1.7830441e-02],\n",
       "                       [ 8.6942568e-02, -9.9768089e-03, -7.8985408e-02, ...,\n",
       "                         4.2044472e-02,  3.5176031e-02,  6.7568459e-02],\n",
       "                       [ 1.8315267e-02,  3.8303226e-02, -5.6982595e-02, ...,\n",
       "                         6.8408191e-02,  8.0332816e-02,  5.2971609e-02],\n",
       "                       ...,\n",
       "                       [ 7.6855890e-02,  7.6475409e-03,  9.0712821e-03, ...,\n",
       "                        -8.5192136e-02,  6.7820218e-03,  2.3423731e-02],\n",
       "                       [ 1.2482508e-02, -3.5793406e-03, -6.0341194e-02, ...,\n",
       "                         5.5297349e-02, -5.3664122e-02, -2.4174204e-02],\n",
       "                       [ 2.8141361e-02,  4.9107555e-02, -5.9210039e-03, ...,\n",
       "                        -2.9841131e-02,  1.2767939e-02, -8.4757041e-05]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "        ln_1: {\n",
       "            bias: Array([-0.03921745,  0.02636211,  0.01889313, ..., -0.03588245,\n",
       "                   -0.00611736,  0.0573645 ], dtype=float32),\n",
       "            scale: Array([0.63787705, 0.6559116 , 0.63281626, ..., 0.61730695, 0.6296161 ,\n",
       "                   0.56823313], dtype=float32),\n",
       "        },\n",
       "        ln_2: {\n",
       "            bias: Array([-0.00521318,  0.06340391, -0.00695922, ..., -0.00719447,\n",
       "                   -0.02020623,  0.00540914], dtype=float32),\n",
       "            scale: Array([0.6383911 , 0.63081783, 0.63396037, ..., 0.62248564, 0.6175139 ,\n",
       "                   0.60810435], dtype=float32),\n",
       "        },\n",
       "        mlp: {\n",
       "            c_fc: {\n",
       "                bias: Array([-0.0530381 , -0.03362967, -0.00787082, ..., -0.00289591,\n",
       "                       -0.05509384, -0.01189748], dtype=float32),\n",
       "                kernel: Array([[-0.04979947, -0.01980531, -0.04885153, ..., -0.02901112,\n",
       "                         0.08301324, -0.0631896 ],\n",
       "                       [-0.00124944, -0.03650594,  0.04416089, ..., -0.06746771,\n",
       "                         0.00181281, -0.00386533],\n",
       "                       [-0.03025898, -0.05494162, -0.07810567, ...,  0.02740075,\n",
       "                        -0.010994  ,  0.01122028],\n",
       "                       ...,\n",
       "                       [ 0.05347668,  0.00393496, -0.05030884, ...,  0.00608242,\n",
       "                        -0.02283068, -0.03247952],\n",
       "                       [-0.01647436,  0.03838442,  0.03212191, ...,  0.04711544,\n",
       "                        -0.01209802, -0.01548866],\n",
       "                       [-0.00412397, -0.00648593, -0.06445888, ..., -0.05515492,\n",
       "                        -0.00255188,  0.01997395]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([ 0.10919188,  0.01121176, -0.02566492, ...,  0.09167251,\n",
       "                        0.06151072, -0.04206697], dtype=float32),\n",
       "                kernel: Array([[ 0.02792775,  0.03400238, -0.00532731, ..., -0.06215054,\n",
       "                        -0.03930965, -0.00450816],\n",
       "                       [ 0.0168865 ,  0.08554682, -0.10881495, ...,  0.03189874,\n",
       "                        -0.07873329,  0.02678603],\n",
       "                       [ 0.05588805, -0.06132621,  0.0125571 , ..., -0.08130085,\n",
       "                         0.03474858,  0.03805121],\n",
       "                       ...,\n",
       "                       [ 0.10883   ,  0.07253934,  0.01150866, ..., -0.00345478,\n",
       "                        -0.00423129,  0.00084098],\n",
       "                       [-0.00892446, -0.0263825 , -0.03558468, ..., -0.02195606,\n",
       "                        -0.00128071, -0.02007642],\n",
       "                       [ 0.02374345, -0.05495197, -0.01534608, ...,  0.02014706,\n",
       "                         0.011052  ,  0.02925046]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "    26: {\n",
       "        attn: {\n",
       "            c_attn: {\n",
       "                bias: Array([ 0.02581429, -0.05454099,  0.00436157, ..., -0.0349655 ,\n",
       "                       -0.00665687, -0.05161881], dtype=float32),\n",
       "                kernel: Array([[ 0.02244196,  0.02434135, -0.01557714, ...,  0.02720675,\n",
       "                        -0.06495118, -0.04963401],\n",
       "                       [-0.02757564, -0.03397835, -0.03644016, ...,  0.04092177,\n",
       "                        -0.07341589,  0.02504244],\n",
       "                       [-0.07903367,  0.01988593, -0.03886601, ...,  0.07283146,\n",
       "                         0.04240632, -0.01659592],\n",
       "                       ...,\n",
       "                       [-0.00771886, -0.00648043,  0.00413921, ...,  0.02936266,\n",
       "                         0.02465579,  0.00196146],\n",
       "                       [ 0.06376086, -0.08960963, -0.05332879, ...,  0.08281332,\n",
       "                         0.03815353, -0.04164173],\n",
       "                       [-0.0655084 , -0.04425504, -0.01144423, ..., -0.03820125,\n",
       "                         0.05517291, -0.05927392]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([ 0.01554102,  0.02720675,  0.05152647, ...,  0.03434435,\n",
       "                       -0.02765088, -0.04317724], dtype=float32),\n",
       "                kernel: Array([[ 0.03706594,  0.0112928 , -0.03322989, ...,  0.02793203,\n",
       "                         0.03547444,  0.05720019],\n",
       "                       [ 0.00545072,  0.0283393 ,  0.05348562, ..., -0.08307636,\n",
       "                        -0.09272406, -0.03739393],\n",
       "                       [ 0.03684866, -0.00839204, -0.01648543, ...,  0.02982544,\n",
       "                        -0.01030634, -0.00968889],\n",
       "                       ...,\n",
       "                       [-0.0045019 , -0.07963221, -0.01779494, ..., -0.04812842,\n",
       "                        -0.01823154,  0.03654918],\n",
       "                       [ 0.02950233,  0.05435333, -0.06562749, ..., -0.02976582,\n",
       "                         0.00025267,  0.01827693],\n",
       "                       [-0.00689772,  0.01836124, -0.03657914, ..., -0.01536883,\n",
       "                        -0.01173077,  0.04103055]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "        ln_1: {\n",
       "            bias: Array([-0.06901766,  0.04800751,  0.04390771, ..., -0.03014532,\n",
       "                   -0.01849931,  0.09053411], dtype=float32),\n",
       "            scale: Array([0.62477386, 0.6582557 , 0.6385177 , ..., 0.6309743 , 0.6441703 ,\n",
       "                   0.5812812 ], dtype=float32),\n",
       "        },\n",
       "        ln_2: {\n",
       "            bias: Array([-0.02031913,  0.06555955, -0.00822894, ...,  0.01335153,\n",
       "                   -0.03249934,  0.02670768], dtype=float32),\n",
       "            scale: Array([0.659243  , 0.64845353, 0.65309596, ..., 0.6191399 , 0.62382764,\n",
       "                   0.61132747], dtype=float32),\n",
       "        },\n",
       "        mlp: {\n",
       "            c_fc: {\n",
       "                bias: Array([-0.00633441, -0.04594286, -0.02174013, ..., -0.04559875,\n",
       "                       -0.03158432, -0.00711211], dtype=float32),\n",
       "                kernel: Array([[-0.03183161, -0.0299914 , -0.00205787, ..., -0.06204181,\n",
       "                        -0.02145538,  0.0526646 ],\n",
       "                       [ 0.02356382,  0.03149422,  0.0396849 , ...,  0.03640375,\n",
       "                         0.03741847,  0.07865856],\n",
       "                       [ 0.0429712 ,  0.05447725,  0.08667465, ...,  0.00490768,\n",
       "                         0.01216048,  0.02898181],\n",
       "                       ...,\n",
       "                       [-0.03673457,  0.07216199, -0.05016424, ...,  0.00367197,\n",
       "                         0.02676814, -0.00631639],\n",
       "                       [-0.04069392,  0.02792463, -0.01425844, ..., -0.07295031,\n",
       "                        -0.01980137,  0.07057261],\n",
       "                       [ 0.06424533,  0.03303708, -0.00665926, ..., -0.00391456,\n",
       "                         0.00112222,  0.07107647]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([ 0.1244736 ,  0.01406779, -0.03167156, ...,  0.10849836,\n",
       "                        0.07519187, -0.08478455], dtype=float32),\n",
       "                kernel: Array([[-0.01968852,  0.04497705, -0.03997092, ...,  0.11892828,\n",
       "                        -0.04230844,  0.0415731 ],\n",
       "                       [ 0.09489341,  0.03460022, -0.03469254, ..., -0.15056716,\n",
       "                         0.02452694,  0.01104123],\n",
       "                       [ 0.01909725,  0.00264112, -0.0293805 , ..., -0.04516771,\n",
       "                         0.02065708,  0.0632309 ],\n",
       "                       ...,\n",
       "                       [-0.02065447, -0.05794155, -0.02304376, ...,  0.05574768,\n",
       "                         0.01659188, -0.04844369],\n",
       "                       [ 0.02511849,  0.06121323, -0.02173042, ..., -0.00254218,\n",
       "                         0.08363768,  0.02662364],\n",
       "                       [-0.00209621, -0.13314883, -0.0625385 , ...,  0.01462454,\n",
       "                        -0.0718931 , -0.06971475]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "    27: {\n",
       "        attn: {\n",
       "            c_attn: {\n",
       "                bias: Array([ 0.18031748, -0.03621631,  0.04615216, ..., -0.01316749,\n",
       "                        0.01838915,  0.03005741], dtype=float32),\n",
       "                kernel: Array([[ 0.09107968, -0.01154158, -0.04174169, ..., -0.00518121,\n",
       "                         0.00610641, -0.00322865],\n",
       "                       [ 0.08234366, -0.03017472, -0.04114359, ...,  0.0464556 ,\n",
       "                         0.01406244,  0.01993613],\n",
       "                       [-0.0029447 ,  0.01008877,  0.03627313, ..., -0.00706738,\n",
       "                         0.03087416,  0.01078075],\n",
       "                       ...,\n",
       "                       [ 0.0137574 ,  0.06666136, -0.08058833, ..., -0.01218237,\n",
       "                        -0.03574141,  0.01473121],\n",
       "                       [ 0.07159632, -0.01518889, -0.01170235, ...,  0.04352067,\n",
       "                        -0.00790837, -0.01977403],\n",
       "                       [-0.06641539,  0.00587102,  0.0272095 , ..., -0.00843361,\n",
       "                         0.02857258, -0.0168533 ]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([-0.0437433 , -0.00789087,  0.01361091, ...,  0.01327209,\n",
       "                        0.00980487, -0.02389253], dtype=float32),\n",
       "                kernel: Array([[-0.02128172, -0.00767041,  0.02922211, ...,  0.01179373,\n",
       "                         0.10493954,  0.05735696],\n",
       "                       [-0.03369264, -0.01253813, -0.0074418 , ..., -0.06458379,\n",
       "                         0.02519838,  0.00335785],\n",
       "                       [ 0.04339097,  0.01884186, -0.04292892, ...,  0.0015187 ,\n",
       "                         0.02408279, -0.04888967],\n",
       "                       ...,\n",
       "                       [ 0.01483284,  0.03718988, -0.02335863, ..., -0.01113205,\n",
       "                         0.06920952,  0.03004962],\n",
       "                       [ 0.13422854, -0.07996015, -0.01691975, ...,  0.00721085,\n",
       "                        -0.00744147, -0.08529509],\n",
       "                       [-0.01042583,  0.08435161,  0.01266286, ..., -0.03900534,\n",
       "                        -0.04061443, -0.09002167]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "        ln_1: {\n",
       "            bias: Array([-0.03935993,  0.04210049,  0.03791028, ..., -0.01414481,\n",
       "                    0.00725579,  0.08701499], dtype=float32),\n",
       "            scale: Array([0.64697015, 0.6598356 , 0.6296415 , ..., 0.6235519 , 0.63929147,\n",
       "                   0.5605473 ], dtype=float32),\n",
       "        },\n",
       "        ln_2: {\n",
       "            bias: Array([ 0.0142786 ,  0.04832748,  0.00169814, ...,  0.02434055,\n",
       "                   -0.02847543,  0.02292089], dtype=float32),\n",
       "            scale: Array([0.68103963, 0.66046387, 0.6647597 , ..., 0.6455879 , 0.6442979 ,\n",
       "                   0.63077784], dtype=float32),\n",
       "        },\n",
       "        mlp: {\n",
       "            c_fc: {\n",
       "                bias: Array([-0.03138945, -0.02544568,  0.02454551, ..., -0.07833876,\n",
       "                       -0.03669316, -0.00373337], dtype=float32),\n",
       "                kernel: Array([[-0.01572742, -0.0072501 ,  0.06276424, ...,  0.02060526,\n",
       "                        -0.00532918,  0.0071026 ],\n",
       "                       [-0.01332407,  0.00877468,  0.04324963, ...,  0.04668441,\n",
       "                         0.021214  ,  0.10060051],\n",
       "                       [-0.09169116, -0.05342892,  0.02303477, ..., -0.01233622,\n",
       "                        -0.04687798,  0.01470434],\n",
       "                       ...,\n",
       "                       [ 0.02295444, -0.02797161, -0.01148873, ..., -0.01321255,\n",
       "                        -0.0499148 , -0.03617289],\n",
       "                       [ 0.064367  ,  0.03254566, -0.00423425, ...,  0.00764993,\n",
       "                        -0.00751952,  0.01903526],\n",
       "                       [-0.00466183, -0.00439861, -0.04890677, ...,  0.00661942,\n",
       "                        -0.0386942 ,  0.02449425]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([ 0.13186419,  0.03070578, -0.02087319, ...,  0.11900023,\n",
       "                        0.08503728, -0.06235469], dtype=float32),\n",
       "                kernel: Array([[ 0.00961129,  0.06459115, -0.0057068 , ...,  0.04327742,\n",
       "                         0.03207821,  0.01733139],\n",
       "                       [ 0.02803318,  0.01142326,  0.09936376, ...,  0.11124674,\n",
       "                        -0.03095932,  0.02084947],\n",
       "                       [ 0.04780394,  0.01632296, -0.00124211, ...,  0.07517614,\n",
       "                        -0.00166773, -0.00552338],\n",
       "                       ...,\n",
       "                       [ 0.12412778,  0.07669675,  0.04671932, ...,  0.18074535,\n",
       "                         0.02515819,  0.02037663],\n",
       "                       [ 0.02932805, -0.04011674,  0.08285222, ...,  0.0535056 ,\n",
       "                        -0.10065029, -0.03230719],\n",
       "                       [ 0.00644633, -0.18921001,  0.00765976, ...,  0.01420581,\n",
       "                         0.01696899,  0.01759938]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "    28: {\n",
       "        attn: {\n",
       "            c_attn: {\n",
       "                bias: Array([-0.0029152 , -0.03091265,  0.09329583, ..., -0.03354475,\n",
       "                        0.02203763, -0.00267745], dtype=float32),\n",
       "                kernel: Array([[ 0.00706738,  0.09748875,  0.0009915 , ...,  0.02441038,\n",
       "                        -0.0593266 ,  0.0642813 ],\n",
       "                       [ 0.04088077,  0.00228497,  0.03690389, ..., -0.0298638 ,\n",
       "                        -0.01181031, -0.04552187],\n",
       "                       [-0.04400874, -0.03202424, -0.01202633, ...,  0.03101915,\n",
       "                         0.02184749,  0.01237838],\n",
       "                       ...,\n",
       "                       [-0.06035401,  0.06210288, -0.01766469, ..., -0.08617727,\n",
       "                         0.03673136, -0.09884647],\n",
       "                       [ 0.03404038,  0.01777626,  0.00796143, ...,  0.10897094,\n",
       "                        -0.01102099,  0.04511466],\n",
       "                       [-0.08335302,  0.14630537,  0.06059798, ...,  0.03800319,\n",
       "                        -0.0394122 ,  0.01938132]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([-0.00966813, -0.00192081,  0.01525487, ..., -0.02853198,\n",
       "                       -0.02402867, -0.06698362], dtype=float32),\n",
       "                kernel: Array([[-0.06178613, -0.07032565, -0.03513376, ...,  0.03529928,\n",
       "                        -0.0741185 , -0.08269883],\n",
       "                       [-0.02231484,  0.01906584,  0.07621469, ..., -0.00207866,\n",
       "                        -0.00104101, -0.04729763],\n",
       "                       [-0.04971511, -0.03679726, -0.0644962 , ..., -0.06790421,\n",
       "                        -0.12373959,  0.05511543],\n",
       "                       ...,\n",
       "                       [-0.01312885, -0.00591554,  0.01366898, ...,  0.08229617,\n",
       "                        -0.04982107,  0.04832614],\n",
       "                       [ 0.01681469, -0.06390781, -0.13968655, ...,  0.00674789,\n",
       "                        -0.00624019,  0.06472278],\n",
       "                       [-0.09490924,  0.00667255, -0.03415025, ...,  0.01763641,\n",
       "                         0.03430586, -0.01165899]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "        ln_1: {\n",
       "            bias: Array([-0.03606706,  0.03778488,  0.04421993, ..., -0.02354234,\n",
       "                    0.02217534,  0.09670716], dtype=float32),\n",
       "            scale: Array([0.6661242 , 0.6782926 , 0.6349123 , ..., 0.6261518 , 0.6628982 ,\n",
       "                   0.58533615], dtype=float32),\n",
       "        },\n",
       "        ln_2: {\n",
       "            bias: Array([-0.02438473,  0.06023987, -0.00225281, ...,  0.00029614,\n",
       "                   -0.0168546 ,  0.02977363], dtype=float32),\n",
       "            scale: Array([0.6774901 , 0.6649628 , 0.67258304, ..., 0.6548463 , 0.6465535 ,\n",
       "                   0.63670355], dtype=float32),\n",
       "        },\n",
       "        mlp: {\n",
       "            c_fc: {\n",
       "                bias: Array([-0.01206196, -0.02394314, -0.02664112, ..., -0.03623279,\n",
       "                       -0.0159948 , -0.02100796], dtype=float32),\n",
       "                kernel: Array([[-0.05659195, -0.0158085 ,  0.0060962 , ...,  0.0350351 ,\n",
       "                        -0.01078128, -0.00998559],\n",
       "                       [ 0.09228021, -0.0487381 ,  0.02292343, ...,  0.00796392,\n",
       "                        -0.05485405,  0.02752681],\n",
       "                       [ 0.05883615, -0.05510887, -0.02635392, ..., -0.0800201 ,\n",
       "                        -0.02581288,  0.04288635],\n",
       "                       ...,\n",
       "                       [-0.06560693, -0.01492309,  0.04117934, ..., -0.0043043 ,\n",
       "                         0.04221445, -0.01469602],\n",
       "                       [-0.01607635,  0.00806978, -0.00446994, ..., -0.06016924,\n",
       "                        -0.02600466, -0.00869363],\n",
       "                       [-0.00159084,  0.0529605 ,  0.08014967, ..., -0.02234514,\n",
       "                         0.09506532, -0.01711546]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([ 0.10363264, -0.03172447, -0.03195671, ...,  0.08797346,\n",
       "                        0.01619527, -0.05649939], dtype=float32),\n",
       "                kernel: Array([[ 0.0641858 ,  0.06738296,  0.02373474, ...,  0.10414805,\n",
       "                         0.0194329 , -0.01112255],\n",
       "                       [ 0.09295705,  0.15221433, -0.13802534, ...,  0.02763773,\n",
       "                         0.02888024, -0.00029989],\n",
       "                       [-0.07474239,  0.02317366, -0.01360125, ...,  0.0439614 ,\n",
       "                        -0.02199297,  0.01585953],\n",
       "                       ...,\n",
       "                       [-0.0274353 , -0.03407631, -0.00170163, ...,  0.01189011,\n",
       "                        -0.02656321,  0.00544691],\n",
       "                       [ 0.01265528, -0.01284876,  0.0541671 , ...,  0.02403335,\n",
       "                        -0.01993543,  0.01771096],\n",
       "                       [-0.00489229, -0.02122924, -0.06137764, ...,  0.02456915,\n",
       "                        -0.09437401,  0.07504216]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "    29: {\n",
       "        attn: {\n",
       "            c_attn: {\n",
       "                bias: Array([-6.5492317e-02,  7.6594202e-05, -8.1142344e-02, ...,\n",
       "                       -1.4974673e-02,  2.4560306e-03, -3.6610391e-02], dtype=float32),\n",
       "                kernel: Array([[-0.02878206, -0.04092327,  0.00786334, ...,  0.05979552,\n",
       "                        -0.05206965,  0.05490621],\n",
       "                       [-0.00050478, -0.00802543,  0.01585814, ..., -0.0076446 ,\n",
       "                         0.02137084, -0.01566425],\n",
       "                       [-0.00068938,  0.01285715,  0.01846122, ...,  0.00045941,\n",
       "                         0.03031413, -0.03258632],\n",
       "                       ...,\n",
       "                       [ 0.05659772, -0.05006389,  0.02181705, ..., -0.00997181,\n",
       "                        -0.05008129,  0.01242909],\n",
       "                       [ 0.10286622, -0.06702061, -0.11346908, ...,  0.01817758,\n",
       "                        -0.03092838, -0.01207771],\n",
       "                       [ 0.03055191,  0.13532507, -0.00642909, ..., -0.02669538,\n",
       "                        -0.05159999, -0.02411988]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([-0.01254634, -0.0132088 ,  0.02160191, ...,  0.00906816,\n",
       "                       -0.03575642, -0.0845812 ], dtype=float32),\n",
       "                kernel: Array([[ 0.05700509,  0.00497324, -0.01456862, ..., -0.03619868,\n",
       "                         0.08638845, -0.15162478],\n",
       "                       [-0.00502365,  0.00219955, -0.00636662, ..., -0.09527145,\n",
       "                         0.03006193,  0.00340957],\n",
       "                       [ 0.02584223, -0.00296134, -0.06226911, ..., -0.03202894,\n",
       "                         0.02279687,  0.04561101],\n",
       "                       ...,\n",
       "                       [-0.00196089,  0.0287503 , -0.03057995, ...,  0.02343622,\n",
       "                        -0.04834866,  0.00552493],\n",
       "                       [ 0.0512859 , -0.00306344, -0.05811785, ...,  0.00573064,\n",
       "                        -0.08609475,  0.01212737],\n",
       "                       [ 0.03737817, -0.00241087,  0.05330568, ..., -0.00038502,\n",
       "                         0.12874474, -0.0006802 ]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "        ln_1: {\n",
       "            bias: Array([-0.02455145,  0.03058603,  0.03719166, ..., -0.01994837,\n",
       "                    0.01836141,  0.08534354], dtype=float32),\n",
       "            scale: Array([0.66571313, 0.6793051 , 0.6584979 , ..., 0.66018856, 0.66855776,\n",
       "                   0.59982806], dtype=float32),\n",
       "        },\n",
       "        ln_2: {\n",
       "            bias: Array([-0.00092424,  0.05684006,  0.00719578, ...,  0.01077093,\n",
       "                   -0.02484591,  0.01966389], dtype=float32),\n",
       "            scale: Array([0.6958831 , 0.68425065, 0.7045131 , ..., 0.66469365, 0.65222967,\n",
       "                   0.65411067], dtype=float32),\n",
       "        },\n",
       "        mlp: {\n",
       "            c_fc: {\n",
       "                bias: Array([-0.05829044, -0.02374266, -0.01468315, ..., -0.03270705,\n",
       "                       -0.00469313, -0.02370166], dtype=float32),\n",
       "                kernel: Array([[-0.00165362, -0.070602  ,  0.03418419, ..., -0.0709442 ,\n",
       "                        -0.10003561, -0.07287399],\n",
       "                       [-0.02038668, -0.08704021, -0.02241413, ..., -0.01922433,\n",
       "                         0.02820271,  0.06017419],\n",
       "                       [ 0.01434412, -0.04531473,  0.03240838, ...,  0.05578468,\n",
       "                         0.01741475, -0.05678108],\n",
       "                       ...,\n",
       "                       [-0.01774768,  0.05846839,  0.03169994, ..., -0.05929279,\n",
       "                         0.04063675,  0.03293695],\n",
       "                       [ 0.00702227, -0.04457054, -0.02520382, ..., -0.08201456,\n",
       "                        -0.02052411,  0.09332031],\n",
       "                       [ 0.05559367,  0.05515191, -0.047586  , ...,  0.01981721,\n",
       "                        -0.02444832, -0.01336194]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([ 0.12699813, -0.00794126, -0.04286527, ...,  0.08063866,\n",
       "                        0.04633417, -0.09016827], dtype=float32),\n",
       "                kernel: Array([[ 0.0784732 , -0.07666142,  0.01368152, ..., -0.04555255,\n",
       "                        -0.11178143,  0.10755516],\n",
       "                       [-0.04570652, -0.13268942,  0.02192058, ...,  0.02403388,\n",
       "                        -0.01525486, -0.04137135],\n",
       "                       [-0.03219367, -0.0091955 , -0.02592765, ..., -0.03820977,\n",
       "                         0.03621497,  0.06109991],\n",
       "                       ...,\n",
       "                       [-0.02078742,  0.02292055, -0.04030523, ..., -0.00163809,\n",
       "                         0.0087313 ,  0.01009073],\n",
       "                       [ 0.03662073,  0.08739969,  0.09527498, ..., -0.01411021,\n",
       "                        -0.04835924,  0.05394901],\n",
       "                       [ 0.0894089 , -0.03392917, -0.01061959, ...,  0.01566046,\n",
       "                        -0.11367717,  0.07338622]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "    3: {\n",
       "        attn: {\n",
       "            c_attn: {\n",
       "                bias: Array([ 0.1845229 , -0.00281118,  0.096673  , ..., -0.00667497,\n",
       "                       -0.005991  ,  0.00726198], dtype=float32),\n",
       "                kernel: Array([[ 0.02560152, -0.00467859, -0.06944604, ...,  0.01192849,\n",
       "                         0.02425067, -0.01342591],\n",
       "                       [-0.00692974, -0.00426727,  0.09353615, ..., -0.01939737,\n",
       "                         0.04342277,  0.01377604],\n",
       "                       [ 0.00408478,  0.07869735, -0.00962142, ...,  0.01014984,\n",
       "                        -0.00889346, -0.00949982],\n",
       "                       ...,\n",
       "                       [ 0.05423979, -0.02228798,  0.06130129, ..., -0.01267134,\n",
       "                         0.02359089,  0.01019178],\n",
       "                       [ 0.04828317, -0.02266806,  0.04084509, ...,  0.02143092,\n",
       "                         0.03602462,  0.03675512],\n",
       "                       [-0.04384729,  0.03462821, -0.1237605 , ..., -0.03729232,\n",
       "                        -0.0225767 , -0.02363221]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([-0.05469384,  0.03945774, -0.03383378, ...,  0.03936506,\n",
       "                        0.02620739,  0.02831275], dtype=float32),\n",
       "                kernel: Array([[-0.04776809,  0.01282799, -0.04497882, ...,  0.04638562,\n",
       "                        -0.00864599, -0.00445575],\n",
       "                       [ 0.02163986, -0.01251436, -0.00652038, ..., -0.01409613,\n",
       "                         0.03312163, -0.02769929],\n",
       "                       [ 0.03640869, -0.02414897, -0.00497156, ...,  0.03191787,\n",
       "                         0.0248321 ,  0.01002653],\n",
       "                       ...,\n",
       "                       [ 0.05189879,  0.02473487,  0.02943767, ..., -0.00167179,\n",
       "                         0.05292583, -0.0287055 ],\n",
       "                       [-0.00311479,  0.01840742,  0.03878686, ..., -0.03478032,\n",
       "                        -0.01744408, -0.01010828],\n",
       "                       [-0.023813  ,  0.03249106, -0.03948287, ...,  0.03684202,\n",
       "                        -0.01500207, -0.02208531]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "        ln_1: {\n",
       "            bias: Array([-0.05879219, -0.03812889,  0.00097701, ..., -0.12151992,\n",
       "                   -0.05717241, -0.05302386], dtype=float32),\n",
       "            scale: Array([0.42416787, 0.43461952, 0.41767725, ..., 0.4230136 , 0.44517362,\n",
       "                   0.36690018], dtype=float32),\n",
       "        },\n",
       "        ln_2: {\n",
       "            bias: Array([-0.05657151, -0.07421769,  0.03027099, ...,  0.04805579,\n",
       "                    0.01161695,  0.02118138], dtype=float32),\n",
       "            scale: Array([0.5440578 , 0.6009363 , 0.5861723 , ..., 0.5579305 , 0.52946264,\n",
       "                   0.5604176 ], dtype=float32),\n",
       "        },\n",
       "        mlp: {\n",
       "            c_fc: {\n",
       "                bias: Array([ 0.02008365, -0.04335994, -0.04811539, ..., -0.0369886 ,\n",
       "                       -0.02763673, -0.03615285], dtype=float32),\n",
       "                kernel: Array([[-4.87263128e-02,  3.04449257e-02,  3.76069173e-02, ...,\n",
       "                         2.41025258e-02,  4.95651783e-03,  7.12151378e-02],\n",
       "                       [-6.64168000e-02,  9.78267789e-02, -9.36485827e-02, ...,\n",
       "                         4.11840640e-02,  5.40478751e-02,  8.44381899e-02],\n",
       "                       [ 3.15614715e-02, -3.19348797e-02,  2.03962978e-02, ...,\n",
       "                         1.35037629e-03, -1.36509746e-01, -5.62309511e-02],\n",
       "                       ...,\n",
       "                       [ 3.05820741e-02,  6.89434214e-03, -5.27304830e-03, ...,\n",
       "                        -6.91576004e-02, -3.72570790e-02, -1.20530903e-01],\n",
       "                       [-1.61442626e-02, -7.11905882e-02, -1.28716370e-02, ...,\n",
       "                        -8.41329992e-03, -5.06377146e-02, -5.05314544e-02],\n",
       "                       [-2.87453271e-02, -3.28882597e-03, -1.04226045e-01, ...,\n",
       "                         2.22939122e-02,  9.58900855e-05, -3.11482307e-02]],      dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([-0.02024017, -0.05440358, -0.01548452, ...,  0.02491841,\n",
       "                        0.06844142,  0.02859765], dtype=float32),\n",
       "                kernel: Array([[ 0.03331364,  0.06400297, -0.01855358, ..., -0.03832754,\n",
       "                         0.01542173, -0.0048696 ],\n",
       "                       [-0.05146594,  0.02185625,  0.05930527, ..., -0.03747976,\n",
       "                        -0.02957374, -0.07287274],\n",
       "                       [ 0.00588947, -0.03667685,  0.01135078, ..., -0.02363698,\n",
       "                        -0.03470327, -0.00713065],\n",
       "                       ...,\n",
       "                       [-0.06172661, -0.01876316, -0.00136118, ...,  0.01576167,\n",
       "                        -0.01589264,  0.06185005],\n",
       "                       [-0.01635051, -0.05677294, -0.05716744, ..., -0.00058858,\n",
       "                        -0.00435702,  0.05391692],\n",
       "                       [-0.01593222,  0.01524191, -0.06790785, ..., -0.07336605,\n",
       "                         0.03944391,  0.00866679]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "    30: {\n",
       "        attn: {\n",
       "            c_attn: {\n",
       "                bias: Array([ 0.08429743, -0.05830116, -0.11457928, ..., -0.02350396,\n",
       "                        0.01723482, -0.01162391], dtype=float32),\n",
       "                kernel: Array([[-0.13391183, -0.07271236,  0.00893132, ...,  0.01888596,\n",
       "                         0.01062317, -0.03884715],\n",
       "                       [ 0.03476079,  0.01682665,  0.05608271, ...,  0.03457185,\n",
       "                        -0.03449567, -0.01777866],\n",
       "                       [ 0.00437559,  0.09642181,  0.1429662 , ..., -0.07718874,\n",
       "                        -0.04206378,  0.00135385],\n",
       "                       ...,\n",
       "                       [ 0.00469365, -0.0653531 ,  0.00311756, ...,  0.0242859 ,\n",
       "                        -0.0472205 ,  0.01812416],\n",
       "                       [-0.04331171, -0.00360207, -0.08306351, ..., -0.0602349 ,\n",
       "                        -0.02768464,  0.0094314 ],\n",
       "                       [ 0.04474568, -0.04057062,  0.02861446, ..., -0.00661448,\n",
       "                        -0.02611531,  0.01623613]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([-0.00979887,  0.0020738 , -0.01520485, ..., -0.00950568,\n",
       "                       -0.01995552, -0.06765304], dtype=float32),\n",
       "                kernel: Array([[ 0.07731675, -0.03610476,  0.08210012, ...,  0.06080029,\n",
       "                        -0.0389224 , -0.03253014],\n",
       "                       [-0.12535688,  0.00635177, -0.09322337, ...,  0.02202126,\n",
       "                        -0.10716021,  0.013812  ],\n",
       "                       [-0.0852044 , -0.10821837, -0.07315638, ...,  0.02744699,\n",
       "                         0.07516274, -0.07353078],\n",
       "                       ...,\n",
       "                       [ 0.0124803 ,  0.04094421,  0.01842416, ..., -0.03486301,\n",
       "                         0.01281179,  0.02014803],\n",
       "                       [ 0.03919418,  0.05436638,  0.02971482, ...,  0.09978142,\n",
       "                        -0.01307707,  0.00939483],\n",
       "                       [-0.06314261,  0.03445994, -0.02607337, ..., -0.02183816,\n",
       "                         0.08511609, -0.00759155]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "        ln_1: {\n",
       "            bias: Array([-0.038782  ,  0.03198827,  0.04679318, ..., -0.01971343,\n",
       "                    0.01430554,  0.10981038], dtype=float32),\n",
       "            scale: Array([0.6817928, 0.7200065, 0.6913661, ..., 0.6892894, 0.7052865,\n",
       "                   0.6082412], dtype=float32),\n",
       "        },\n",
       "        ln_2: {\n",
       "            bias: Array([ 0.01136859,  0.05388467,  0.01352031, ...,  0.00956906,\n",
       "                   -0.02010782, -0.00218282], dtype=float32),\n",
       "            scale: Array([0.7068323 , 0.69375074, 0.71402675, ..., 0.68601996, 0.67731   ,\n",
       "                   0.67097664], dtype=float32),\n",
       "        },\n",
       "        mlp: {\n",
       "            c_fc: {\n",
       "                bias: Array([-0.02404595, -0.04133944, -0.04853708, ..., -0.02018493,\n",
       "                       -0.03288653, -0.06636956], dtype=float32),\n",
       "                kernel: Array([[ 0.03618062,  0.07752635, -0.03100723, ..., -0.0481842 ,\n",
       "                         0.00597818, -0.09052283],\n",
       "                       [ 0.0155154 ,  0.0203889 , -0.06064181, ...,  0.02899469,\n",
       "                         0.05039908, -0.02304267],\n",
       "                       [-0.00252103,  0.09770602,  0.02824152, ..., -0.00806757,\n",
       "                         0.02829338, -0.06197393],\n",
       "                       ...,\n",
       "                       [ 0.00466659, -0.01640653,  0.06151908, ...,  0.02649108,\n",
       "                         0.05165996, -0.03628633],\n",
       "                       [-0.01857468,  0.01578962,  0.01326492, ..., -0.00947275,\n",
       "                         0.06011204,  0.01193252],\n",
       "                       [ 0.05231229, -0.00329985, -0.01439339, ..., -0.02041088,\n",
       "                         0.01473408, -0.08531725]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([ 0.04913253, -0.04145812, -0.02983723, ...,  0.06165254,\n",
       "                        0.03158101, -0.09936002], dtype=float32),\n",
       "                kernel: Array([[ 0.01805865,  0.04208896,  0.04477213, ...,  0.07314653,\n",
       "                        -0.11545854,  0.04769914],\n",
       "                       [ 0.01732761,  0.06979176, -0.00941007, ...,  0.05031838,\n",
       "                         0.04056159, -0.12081973],\n",
       "                       [ 0.02240677,  0.00080301, -0.12210792, ..., -0.02863373,\n",
       "                        -0.08989441,  0.03179786],\n",
       "                       ...,\n",
       "                       [ 0.0872535 , -0.06845548,  0.01014377, ...,  0.05958569,\n",
       "                        -0.02840745,  0.02032521],\n",
       "                       [ 0.03249578, -0.09748071, -0.02042417, ..., -0.04920047,\n",
       "                        -0.08113247, -0.01306583],\n",
       "                       [ 0.09720913,  0.04699811,  0.02557297, ...,  0.0071223 ,\n",
       "                         0.04391241,  0.07948188]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "    31: {\n",
       "        attn: {\n",
       "            c_attn: {\n",
       "                bias: Array([ 0.05363272,  0.04470649, -0.02060365, ..., -0.07785188,\n",
       "                       -0.04952186, -0.05489444], dtype=float32),\n",
       "                kernel: Array([[-0.05583104, -0.01492386, -0.00143732, ..., -0.01518343,\n",
       "                         0.0503323 , -0.01592775],\n",
       "                       [-0.02267788, -0.01050765,  0.01312723, ..., -0.08813708,\n",
       "                        -0.01890859,  0.03947265],\n",
       "                       [ 0.01519271, -0.02480238,  0.10329616, ...,  0.08349813,\n",
       "                        -0.00586374, -0.01937306],\n",
       "                       ...,\n",
       "                       [ 0.12258042,  0.01187363,  0.00828306, ..., -0.00294191,\n",
       "                         0.03865072, -0.03171575],\n",
       "                       [-0.00137203,  0.01714638, -0.00948514, ...,  0.01562135,\n",
       "                        -0.0625431 ,  0.04900201],\n",
       "                       [-0.07108207, -0.01360727, -0.00427834, ...,  0.01437691,\n",
       "                         0.06776626,  0.06081424]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([-0.00143474, -0.03984059, -0.04358477, ..., -0.01376859,\n",
       "                       -0.01267096, -0.09593121], dtype=float32),\n",
       "                kernel: Array([[ 0.00365323,  0.00064703,  0.07230619, ...,  0.00120284,\n",
       "                        -0.08096784, -0.02423728],\n",
       "                       [ 0.0099964 , -0.01656508, -0.03108179, ..., -0.0002104 ,\n",
       "                        -0.01161549,  0.03549656],\n",
       "                       [ 0.03240053, -0.01084892, -0.03249314, ..., -0.09491397,\n",
       "                         0.04340025, -0.03390358],\n",
       "                       ...,\n",
       "                       [-0.05043704,  0.01233246, -0.06048167, ...,  0.00498784,\n",
       "                        -0.09345889, -0.03671709],\n",
       "                       [-0.05751621, -0.06559609,  0.05711509, ..., -0.08646408,\n",
       "                        -0.01307047,  0.04855187],\n",
       "                       [-0.01327409, -0.00596458,  0.20792015, ...,  0.08888407,\n",
       "                         0.0712983 , -0.01276477]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "        ln_1: {\n",
       "            bias: Array([-0.02565054,  0.03710667,  0.04284472, ..., -0.01352755,\n",
       "                    0.03547335,  0.10461047], dtype=float32),\n",
       "            scale: Array([0.6999537 , 0.6973407 , 0.6782628 , ..., 0.67372465, 0.71513313,\n",
       "                   0.5958037 ], dtype=float32),\n",
       "        },\n",
       "        ln_2: {\n",
       "            bias: Array([-0.02524331,  0.03848087,  0.00815174, ..., -0.00091769,\n",
       "                   -0.0347187 ,  0.01413824], dtype=float32),\n",
       "            scale: Array([0.720677  , 0.7147764 , 0.73635095, ..., 0.6930876 , 0.6883207 ,\n",
       "                   0.69933707], dtype=float32),\n",
       "        },\n",
       "        mlp: {\n",
       "            c_fc: {\n",
       "                bias: Array([-0.0209803 ,  0.0056089 , -0.06438298, ..., -0.03993744,\n",
       "                       -0.02354826, -0.04569088], dtype=float32),\n",
       "                kernel: Array([[ 0.01208657, -0.03630368, -0.06595644, ...,  0.03241472,\n",
       "                        -0.04705668, -0.07289916],\n",
       "                       [-0.0467273 ,  0.06553193,  0.05594027, ..., -0.02006175,\n",
       "                        -0.01814622,  0.02059317],\n",
       "                       [ 0.02341745, -0.05758198,  0.00348262, ...,  0.05763493,\n",
       "                        -0.01350194,  0.01931915],\n",
       "                       ...,\n",
       "                       [-0.04206286, -0.06037206, -0.04510919, ...,  0.02883088,\n",
       "                         0.0410428 ,  0.07049103],\n",
       "                       [ 0.03370439, -0.00254738,  0.0139206 , ...,  0.0030047 ,\n",
       "                         0.0670585 ,  0.00390613],\n",
       "                       [ 0.02782555,  0.06851137,  0.02699052, ..., -0.02313562,\n",
       "                         0.04433988,  0.05926879]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([ 0.04895862, -0.04614296, -0.01100057, ...,  0.04160379,\n",
       "                        0.03887564, -0.07190683], dtype=float32),\n",
       "                kernel: Array([[-0.06011198,  0.08267825, -0.05946245, ...,  0.06301598,\n",
       "                         0.01981795, -0.13698745],\n",
       "                       [-0.07160041,  0.03877124, -0.12817717, ...,  0.00064674,\n",
       "                        -0.08773091, -0.01933561],\n",
       "                       [ 0.03302591, -0.07777894, -0.03973036, ..., -0.01433645,\n",
       "                         0.04641065,  0.0543719 ],\n",
       "                       ...,\n",
       "                       [-0.03565973,  0.05407067,  0.03819638, ...,  0.13422792,\n",
       "                        -0.01921384,  0.03342029],\n",
       "                       [-0.08496131,  0.08259168,  0.04657582, ..., -0.05674708,\n",
       "                         0.03407416,  0.06477432],\n",
       "                       [ 0.04521272, -0.09748528,  0.02166946, ..., -0.01812674,\n",
       "                         0.0925191 ,  0.01862499]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "    32: {\n",
       "        attn: {\n",
       "            c_attn: {\n",
       "                bias: Array([-0.03307068,  0.02606189,  0.09285385, ...,  0.03946564,\n",
       "                       -0.0643611 ,  0.00805469], dtype=float32),\n",
       "                kernel: Array([[-0.00145975,  0.02412769,  0.02215521, ...,  0.01222602,\n",
       "                        -0.00986082,  0.01830527],\n",
       "                       [ 0.01262663,  0.03751126,  0.06690375, ..., -0.06209905,\n",
       "                         0.01113719, -0.05953255],\n",
       "                       [ 0.0359463 ,  0.0263348 , -0.07519151, ..., -0.03475087,\n",
       "                        -0.01690562, -0.09095476],\n",
       "                       ...,\n",
       "                       [-0.06297299,  0.06113301, -0.04374489, ..., -0.01082396,\n",
       "                         0.04442675,  0.02084813],\n",
       "                       [-0.05077701, -0.02262486, -0.04232273, ..., -0.00640277,\n",
       "                        -0.04997208,  0.05727479],\n",
       "                       [-0.00776452,  0.04565614,  0.02647939, ..., -0.02973026,\n",
       "                         0.06761345,  0.04771074]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([-0.00968172,  0.00038596, -0.02517687, ...,  0.01785674,\n",
       "                       -0.0418346 , -0.07013009], dtype=float32),\n",
       "                kernel: Array([[-0.03494884,  0.03993143, -0.03080796, ..., -0.07365181,\n",
       "                         0.05982768,  0.11761339],\n",
       "                       [-0.01954028,  0.0439932 , -0.02145702, ..., -0.05158426,\n",
       "                         0.03631309, -0.0208006 ],\n",
       "                       [-0.10927285, -0.02157442,  0.06608862, ..., -0.02277267,\n",
       "                         0.06054484, -0.05616161],\n",
       "                       ...,\n",
       "                       [ 0.00240588, -0.0288355 , -0.06209933, ...,  0.1074271 ,\n",
       "                         0.12223399, -0.00280291],\n",
       "                       [-0.08989687,  0.03885918, -0.04199269, ...,  0.02480021,\n",
       "                         0.02421033,  0.02862101],\n",
       "                       [ 0.00836129, -0.03494814, -0.03726269, ...,  0.03247691,\n",
       "                         0.01970705, -0.05202568]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "        ln_1: {\n",
       "            bias: Array([-0.03937627,  0.01736795,  0.07128249, ..., -0.00525955,\n",
       "                    0.02922151,  0.15695216], dtype=float32),\n",
       "            scale: Array([0.7393604 , 0.7243636 , 0.71846795, ..., 0.72165096, 0.73436385,\n",
       "                   0.6113669 ], dtype=float32),\n",
       "        },\n",
       "        ln_2: {\n",
       "            bias: Array([-0.01913837,  0.03769106,  0.03873805, ...,  0.01682572,\n",
       "                   -0.0167734 ,  0.06779825], dtype=float32),\n",
       "            scale: Array([0.7729825 , 0.74042827, 0.7619212 , ..., 0.73205596, 0.71675694,\n",
       "                   0.7172146 ], dtype=float32),\n",
       "        },\n",
       "        mlp: {\n",
       "            c_fc: {\n",
       "                bias: Array([-0.05157207, -0.01632785, -0.05868624, ..., -0.03159672,\n",
       "                       -0.03277741, -0.01612134], dtype=float32),\n",
       "                kernel: Array([[-0.02650844,  0.00910586, -0.03654279, ..., -0.03824143,\n",
       "                         0.03938806,  0.05871569],\n",
       "                       [-0.01369379, -0.11950094, -0.01916006, ...,  0.09913996,\n",
       "                         0.02192364,  0.02260602],\n",
       "                       [ 0.11770221,  0.03795262, -0.01798439, ...,  0.02181018,\n",
       "                         0.02267023, -0.0348535 ],\n",
       "                       ...,\n",
       "                       [-0.103702  ,  0.02396538, -0.06423165, ..., -0.03573612,\n",
       "                        -0.00450901, -0.04308296],\n",
       "                       [ 0.02092757, -0.04663444,  0.08477122, ..., -0.05400546,\n",
       "                        -0.01303286,  0.00593208],\n",
       "                       [ 0.01000099, -0.03624744, -0.00462268, ..., -0.03262231,\n",
       "                        -0.04854048,  0.003518  ]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([ 0.01268117, -0.02152368, -0.02365021, ...,  0.04702277,\n",
       "                        0.06652512, -0.09389737], dtype=float32),\n",
       "                kernel: Array([[ 0.04716757, -0.00138097,  0.09986909, ...,  0.07634432,\n",
       "                         0.04002401, -0.14681305],\n",
       "                       [ 0.0282362 ,  0.11445709, -0.00056564, ..., -0.09340932,\n",
       "                         0.07322723,  0.04385628],\n",
       "                       [-0.04316388,  0.06103801,  0.01697063, ..., -0.04121768,\n",
       "                        -0.00583862, -0.00817998],\n",
       "                       ...,\n",
       "                       [-0.10662364, -0.07482271,  0.00437223, ..., -0.06212508,\n",
       "                         0.02689055,  0.00293528],\n",
       "                       [ 0.01092316,  0.06512947, -0.04861206, ...,  0.15936983,\n",
       "                         0.06836116,  0.03615707],\n",
       "                       [-0.00351674, -0.00555157,  0.00805685, ..., -0.05418671,\n",
       "                        -0.00566504, -0.04916792]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "    33: {\n",
       "        attn: {\n",
       "            c_attn: {\n",
       "                bias: Array([ 0.08019159, -0.05550566, -0.08294931, ..., -0.00505162,\n",
       "                        0.04751274,  0.00016638], dtype=float32),\n",
       "                kernel: Array([[-9.09981579e-02, -2.38397252e-02,  2.79141273e-02, ...,\n",
       "                         1.03753977e-01, -3.26105244e-02,  1.90077983e-02],\n",
       "                       [-2.19855504e-03, -2.32820753e-02,  4.97876992e-03, ...,\n",
       "                         9.76230585e-05, -5.71397990e-02,  1.26305353e-02],\n",
       "                       [-2.95837433e-03,  5.63627109e-03,  2.75246855e-02, ...,\n",
       "                         7.32750073e-02,  2.34715734e-02,  4.03528176e-02],\n",
       "                       ...,\n",
       "                       [-4.03120257e-02, -5.54936752e-02,  1.43254185e-02, ...,\n",
       "                         6.15056157e-02,  7.46457418e-03, -1.23202158e-02],\n",
       "                       [-8.94789025e-02, -1.00225061e-01,  4.13575359e-02, ...,\n",
       "                        -3.41857318e-03,  6.99253157e-02,  4.20725308e-02],\n",
       "                       [-5.51584810e-02, -8.42775684e-03, -2.38568429e-02, ...,\n",
       "                        -4.55375426e-02,  8.24421868e-02, -2.09721196e-02]],      dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([-0.00255889, -0.02231706, -0.03688794, ..., -0.01279729,\n",
       "                       -0.01456975, -0.09353462], dtype=float32),\n",
       "                kernel: Array([[-0.02389243, -0.03326515,  0.02099557, ..., -0.08703519,\n",
       "                        -0.00510575,  0.03027746],\n",
       "                       [-0.01111967,  0.07276513,  0.03634189, ...,  0.05876042,\n",
       "                        -0.06106663,  0.07723432],\n",
       "                       [-0.003543  , -0.01092419,  0.00635857, ..., -0.04019722,\n",
       "                        -0.0104675 ,  0.01801922],\n",
       "                       ...,\n",
       "                       [ 0.09516279, -0.02976481, -0.0001094 , ...,  0.06123344,\n",
       "                        -0.01636778, -0.07010609],\n",
       "                       [-0.0015726 , -0.07134487,  0.05885371, ...,  0.00114775,\n",
       "                        -0.0107918 ,  0.08548597],\n",
       "                       [ 0.03654855,  0.07481954,  0.0259254 , ..., -0.03114425,\n",
       "                        -0.00414623,  0.10213037]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "        ln_1: {\n",
       "            bias: Array([ 0.0065318 ,  0.0621434 ,  0.05607066, ..., -0.00405358,\n",
       "                    0.06332005,  0.24486126], dtype=float32),\n",
       "            scale: Array([0.7445609 , 0.7314716 , 0.71594286, ..., 0.72006756, 0.7365728 ,\n",
       "                   0.5842943 ], dtype=float32),\n",
       "        },\n",
       "        ln_2: {\n",
       "            bias: Array([-0.03170985,  0.03891659,  0.06727333, ..., -0.00807863,\n",
       "                   -0.03187126,  0.07273062], dtype=float32),\n",
       "            scale: Array([0.7643458 , 0.76709527, 0.7828115 , ..., 0.7519485 , 0.7728321 ,\n",
       "                   0.7849268 ], dtype=float32),\n",
       "        },\n",
       "        mlp: {\n",
       "            c_fc: {\n",
       "                bias: Array([-0.07448751,  0.00502267, -0.02223524, ..., -0.02232803,\n",
       "                       -0.03565744, -0.00186472], dtype=float32),\n",
       "                kernel: Array([[-0.05907745, -0.00313817,  0.03776214, ...,  0.01648805,\n",
       "                        -0.07643111, -0.04185036],\n",
       "                       [-0.02254804,  0.02869022, -0.01478436, ...,  0.06543326,\n",
       "                        -0.03872447,  0.036624  ],\n",
       "                       [ 0.02325147,  0.0023306 ,  0.02243963, ...,  0.0364932 ,\n",
       "                         0.09830233,  0.07103858],\n",
       "                       ...,\n",
       "                       [ 0.00481702, -0.08770789, -0.05370535, ..., -0.01987054,\n",
       "                        -0.06828987,  0.02705899],\n",
       "                       [ 0.07106697, -0.03375266,  0.00268838, ...,  0.02922538,\n",
       "                         0.07970886,  0.02654402],\n",
       "                       [-0.04054485, -0.01039694, -0.04406393, ...,  0.01583953,\n",
       "                         0.03771379, -0.00951228]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([ 0.03794361, -0.01317359,  0.00590369, ...,  0.00055473,\n",
       "                        0.0659118 , -0.09589231], dtype=float32),\n",
       "                kernel: Array([[ 0.07746609, -0.07838836,  0.01663261, ...,  0.02980066,\n",
       "                         0.0763176 ,  0.03306967],\n",
       "                       [ 0.01066165, -0.0684946 ,  0.02256688, ..., -0.16303696,\n",
       "                        -0.02614482,  0.03776973],\n",
       "                       [ 0.07303086, -0.02430726,  0.05700187, ..., -0.01143149,\n",
       "                         0.04525625,  0.06422871],\n",
       "                       ...,\n",
       "                       [-0.06418292, -0.04343323, -0.0177804 , ...,  0.16900586,\n",
       "                        -0.05047669,  0.03035475],\n",
       "                       [-0.10506169, -0.01111558, -0.0187216 , ..., -0.0581541 ,\n",
       "                        -0.00037782, -0.07751212],\n",
       "                       [ 0.01498937,  0.01224207,  0.07743364, ..., -0.1387174 ,\n",
       "                        -0.05958399, -0.00688512]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "    34: {\n",
       "        attn: {\n",
       "            c_attn: {\n",
       "                bias: Array([ 0.04653252,  0.11117557,  0.1465371 , ..., -0.03141013,\n",
       "                        0.04534077, -0.01573305], dtype=float32),\n",
       "                kernel: Array([[ 0.0577656 , -0.04904472,  0.00396245, ...,  0.0209093 ,\n",
       "                        -0.01358769,  0.06634523],\n",
       "                       [-0.04765114,  0.07839862, -0.08519921, ...,  0.01736996,\n",
       "                         0.05157791,  0.02647349],\n",
       "                       [-0.0719003 , -0.05033021, -0.05188488, ..., -0.02907584,\n",
       "                         0.00708278,  0.07059519],\n",
       "                       ...,\n",
       "                       [ 0.07268663, -0.00641885, -0.00231561, ...,  0.00497882,\n",
       "                         0.00518141,  0.06267006],\n",
       "                       [-0.06491241,  0.01944273, -0.02942328, ..., -0.04541402,\n",
       "                        -0.01917718, -0.08103538],\n",
       "                       [ 0.06098956,  0.05167803, -0.07135229, ...,  0.02421294,\n",
       "                        -0.00247891,  0.03719468]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([ 0.02752047, -0.00997857, -0.01121363, ...,  0.004429  ,\n",
       "                        0.03572601, -0.13616571], dtype=float32),\n",
       "                kernel: Array([[-0.01487441,  0.04225869,  0.02756711, ...,  0.0928435 ,\n",
       "                         0.02409357, -0.06637318],\n",
       "                       [-0.03032298,  0.11849419,  0.0345354 , ..., -0.05981131,\n",
       "                        -0.04772716, -0.04658309],\n",
       "                       [ 0.06687593, -0.02962398,  0.07125906, ...,  0.05176169,\n",
       "                         0.01561277, -0.04190934],\n",
       "                       ...,\n",
       "                       [-0.09689871,  0.09437846, -0.07354639, ..., -0.05033918,\n",
       "                        -0.02777584, -0.03760841],\n",
       "                       [-0.0075871 ,  0.02339577, -0.04993774, ..., -0.02829297,\n",
       "                         0.01387835,  0.03799865],\n",
       "                       [-0.05994433, -0.03261816, -0.02032659, ...,  0.04698608,\n",
       "                        -0.03483654,  0.00039377]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "        ln_1: {\n",
       "            bias: Array([-0.00490377,  0.08854575,  0.10918922, ...,  0.01566559,\n",
       "                    0.02741098,  0.24888472], dtype=float32),\n",
       "            scale: Array([0.824154  , 0.7676502 , 0.73273474, ..., 0.7676916 , 0.7833274 ,\n",
       "                   0.6200537 ], dtype=float32),\n",
       "        },\n",
       "        ln_2: {\n",
       "            bias: Array([-0.0335305 ,  0.05199316,  0.07366975, ..., -0.02146054,\n",
       "                    0.01295749,  0.05832179], dtype=float32),\n",
       "            scale: Array([0.8023742 , 0.79813755, 0.81366843, ..., 0.78184885, 0.801361  ,\n",
       "                   0.8304475 ], dtype=float32),\n",
       "        },\n",
       "        mlp: {\n",
       "            c_fc: {\n",
       "                bias: Array([ 0.0613433 , -0.06424464, -0.04960312, ...,  0.07853626,\n",
       "                       -0.02784527,  0.00840594], dtype=float32),\n",
       "                kernel: Array([[-0.06709976,  0.08567328, -0.00690073, ..., -0.00289524,\n",
       "                         0.00073432, -0.05853608],\n",
       "                       [ 0.00205029, -0.01678838, -0.05873349, ..., -0.07712848,\n",
       "                         0.01073796, -0.01858617],\n",
       "                       [ 0.09078659,  0.05454991, -0.08571021, ..., -0.03222253,\n",
       "                         0.08378122, -0.0234529 ],\n",
       "                       ...,\n",
       "                       [ 0.06370633,  0.0367955 ,  0.00842804, ...,  0.06172397,\n",
       "                         0.04715695,  0.09943502],\n",
       "                       [ 0.00732956,  0.02306081,  0.05105698, ..., -0.01126649,\n",
       "                        -0.01031718,  0.01758654],\n",
       "                       [ 0.04211526,  0.04325444,  0.03819659, ...,  0.06326035,\n",
       "                         0.11477079,  0.04402977]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([ 0.00205509,  0.0449319 ,  0.05404347, ...,  0.04565461,\n",
       "                        0.07448976, -0.06576829], dtype=float32),\n",
       "                kernel: Array([[ 0.01819025,  0.00414369,  0.01371908, ..., -0.03385716,\n",
       "                        -0.03338538,  0.00088588],\n",
       "                       [ 0.04275306,  0.0114273 ,  0.08471283, ..., -0.04082907,\n",
       "                        -0.10733314,  0.18153532],\n",
       "                       [ 0.12345343, -0.06369196, -0.08069129, ..., -0.05238955,\n",
       "                        -0.00322452, -0.10305966],\n",
       "                       ...,\n",
       "                       [ 0.04864234,  0.00906529,  0.03676454, ..., -0.08923694,\n",
       "                        -0.02375241, -0.06153123],\n",
       "                       [-0.02554117, -0.0620223 ,  0.05377237, ..., -0.05534874,\n",
       "                        -0.06233791, -0.10992616],\n",
       "                       [-0.02501219,  0.02429077, -0.03077015, ..., -0.10313419,\n",
       "                        -0.00133802,  0.10285872]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "    35: {\n",
       "        attn: {\n",
       "            c_attn: {\n",
       "                bias: Array([-0.01823208, -0.00705104,  0.04333788, ..., -0.0226221 ,\n",
       "                       -0.02781406, -0.04043519], dtype=float32),\n",
       "                kernel: Array([[-0.01646764,  0.03892892, -0.03283568, ..., -0.03309586,\n",
       "                         0.02790978, -0.05996922],\n",
       "                       [-0.02040652,  0.02906768, -0.04357047, ...,  0.00980339,\n",
       "                        -0.00569449, -0.04386063],\n",
       "                       [-0.02707166,  0.06915474,  0.04990809, ..., -0.02942114,\n",
       "                         0.01490593, -0.02451561],\n",
       "                       ...,\n",
       "                       [ 0.01579889,  0.00106831,  0.09546958, ...,  0.05471499,\n",
       "                         0.07629736,  0.02937812],\n",
       "                       [-0.05979258, -0.0067527 , -0.0649633 , ..., -0.00788496,\n",
       "                         0.02308321,  0.01674038],\n",
       "                       [-0.03050321,  0.10465658, -0.05571888, ..., -0.00265523,\n",
       "                        -0.00217973, -0.02356367]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([-0.05256285,  0.0129461 ,  0.02626646, ..., -0.02648602,\n",
       "                        0.05540956, -0.05084242], dtype=float32),\n",
       "                kernel: Array([[ 8.9390695e-02,  1.2735709e-02,  6.4483196e-02, ...,\n",
       "                         1.7487863e-02,  1.8322594e-02,  2.2817943e-03],\n",
       "                       [ 2.8400191e-03, -1.8615700e-02, -2.8300904e-02, ...,\n",
       "                         5.0938658e-02,  5.6345537e-02,  4.5294531e-02],\n",
       "                       [ 5.2296497e-02,  5.8221016e-03, -3.2770166e-03, ...,\n",
       "                         4.5368526e-02,  1.7353324e-03, -7.1588499e-03],\n",
       "                       ...,\n",
       "                       [-4.5529348e-03, -2.3827283e-02, -1.4360434e-02, ...,\n",
       "                         5.1633727e-02, -8.8003020e-05, -2.2621753e-03],\n",
       "                       [ 2.6329523e-02,  8.5401917e-03,  3.1600583e-02, ...,\n",
       "                         4.2993143e-02, -3.4025639e-02, -5.1993851e-02],\n",
       "                       [-6.4225301e-02, -2.7574448e-02, -2.7861346e-02, ...,\n",
       "                         1.0828513e-02,  4.0624649e-03, -6.9130041e-02]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "        ln_1: {\n",
       "            bias: Array([ 0.06001949,  0.0820421 ,  0.10388365, ..., -0.02005779,\n",
       "                    0.0866721 ,  0.01320362], dtype=float32),\n",
       "            scale: Array([0.89640445, 0.76618737, 0.73279095, ..., 0.7406818 , 0.80267304,\n",
       "                   0.6120113 ], dtype=float32),\n",
       "        },\n",
       "        ln_2: {\n",
       "            bias: Array([-0.01921526,  0.02777417,  0.03965041, ...,  0.00617342,\n",
       "                    0.03711232,  0.02046289], dtype=float32),\n",
       "            scale: Array([0.78589815, 0.8103485 , 0.8251189 , ..., 0.77700436, 0.82788396,\n",
       "                   0.8162474 ], dtype=float32),\n",
       "        },\n",
       "        mlp: {\n",
       "            c_fc: {\n",
       "                bias: Array([ 0.03183742,  0.0063898 , -0.01041382, ...,  0.00444355,\n",
       "                       -0.01485589, -0.08979724], dtype=float32),\n",
       "                kernel: Array([[-3.15435454e-02, -8.65822658e-02, -6.53442461e-03, ...,\n",
       "                        -2.39895862e-02, -4.97939363e-02, -4.24929373e-02],\n",
       "                       [ 7.16458187e-02,  1.04952462e-01,  4.65278700e-02, ...,\n",
       "                         3.28582600e-02,  5.98572718e-04,  3.42269763e-02],\n",
       "                       [ 1.27285972e-01, -4.73787524e-02, -9.41602699e-03, ...,\n",
       "                         1.13633275e-02,  1.17350714e-02,  2.77635138e-02],\n",
       "                       ...,\n",
       "                       [ 3.95873524e-02,  6.44777715e-02, -2.47738305e-02, ...,\n",
       "                         8.40405375e-02,  2.31328867e-02, -5.88666722e-02],\n",
       "                       [-7.65519589e-02, -6.59621845e-04, -3.47744040e-02, ...,\n",
       "                         5.50189316e-02,  2.79350113e-02,  9.81730968e-03],\n",
       "                       [ 4.79330483e-05,  4.94122729e-02,  8.12866315e-02, ...,\n",
       "                         2.88493279e-02,  2.18834188e-02,  7.92060196e-02]],      dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([-0.07014966,  0.05316421,  0.06517939, ..., -0.06303681,\n",
       "                        0.00690162,  0.0243021 ], dtype=float32),\n",
       "                kernel: Array([[-0.03113414, -0.0223851 , -0.0325468 , ..., -0.02999196,\n",
       "                        -0.03268393, -0.04977654],\n",
       "                       [ 0.04327399,  0.00341201,  0.01518328, ..., -0.02756528,\n",
       "                        -0.04118546, -0.01646632],\n",
       "                       [ 0.01862692, -0.02589181, -0.00795203, ..., -0.01365562,\n",
       "                         0.05050663,  0.05256918],\n",
       "                       ...,\n",
       "                       [-0.05056141,  0.02222843,  0.01891076, ..., -0.11752863,\n",
       "                         0.01681285, -0.02619553],\n",
       "                       [ 0.0258526 ,  0.00723438, -0.1434966 , ...,  0.0513082 ,\n",
       "                         0.0413675 , -0.07115071],\n",
       "                       [-0.22459218,  0.13616686, -0.05702484, ..., -0.06848068,\n",
       "                         0.0436574 , -0.1583476 ]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "    4: {\n",
       "        attn: {\n",
       "            c_attn: {\n",
       "                bias: Array([-0.15584368, -0.03115769,  0.0076082 , ...,  0.011075  ,\n",
       "                       -0.0186197 , -0.01646918], dtype=float32),\n",
       "                kernel: Array([[ 0.02009324,  0.01788855,  0.04853028, ...,  0.02108964,\n",
       "                         0.0275238 , -0.02091816],\n",
       "                       [ 0.12557538, -0.03672549, -0.03193895, ...,  0.02729534,\n",
       "                         0.04001398,  0.01661992],\n",
       "                       [-0.01436681,  0.09452249,  0.03963681, ..., -0.01370146,\n",
       "                        -0.00546793, -0.052413  ],\n",
       "                       ...,\n",
       "                       [ 0.10439191,  0.03850477,  0.0580476 , ...,  0.00489299,\n",
       "                         0.0139361 ,  0.02608674],\n",
       "                       [-0.05118633,  0.01768917,  0.02584602, ...,  0.05044579,\n",
       "                         0.00087429,  0.00074154],\n",
       "                       [-0.00842119, -0.03331684,  0.04225206, ...,  0.00560888,\n",
       "                        -0.05276818, -0.00738007]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([-0.06517354, -0.01272765, -0.0406375 , ...,  0.03072599,\n",
       "                        0.04463629,  0.02829543], dtype=float32),\n",
       "                kernel: Array([[ 0.04383808, -0.00373392,  0.05120749, ...,  0.04138723,\n",
       "                         0.03937856, -0.03335271],\n",
       "                       [-0.05093312, -0.03645835, -0.02259934, ..., -0.03041131,\n",
       "                        -0.01493014,  0.00067221],\n",
       "                       [ 0.03903314,  0.03628195,  0.03631692, ..., -0.02499551,\n",
       "                        -0.05348953, -0.02771871],\n",
       "                       ...,\n",
       "                       [-0.03604553,  0.01762424,  0.07234077, ...,  0.0217192 ,\n",
       "                        -0.13344395, -0.03401301],\n",
       "                       [-0.04417718, -0.05754839,  0.01973586, ...,  0.00794533,\n",
       "                        -0.03911776,  0.03903804],\n",
       "                       [-0.0220811 ,  0.06112589,  0.02617789, ..., -0.05551509,\n",
       "                         0.0067581 , -0.01834612]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "        ln_1: {\n",
       "            bias: Array([-0.07091203, -0.03285463, -0.00678125, ..., -0.12365352,\n",
       "                   -0.05221586, -0.04389175], dtype=float32),\n",
       "            scale: Array([0.4555789 , 0.43769747, 0.44311044, ..., 0.41739604, 0.44294515,\n",
       "                   0.36960799], dtype=float32),\n",
       "        },\n",
       "        ln_2: {\n",
       "            bias: Array([-0.04312595, -0.04667905,  0.01050436, ...,  0.04560779,\n",
       "                    0.02702828,  0.02667057], dtype=float32),\n",
       "            scale: Array([0.55275404, 0.5938398 , 0.58006996, ..., 0.5560262 , 0.55249226,\n",
       "                   0.5664071 ], dtype=float32),\n",
       "        },\n",
       "        mlp: {\n",
       "            c_fc: {\n",
       "                bias: Array([ 0.00447719, -0.05640866, -0.04195549, ..., -0.01211083,\n",
       "                       -0.04948987, -0.03319852], dtype=float32),\n",
       "                kernel: Array([[-3.97660956e-02, -2.70968508e-02, -1.99761055e-02, ...,\n",
       "                         4.85571548e-02, -3.42556275e-02, -2.05111522e-02],\n",
       "                       [ 1.09043519e-03, -2.59902403e-02, -4.44905013e-02, ...,\n",
       "                        -2.53267772e-05,  8.08596388e-02,  2.91905161e-02],\n",
       "                       [ 1.21668205e-02, -4.22107056e-02, -1.65849235e-02, ...,\n",
       "                         3.73340100e-02,  2.47183908e-02,  1.91598549e-03],\n",
       "                       ...,\n",
       "                       [ 1.11442776e-02,  4.92828526e-02, -4.04728949e-02, ...,\n",
       "                        -7.81536028e-02,  4.06562760e-02, -6.78381249e-02],\n",
       "                       [ 2.10903622e-02,  3.22190970e-02, -3.77858579e-02, ...,\n",
       "                         3.89352418e-03, -4.76702489e-02,  1.78155710e-03],\n",
       "                       [-5.87442555e-02,  7.47891190e-03, -4.39381301e-02, ...,\n",
       "                        -1.22242598e-02, -5.49349189e-02, -4.29034904e-02]],      dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([-0.0449779 , -0.0704695 , -0.01426516, ...,  0.01757827,\n",
       "                        0.03152857,  0.01374066], dtype=float32),\n",
       "                kernel: Array([[-4.6833324e-05, -4.9676370e-02, -3.1957038e-02, ...,\n",
       "                        -5.8701518e-03, -3.8436290e-02,  3.4740329e-02],\n",
       "                       [-1.9414758e-02, -1.9887013e-02, -4.8532605e-02, ...,\n",
       "                         7.6311827e-02,  4.2039994e-02,  5.8949705e-02],\n",
       "                       [ 3.9324220e-02,  5.6841969e-02, -1.6164023e-02, ...,\n",
       "                        -9.4758961e-03,  3.6896862e-02, -2.4063326e-03],\n",
       "                       ...,\n",
       "                       [ 3.0959649e-02, -3.3497315e-02, -4.4253417e-03, ...,\n",
       "                         5.0677624e-02, -1.4082119e-02,  6.6556767e-02],\n",
       "                       [-2.2975773e-02,  1.0904163e-02,  1.0225729e-02, ...,\n",
       "                         1.9130018e-03, -1.2732424e-01,  1.3314171e-02],\n",
       "                       [-1.7534704e-04, -6.9117576e-02,  8.7280255e-03, ...,\n",
       "                        -7.5024121e-02, -2.5385976e-02,  2.5669618e-02]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "    5: {\n",
       "        attn: {\n",
       "            c_attn: {\n",
       "                bias: Array([-0.05991891,  0.09209378,  0.18313739, ..., -0.02843136,\n",
       "                       -0.02186791, -0.02741874], dtype=float32),\n",
       "                kernel: Array([[ 0.07986934,  0.03417845,  0.03368404, ...,  0.03741684,\n",
       "                        -0.01829761,  0.00612948],\n",
       "                       [ 0.00287583,  0.05243669, -0.03166894, ...,  0.02166171,\n",
       "                         0.02133459,  0.0128652 ],\n",
       "                       [-0.08285053, -0.00325441,  0.0673096 , ..., -0.02398112,\n",
       "                        -0.00383257, -0.00023507],\n",
       "                       ...,\n",
       "                       [ 0.10252706, -0.03313284,  0.03599275, ...,  0.02796862,\n",
       "                        -0.00296252,  0.01519919],\n",
       "                       [ 0.05401446,  0.06364493, -0.01721767, ..., -0.01102749,\n",
       "                        -0.04338709,  0.01824662],\n",
       "                       [-0.03503622, -0.01310909,  0.02556717, ..., -0.00591368,\n",
       "                        -0.02304456, -0.06491799]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([-0.10667528, -0.02087569, -0.13459854, ..., -0.02583467,\n",
       "                       -0.04365133, -0.037639  ], dtype=float32),\n",
       "                kernel: Array([[-0.0454527 , -0.03756623, -0.00996125, ...,  0.01774191,\n",
       "                         0.05915402, -0.01991046],\n",
       "                       [-0.0773588 ,  0.01184169, -0.03342244, ..., -0.01952463,\n",
       "                         0.01865123, -0.00042777],\n",
       "                       [-0.04218002,  0.08049747,  0.03447296, ..., -0.05698434,\n",
       "                        -0.01487553,  0.03443108],\n",
       "                       ...,\n",
       "                       [-0.00761743, -0.00448893, -0.01174557, ..., -0.02331702,\n",
       "                         0.02478284, -0.03442949],\n",
       "                       [ 0.02706977,  0.02453105,  0.02901128, ..., -0.00681713,\n",
       "                        -0.04510468, -0.03344509],\n",
       "                       [ 0.04749607,  0.01590694, -0.01879269, ...,  0.0284119 ,\n",
       "                        -0.01874462,  0.02722923]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "        ln_1: {\n",
       "            bias: Array([-0.05507437, -0.00705871, -0.01307785, ..., -0.10780647,\n",
       "                   -0.03426628, -0.02278687], dtype=float32),\n",
       "            scale: Array([0.4639785 , 0.4692464 , 0.46269813, ..., 0.43467554, 0.46700343,\n",
       "                   0.4191973 ], dtype=float32),\n",
       "        },\n",
       "        ln_2: {\n",
       "            bias: Array([-0.05329974, -0.04183547,  0.0092372 , ...,  0.05273798,\n",
       "                    0.02077561,  0.01371794], dtype=float32),\n",
       "            scale: Array([0.5585169 , 0.5990462 , 0.5952116 , ..., 0.55428344, 0.5463971 ,\n",
       "                   0.5719195 ], dtype=float32),\n",
       "        },\n",
       "        mlp: {\n",
       "            c_fc: {\n",
       "                bias: Array([-0.05083077, -0.05065287, -0.04592918, ..., -0.04889327,\n",
       "                       -0.04490309, -0.05157655], dtype=float32),\n",
       "                kernel: Array([[ 0.02670166,  0.04627665, -0.05425115, ...,  0.03797359,\n",
       "                        -0.07425579, -0.09114971],\n",
       "                       [-0.03560339, -0.06373557, -0.02213182, ...,  0.07049659,\n",
       "                         0.02422452,  0.02501049],\n",
       "                       [-0.00803817, -0.0010536 ,  0.04017933, ..., -0.05111392,\n",
       "                        -0.06640511,  0.02623408],\n",
       "                       ...,\n",
       "                       [-0.03743941,  0.00051922, -0.09242121, ..., -0.00707373,\n",
       "                        -0.03042156, -0.01609664],\n",
       "                       [ 0.05673642,  0.00981409,  0.00192433, ..., -0.03698526,\n",
       "                         0.03937789,  0.05378222],\n",
       "                       [ 0.06357799, -0.00513491, -0.00210245, ...,  0.02632932,\n",
       "                         0.04906955, -0.02882431]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([-0.01661152, -0.05858715,  0.01045536, ...,  0.02563945,\n",
       "                        0.01620406, -0.02168833], dtype=float32),\n",
       "                kernel: Array([[-4.0028682e-03, -5.0617494e-02, -2.6171872e-02, ...,\n",
       "                         6.7084553e-03,  2.0793317e-02, -4.8651166e-02],\n",
       "                       [ 1.3657477e-02, -6.0725633e-02, -1.2680143e-02, ...,\n",
       "                        -5.1260579e-02, -1.1487183e-04,  1.4487465e-02],\n",
       "                       [-4.3669339e-02,  6.0532458e-02, -1.4673164e-02, ...,\n",
       "                         1.5826197e-02, -2.1518677e-02,  6.6853866e-02],\n",
       "                       ...,\n",
       "                       [ 2.2249396e-03,  7.0769854e-02, -1.1555984e-01, ...,\n",
       "                         5.8127087e-02,  1.4431236e-03, -2.3503767e-02],\n",
       "                       [-2.3793070e-02,  1.7198373e-02, -3.8885109e-02, ...,\n",
       "                         8.7083198e-02, -9.6804630e-03,  8.7320190e-03],\n",
       "                       [-1.7699972e-02,  3.4846492e-02,  1.9887082e-02, ...,\n",
       "                        -3.1234419e-02,  5.4690275e-02, -2.4760887e-04]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "    6: {\n",
       "        attn: {\n",
       "            c_attn: {\n",
       "                bias: Array([-2.1025190e-02, -6.5294638e-02,  1.3117197e-01, ...,\n",
       "                       -1.6084848e-02, -6.9789312e-05,  5.0536986e-03], dtype=float32),\n",
       "                kernel: Array([[ 0.02510746,  0.05192959, -0.01834534, ..., -0.00847279,\n",
       "                         0.04676345,  0.03653533],\n",
       "                       [ 0.00314555, -0.04005811, -0.01853693, ..., -0.00305113,\n",
       "                        -0.00226277,  0.00964973],\n",
       "                       [ 0.02592668,  0.05327516, -0.07191984, ..., -0.02998094,\n",
       "                        -0.02008121,  0.01769364],\n",
       "                       ...,\n",
       "                       [-0.03466029,  0.08356169, -0.02044036, ...,  0.01290515,\n",
       "                        -0.01365946, -0.01493345],\n",
       "                       [ 0.00124076, -0.02024482,  0.00945589, ..., -0.0083211 ,\n",
       "                        -0.00654358,  0.03031241],\n",
       "                       [ 0.04404623,  0.02430957,  0.03043554, ..., -0.00242982,\n",
       "                         0.02136947, -0.00885458]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([-0.07144774, -0.06150627, -0.08048222, ...,  0.03141351,\n",
       "                       -0.00437286,  0.00287902], dtype=float32),\n",
       "                kernel: Array([[-0.00358297, -0.01574394,  0.05565945, ...,  0.00327568,\n",
       "                         0.02875859,  0.01088226],\n",
       "                       [-0.00042688, -0.00217927, -0.04081167, ..., -0.03038251,\n",
       "                         0.06588871,  0.00956441],\n",
       "                       [ 0.03027754,  0.01728291, -0.04774858, ..., -0.05795099,\n",
       "                        -0.05814271,  0.00189964],\n",
       "                       ...,\n",
       "                       [-0.00438771,  0.03305306, -0.01894551, ...,  0.02405886,\n",
       "                         0.04236657,  0.02709883],\n",
       "                       [-0.06406033,  0.0229806 , -0.00232294, ..., -0.07962226,\n",
       "                         0.00797269, -0.00196071],\n",
       "                       [-0.01716177, -0.00685615, -0.04998295, ..., -0.00744182,\n",
       "                         0.00035705,  0.03945499]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "        ln_1: {\n",
       "            bias: Array([-0.05949144, -0.0088863 ,  0.01455621, ..., -0.10991936,\n",
       "                   -0.06308698, -0.03669648], dtype=float32),\n",
       "            scale: Array([0.49515593, 0.51040286, 0.5157133 , ..., 0.4554947 , 0.50683415,\n",
       "                   0.45022097], dtype=float32),\n",
       "        },\n",
       "        ln_2: {\n",
       "            bias: Array([-0.02192825, -0.05296227,  0.04249497, ...,  0.0550698 ,\n",
       "                    0.00597038, -0.00265939], dtype=float32),\n",
       "            scale: Array([0.54796636, 0.6117323 , 0.59223187, ..., 0.55264324, 0.55387026,\n",
       "                   0.56053007], dtype=float32),\n",
       "        },\n",
       "        mlp: {\n",
       "            c_fc: {\n",
       "                bias: Array([-0.0513222 , -0.02345812, -0.05572915, ..., -0.02963179,\n",
       "                        0.00274558, -0.04337298], dtype=float32),\n",
       "                kernel: Array([[-0.00726941, -0.00887887,  0.00394151, ...,  0.07586908,\n",
       "                         0.01472049,  0.08576325],\n",
       "                       [-0.00203698,  0.00518325,  0.03943422, ..., -0.01674147,\n",
       "                        -0.0248828 ,  0.07707714],\n",
       "                       [ 0.00572958,  0.0486902 , -0.00702602, ...,  0.07913765,\n",
       "                        -0.02892132, -0.09423419],\n",
       "                       ...,\n",
       "                       [ 0.11529796, -0.00244201, -0.00578063, ...,  0.00709837,\n",
       "                         0.01860272, -0.00316936],\n",
       "                       [-0.00636364, -0.00976295,  0.00484541, ...,  0.0357224 ,\n",
       "                        -0.04371319, -0.04114801],\n",
       "                       [-0.06106075, -0.04287627, -0.02721791, ..., -0.04662515,\n",
       "                        -0.02025851, -0.02581596]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([-0.01532736, -0.04333122,  0.0204799 , ...,  0.02354101,\n",
       "                        0.0377645 ,  0.00480528], dtype=float32),\n",
       "                kernel: Array([[ 0.05331428,  0.05947155,  0.03838469, ...,  0.1105593 ,\n",
       "                        -0.02681934, -0.08708123],\n",
       "                       [-0.05275977,  0.01297764, -0.03644893, ...,  0.05109471,\n",
       "                        -0.00421695, -0.03745387],\n",
       "                       [ 0.03072249,  0.03551528,  0.00044389, ...,  0.00248518,\n",
       "                        -0.01876887, -0.00960014],\n",
       "                       ...,\n",
       "                       [-0.02164341,  0.02171504, -0.05258961, ..., -0.02722054,\n",
       "                        -0.04121805,  0.0235965 ],\n",
       "                       [-0.00323043,  0.00422649, -0.00245179, ..., -0.00802896,\n",
       "                         0.00484087,  0.01622337],\n",
       "                       [-0.01052073, -0.01825089, -0.00150801, ...,  0.00436167,\n",
       "                         0.03270919, -0.04291553]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "    7: {\n",
       "        attn: {\n",
       "            c_attn: {\n",
       "                bias: Array([-0.1456209 , -0.10654703,  0.19125481, ...,  0.0134125 ,\n",
       "                       -0.00251369, -0.0352665 ], dtype=float32),\n",
       "                kernel: Array([[ 0.02407897,  0.01130344, -0.10630146, ..., -0.00224684,\n",
       "                         0.00492945,  0.0209324 ],\n",
       "                       [ 0.02836968,  0.06873965,  0.06803875, ..., -0.03004183,\n",
       "                         0.00017003,  0.03439822],\n",
       "                       [-0.00133358,  0.03486673,  0.03850715, ...,  0.01382911,\n",
       "                        -0.05069152, -0.00693086],\n",
       "                       ...,\n",
       "                       [-0.00016605, -0.02443217,  0.01749589, ...,  0.00271833,\n",
       "                         0.00279771,  0.00027919],\n",
       "                       [-0.0171778 ,  0.00614266, -0.09528558, ..., -0.0299244 ,\n",
       "                        -0.01171676,  0.00259264],\n",
       "                       [ 0.02053555, -0.12813944,  0.05617889, ...,  0.00979239,\n",
       "                        -0.00742148,  0.05845666]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([-0.03437637, -0.08575556, -0.05495815, ...,  0.0455075 ,\n",
       "                        0.01371082,  0.02294296], dtype=float32),\n",
       "                kernel: Array([[-0.05546406, -0.00800102,  0.07160492, ...,  0.01946951,\n",
       "                         0.01706916,  0.06660131],\n",
       "                       [-0.02347722, -0.03403772, -0.0097297 , ...,  0.01489229,\n",
       "                         0.06178812, -0.00999728],\n",
       "                       [ 0.03728683, -0.02924848,  0.02168028, ...,  0.04164321,\n",
       "                        -0.02121477, -0.00772833],\n",
       "                       ...,\n",
       "                       [ 0.06540916,  0.05253676,  0.01664068, ...,  0.03266221,\n",
       "                         0.00853084, -0.00163145],\n",
       "                       [-0.05249988,  0.00214228,  0.01404332, ..., -0.02876578,\n",
       "                        -0.00434248,  0.00507366],\n",
       "                       [-0.02917978, -0.00393457, -0.03626981, ...,  0.09339397,\n",
       "                         0.02362407, -0.05107974]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "        ln_1: {\n",
       "            bias: Array([-0.05468993,  0.00384614,  0.01125048, ..., -0.10045572,\n",
       "                   -0.04907476, -0.0344546 ], dtype=float32),\n",
       "            scale: Array([0.49838054, 0.5136357 , 0.5156126 , ..., 0.4716875 , 0.51739603,\n",
       "                   0.46055257], dtype=float32),\n",
       "        },\n",
       "        ln_2: {\n",
       "            bias: Array([-0.03473024, -0.0609557 ,  0.03014146, ...,  0.06880938,\n",
       "                   -0.01111679, -0.01407559], dtype=float32),\n",
       "            scale: Array([0.56374145, 0.6323684 , 0.6141106 , ..., 0.5810025 , 0.5865285 ,\n",
       "                   0.56570995], dtype=float32),\n",
       "        },\n",
       "        mlp: {\n",
       "            c_fc: {\n",
       "                bias: Array([-0.05328875, -0.04480583, -0.04806983, ..., -0.04308449,\n",
       "                       -0.04766614, -0.04274686], dtype=float32),\n",
       "                kernel: Array([[-0.05199312,  0.1330179 , -0.00068449, ...,  0.01589899,\n",
       "                        -0.07292419, -0.01244664],\n",
       "                       [ 0.02362397,  0.07204516, -0.12373085, ...,  0.04920593,\n",
       "                        -0.01465448,  0.00490957],\n",
       "                       [ 0.01133643,  0.01127343,  0.00681238, ...,  0.02092207,\n",
       "                         0.04281255, -0.1076139 ],\n",
       "                       ...,\n",
       "                       [ 0.05498346,  0.06879666, -0.02584079, ..., -0.04518759,\n",
       "                         0.05043862,  0.00662697],\n",
       "                       [ 0.01457549, -0.06930564, -0.0439569 , ..., -0.08943457,\n",
       "                         0.01441242, -0.00040483],\n",
       "                       [ 0.01635533,  0.01797921, -0.01524868, ..., -0.02069951,\n",
       "                        -0.00250995,  0.00480486]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([-0.00532598, -0.03325615, -0.00032559, ...,  0.01668363,\n",
       "                        0.03364056,  0.00126889], dtype=float32),\n",
       "                kernel: Array([[-0.03369693, -0.01732242, -0.03527671, ..., -0.04059463,\n",
       "                        -0.03135568, -0.02686165],\n",
       "                       [ 0.06877829,  0.05591284,  0.00179074, ..., -0.07280646,\n",
       "                        -0.02273418,  0.04696989],\n",
       "                       [-0.03041854,  0.09648414,  0.03292932, ...,  0.01325771,\n",
       "                         0.0412843 ,  0.02278946],\n",
       "                       ...,\n",
       "                       [-0.04123535,  0.00412633,  0.02639603, ...,  0.04715068,\n",
       "                         0.01050141, -0.02663278],\n",
       "                       [-0.03844079, -0.04056539,  0.11173131, ...,  0.03291775,\n",
       "                         0.01044532, -0.01178486],\n",
       "                       [-0.00973321,  0.02568605, -0.05401955, ...,  0.05085724,\n",
       "                         0.00078806,  0.06685871]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "    8: {\n",
       "        attn: {\n",
       "            c_attn: {\n",
       "                bias: Array([-0.01173885,  0.13326836, -0.05054136, ..., -0.00190065,\n",
       "                        0.00839357, -0.0002598 ], dtype=float32),\n",
       "                kernel: Array([[-0.08468234, -0.07085327,  0.05818424, ..., -0.02513969,\n",
       "                        -0.00493855,  0.01296574],\n",
       "                       [-0.06062659, -0.01021664, -0.04146817, ..., -0.04629397,\n",
       "                         0.01375891,  0.00255859],\n",
       "                       [-0.00559876,  0.08422388,  0.00671157, ..., -0.01464027,\n",
       "                        -0.02780931, -0.04303579],\n",
       "                       ...,\n",
       "                       [-0.08461291, -0.02157283,  0.04177459, ..., -0.04394135,\n",
       "                         0.02366032,  0.00074148],\n",
       "                       [-0.08057892, -0.10108374,  0.05241186, ...,  0.00555836,\n",
       "                        -0.04079631,  0.00025009],\n",
       "                       [-0.02886738,  0.06783401,  0.01306549, ..., -0.03133645,\n",
       "                        -0.03155024, -0.02779569]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([-0.03133995, -0.04081205, -0.08265745, ..., -0.01254424,\n",
       "                       -0.05853035, -0.00197752], dtype=float32),\n",
       "                kernel: Array([[-0.00636956, -0.02878766,  0.01909958, ..., -0.0224709 ,\n",
       "                        -0.01617917, -0.033026  ],\n",
       "                       [ 0.04314052,  0.02377085,  0.03454667, ...,  0.03794894,\n",
       "                         0.01205498, -0.07643931],\n",
       "                       [ 0.05534453, -0.09516454,  0.03321391, ..., -0.01151838,\n",
       "                        -0.01930913,  0.02549305],\n",
       "                       ...,\n",
       "                       [-0.01179547, -0.00528355,  0.05211147, ...,  0.03236581,\n",
       "                         0.04144614,  0.03548167],\n",
       "                       [-0.01238077, -0.02445081, -0.00891595, ...,  0.00681227,\n",
       "                         0.05465172,  0.05985662],\n",
       "                       [ 0.02058069,  0.0183666 ,  0.07114077, ..., -0.00294836,\n",
       "                        -0.00679923, -0.00441737]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "        ln_1: {\n",
       "            bias: Array([-0.03483892, -0.00329283,  0.03022123, ..., -0.08873575,\n",
       "                   -0.0410151 , -0.01324603], dtype=float32),\n",
       "            scale: Array([0.4841917 , 0.53279054, 0.5321487 , ..., 0.48091662, 0.52553624,\n",
       "                   0.49217203], dtype=float32),\n",
       "        },\n",
       "        ln_2: {\n",
       "            bias: Array([-0.03417087, -0.05503681,  0.03418307, ...,  0.05463273,\n",
       "                   -0.02120833,  0.00310488], dtype=float32),\n",
       "            scale: Array([0.563637  , 0.64318347, 0.6074251 , ..., 0.58007365, 0.5830381 ,\n",
       "                   0.56370324], dtype=float32),\n",
       "        },\n",
       "        mlp: {\n",
       "            c_fc: {\n",
       "                bias: Array([-0.03531602, -0.02679597, -0.07158306, ..., -0.0265601 ,\n",
       "                       -0.04462031, -0.02720697], dtype=float32),\n",
       "                kernel: Array([[ 0.02174225, -0.02829929,  0.02151309, ..., -0.04954825,\n",
       "                        -0.08082572,  0.03612174],\n",
       "                       [ 0.0544328 , -0.05930048,  0.07934989, ..., -0.00999511,\n",
       "                         0.1034288 ,  0.02538439],\n",
       "                       [-0.06848788, -0.04551249, -0.09622971, ...,  0.09033757,\n",
       "                        -0.0129648 ,  0.00753873],\n",
       "                       ...,\n",
       "                       [ 0.00517934, -0.00108308,  0.08419678, ...,  0.01298593,\n",
       "                         0.0093583 ,  0.00865765],\n",
       "                       [-0.03762262, -0.02359089, -0.01426265, ..., -0.05687205,\n",
       "                        -0.14162266,  0.04682595],\n",
       "                       [ 0.04673976,  0.04596692, -0.04365601, ...,  0.04812708,\n",
       "                        -0.01986469, -0.12010836]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([ 0.01023365, -0.016442  , -0.03909723, ...,  0.01781337,\n",
       "                        0.03773139, -0.00825455], dtype=float32),\n",
       "                kernel: Array([[-0.01774104,  0.00843976,  0.04822189, ..., -0.05071041,\n",
       "                        -0.01933133,  0.01463472],\n",
       "                       [-0.02841729, -0.03823257,  0.00405333, ..., -0.01454593,\n",
       "                         0.02640232,  0.07927064],\n",
       "                       [ 0.03816459, -0.0136351 , -0.01247866, ..., -0.05286407,\n",
       "                         0.0508052 , -0.01091394],\n",
       "                       ...,\n",
       "                       [-0.00723636, -0.0050352 ,  0.03806635, ...,  0.03073597,\n",
       "                        -0.00794225, -0.04792085],\n",
       "                       [-0.01885991, -0.04323349, -0.02646614, ...,  0.05545561,\n",
       "                        -0.03365228, -0.04363329],\n",
       "                       [ 0.04115453, -0.02959258, -0.0072873 , ..., -0.02231471,\n",
       "                        -0.00903808, -0.01450868]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "    9: {\n",
       "        attn: {\n",
       "            c_attn: {\n",
       "                bias: Array([-0.04277876, -0.06818724, -0.09869727, ..., -0.00135973,\n",
       "                       -0.0048161 , -0.01077853], dtype=float32),\n",
       "                kernel: Array([[ 0.02516848, -0.06959037, -0.17734927, ..., -0.01501723,\n",
       "                        -0.05363854,  0.0396672 ],\n",
       "                       [-0.06245829,  0.00204335,  0.00409712, ...,  0.04122163,\n",
       "                        -0.04370447, -0.04631596],\n",
       "                       [-0.07086102,  0.01809686, -0.07457864, ..., -0.02424765,\n",
       "                         0.03228455, -0.02993347],\n",
       "                       ...,\n",
       "                       [ 0.0646265 , -0.0908712 , -0.00183535, ..., -0.00237504,\n",
       "                        -0.0122423 , -0.01434586],\n",
       "                       [ 0.00371932, -0.00667866, -0.05289409, ..., -0.06781968,\n",
       "                         0.01917772, -0.01072659],\n",
       "                       [ 0.04758763, -0.01296958, -0.02192018, ...,  0.00376835,\n",
       "                        -0.02524021, -0.03555339]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([ 0.01920359, -0.02317817, -0.07730135, ...,  0.01123958,\n",
       "                       -0.04868112, -0.01842665], dtype=float32),\n",
       "                kernel: Array([[ 0.05541898,  0.07908107, -0.02474583, ..., -0.04240261,\n",
       "                         0.07147417, -0.03817447],\n",
       "                       [ 0.02891323, -0.08763725,  0.03703124, ...,  0.06440807,\n",
       "                        -0.01185452, -0.03951773],\n",
       "                       [-0.0599082 ,  0.00221367, -0.05397188, ..., -0.08323388,\n",
       "                         0.01006231,  0.05283359],\n",
       "                       ...,\n",
       "                       [-0.01246343, -0.05082306,  0.09341454, ..., -0.04815929,\n",
       "                         0.12355918, -0.05662627],\n",
       "                       [-0.01462707,  0.04733894,  0.01958623, ..., -0.00254575,\n",
       "                         0.02825813,  0.03331137],\n",
       "                       [-0.03751362,  0.03646212,  0.00142817, ...,  0.01439473,\n",
       "                        -0.02896075,  0.03677345]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "        ln_1: {\n",
       "            bias: Array([-0.04936757,  0.00616127,  0.01160615, ..., -0.07772851,\n",
       "                   -0.05312387, -0.0207131 ], dtype=float32),\n",
       "            scale: Array([0.50076646, 0.5488624 , 0.5550506 , ..., 0.49127194, 0.5516152 ,\n",
       "                   0.5188756 ], dtype=float32),\n",
       "        },\n",
       "        ln_2: {\n",
       "            bias: Array([-0.03236543, -0.04413556,  0.01114574, ...,  0.04701756,\n",
       "                   -0.02319888,  0.01793663], dtype=float32),\n",
       "            scale: Array([0.56993455, 0.63676834, 0.61884815, ..., 0.59393996, 0.5913593 ,\n",
       "                   0.5683644 ], dtype=float32),\n",
       "        },\n",
       "        mlp: {\n",
       "            c_fc: {\n",
       "                bias: Array([ 0.03351539, -0.05149357, -0.05349788, ..., -0.02977525,\n",
       "                       -0.05779917, -0.03245061], dtype=float32),\n",
       "                kernel: Array([[-1.5635893e-02, -4.6759644e-03, -1.5298983e-02, ...,\n",
       "                         3.4473225e-02,  2.7057849e-02, -2.3169245e-05],\n",
       "                       [ 5.6944992e-02, -1.2288002e-03,  7.1575627e-02, ...,\n",
       "                        -1.7195927e-02,  2.3470996e-02,  1.6559944e-02],\n",
       "                       [ 5.8706474e-02,  1.5319863e-02, -4.2173818e-02, ...,\n",
       "                         1.3464266e-02,  1.1177760e-02, -9.8895701e-03],\n",
       "                       ...,\n",
       "                       [ 4.0517431e-02,  1.4150462e-01, -5.6961760e-02, ...,\n",
       "                         1.5056266e-02,  3.7555955e-02, -2.0519335e-02],\n",
       "                       [-2.7001632e-02,  4.7750022e-02, -1.3083477e-02, ...,\n",
       "                         8.0434196e-02,  4.1775849e-02, -1.6830092e-02],\n",
       "                       [-1.4061823e-02,  1.4456229e-02,  1.3458365e-01, ...,\n",
       "                        -7.3919713e-02,  4.8055548e-02,  9.0943212e-03]], dtype=float32),\n",
       "            },\n",
       "            c_proj: {\n",
       "                bias: Array([-0.00758245,  0.00614548, -0.04472281, ...,  0.00680034,\n",
       "                        0.04879486,  0.01374959], dtype=float32),\n",
       "                kernel: Array([[ 0.01231434, -0.04490128, -0.01530279, ..., -0.04247779,\n",
       "                        -0.02339749, -0.00540675],\n",
       "                       [ 0.06834887,  0.06019654,  0.0381416 , ...,  0.01033414,\n",
       "                         0.04572955, -0.01533173],\n",
       "                       [-0.02837222, -0.04734134,  0.02612038, ...,  0.05903548,\n",
       "                        -0.08085645,  0.03761077],\n",
       "                       ...,\n",
       "                       [-0.04401831, -0.06048104, -0.0403959 , ..., -0.03182922,\n",
       "                        -0.06443729, -0.03919089],\n",
       "                       [ 0.05859979, -0.00790275,  0.06030363, ..., -0.01472107,\n",
       "                        -0.01064102, -0.02403709],\n",
       "                       [-0.04117184, -0.03076264, -0.01164124, ..., -0.00695894,\n",
       "                         0.02612539, -0.04728494]], dtype=float32),\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "    ln_f: {\n",
       "        bias: Array([-0.0177378 ,  0.03218177, -0.04121364, ...,  0.04586753,\n",
       "                0.0147974 , -0.07349386], dtype=float32),\n",
       "        scale: Array([1.1928456, 1.1837783, 1.3633441, ..., 1.1690326, 1.1669235,\n",
       "               1.3815583], dtype=float32),\n",
       "    },\n",
       "    wpe: {\n",
       "        embedding: Array([[ 0.00907944,  0.00058785,  0.00159346, ..., -0.03401913,\n",
       "                -0.0053568 , -0.00563951],\n",
       "               [-0.00454083,  0.00297051, -0.0066255 , ...,  0.00451538,\n",
       "                 0.01274661, -0.00312695],\n",
       "               [-0.00079973,  0.00312586, -0.00186703, ...,  0.00581723,\n",
       "                -0.00158472,  0.00317201],\n",
       "               ...,\n",
       "               [-0.00557327, -0.0007401 , -0.01307584, ...,  0.00109094,\n",
       "                 0.00076556,  0.00606313],\n",
       "               [ 0.00200112, -0.00040912, -0.00385755, ..., -0.00655925,\n",
       "                -0.00587326,  0.00012956],\n",
       "               [ 0.00306661,  0.00109863, -0.00449043, ..., -0.00205312,\n",
       "                -0.00599036, -0.00189639]], dtype=float32),\n",
       "    },\n",
       "    wte: {\n",
       "        embedding: Array([[-0.01491644, -0.02086054,  0.0021202 , ...,  0.03362218,\n",
       "                -0.00054191, -0.00898338],\n",
       "               [ 0.00546552, -0.04377642,  0.00134842, ...,  0.06712282,\n",
       "                 0.03294637, -0.03985127],\n",
       "               [ 0.0585402 ,  0.06026442,  0.03023641, ..., -0.10414282,\n",
       "                -0.05661995, -0.03297632],\n",
       "               ...,\n",
       "               [-0.01075445, -0.09077371,  0.06236218, ..., -0.03369946,\n",
       "                 0.0776626 ,  0.02926068],\n",
       "               [ 0.01951103, -0.03178071,  0.01820766, ...,  0.01913727,\n",
       "                -0.04542878, -0.01392519],\n",
       "               [-0.04187777,  0.08481726, -0.05120016, ..., -0.0083037 ,\n",
       "                -0.04468034, -0.02740996]], dtype=float32),\n",
       "    },\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_state.params['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokens, target_tokens = train_data[0]\n",
    "A = input_tokens.reshape(-1, input_tokens.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Too many indices for array: 1 non-None/Ellipsis indices for dim 0.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m A \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39marray(A)\n\u001b[0;32m----> 2\u001b[0m train_state \u001b[38;5;241m=\u001b[39m \u001b[43munreplicate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/flax/jax_utils.py:52\u001b[0m, in \u001b[0;36munreplicate\u001b[0;34m(tree)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munreplicate\u001b[39m(tree):\n\u001b[1;32m     51\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a single instance of a replicated array.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_map\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtree\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/tree_util.py:210\u001b[0m, in \u001b[0;36mtree_map\u001b[0;34m(f, tree, is_leaf, *rest)\u001b[0m\n\u001b[1;32m    208\u001b[0m leaves, treedef \u001b[38;5;241m=\u001b[39m tree_flatten(tree, is_leaf)\n\u001b[1;32m    209\u001b[0m all_leaves \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treedef\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rest]\n\u001b[0;32m--> 210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtreedef\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mxs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mxs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_leaves\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/tree_util.py:210\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    208\u001b[0m leaves, treedef \u001b[38;5;241m=\u001b[39m tree_flatten(tree, is_leaf)\n\u001b[1;32m    209\u001b[0m all_leaves \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treedef\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rest]\n\u001b[0;32m--> 210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m treedef\u001b[38;5;241m.\u001b[39munflatten(\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mxs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m xs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mall_leaves))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/flax/jax_utils.py:52\u001b[0m, in \u001b[0;36munreplicate.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munreplicate\u001b[39m(tree):\n\u001b[1;32m     51\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a single instance of a replicated array.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m jax\u001b[38;5;241m.\u001b[39mtree_util\u001b[38;5;241m.\u001b[39mtree_map(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m, tree)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/array.py:317\u001b[0m, in \u001b[0;36mArrayImpl.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    315\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m lax_numpy\u001b[38;5;241m.\u001b[39m_rewriting_take(\u001b[38;5;28mself\u001b[39m, idx)\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 317\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlax_numpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rewriting_take\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py:4143\u001b[0m, in \u001b[0;36m_rewriting_take\u001b[0;34m(arr, idx, indices_are_sorted, unique_indices, mode, fill_value)\u001b[0m\n\u001b[1;32m   4140\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m lax\u001b[38;5;241m.\u001b[39mdynamic_index_in_dim(arr, idx, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   4142\u001b[0m treedef, static_idx, dynamic_idx \u001b[38;5;241m=\u001b[39m _split_index_for_jit(idx, arr\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m-> 4143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_gather\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtreedef\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatic_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdynamic_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices_are_sorted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4144\u001b[0m \u001b[43m               \u001b[49m\u001b[43munique_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py:4152\u001b[0m, in \u001b[0;36m_gather\u001b[0;34m(arr, treedef, static_idx, dynamic_idx, indices_are_sorted, unique_indices, mode, fill_value)\u001b[0m\n\u001b[1;32m   4149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_gather\u001b[39m(arr, treedef, static_idx, dynamic_idx, indices_are_sorted,\n\u001b[1;32m   4150\u001b[0m             unique_indices, mode, fill_value):\n\u001b[1;32m   4151\u001b[0m   idx \u001b[38;5;241m=\u001b[39m _merge_static_and_dynamic_indices(treedef, static_idx, dynamic_idx)\n\u001b[0;32m-> 4152\u001b[0m   indexer \u001b[38;5;241m=\u001b[39m \u001b[43m_index_to_gather\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# shared with _scatter_update\u001b[39;00m\n\u001b[1;32m   4153\u001b[0m   y \u001b[38;5;241m=\u001b[39m arr\n\u001b[1;32m   4155\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py:4253\u001b[0m, in \u001b[0;36m_index_to_gather\u001b[0;34m(x_shape, idx, normalize_indices)\u001b[0m\n\u001b[1;32m   4250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_index_to_gather\u001b[39m(x_shape: Sequence[\u001b[38;5;28mint\u001b[39m], idx: Sequence[Any],\n\u001b[1;32m   4251\u001b[0m                      normalize_indices: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _Indexer:\n\u001b[1;32m   4252\u001b[0m   \u001b[38;5;66;03m# Remove ellipses and add trailing slice(None)s.\u001b[39;00m\n\u001b[0;32m-> 4253\u001b[0m   idx \u001b[38;5;241m=\u001b[39m \u001b[43m_canonicalize_tuple_index\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_shape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4255\u001b[0m   \u001b[38;5;66;03m# Check for advanced indexing:\u001b[39;00m\n\u001b[1;32m   4256\u001b[0m   \u001b[38;5;66;03m# https://docs.scipy.org/doc/numpy/reference/arrays.indexing.html#advanced-indexing\u001b[39;00m\n\u001b[1;32m   4257\u001b[0m \n\u001b[1;32m   4258\u001b[0m   \u001b[38;5;66;03m# Do the advanced indexing axes appear contiguously? If not, NumPy semantics\u001b[39;00m\n\u001b[1;32m   4259\u001b[0m   \u001b[38;5;66;03m# move the advanced axes to the front.\u001b[39;00m\n\u001b[1;32m   4260\u001b[0m   advanced_axes_are_contiguous \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py:4586\u001b[0m, in \u001b[0;36m_canonicalize_tuple_index\u001b[0;34m(arr_ndim, idx, array_name)\u001b[0m\n\u001b[1;32m   4584\u001b[0m len_without_none \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m idx \u001b[38;5;28;01mif\u001b[39;00m e \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mEllipsis\u001b[39m)\n\u001b[1;32m   4585\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m len_without_none \u001b[38;5;241m>\u001b[39m arr_ndim:\n\u001b[0;32m-> 4586\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[1;32m   4587\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToo many indices for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlen_without_none\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4588\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-None/Ellipsis indices for dim \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marr_ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4589\u001b[0m ellipses \u001b[38;5;241m=\u001b[39m (i \u001b[38;5;28;01mfor\u001b[39;00m i, elt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(idx) \u001b[38;5;28;01mif\u001b[39;00m elt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mEllipsis\u001b[39m)\n\u001b[1;32m   4590\u001b[0m ellipsis_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(ellipses, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mIndexError\u001b[0m: Too many indices for array: 1 non-None/Ellipsis indices for dim 0."
     ]
    }
   ],
   "source": [
    "A = jnp.array(A)\n",
    "train_state = unreplicate(train_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "ename": "ScopeParamNotFoundError",
     "evalue": "Could not find parameter named \"scale\" in scope \"/transformer/h/0/ln_1\". (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.ScopeParamNotFoundError)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mScopeParamNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mEasyLM\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjax_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JaxRNG\n\u001b[0;32m----> 2\u001b[0m \u001b[43mhf_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtransformer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mparams\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# num_return_sequences=5,\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# beam\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprng_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mJaxRNG\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# logits_processor=FlaxLogitsProcessorList(\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m#     [FlaxTemperatureLogitsWarper(temperature)]\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# ),\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/generation/flax_utils.py:417\u001b[0m, in \u001b[0;36mFlaxGenerationMixin.generate\u001b[0;34m(self, input_ids, generation_config, prng_key, trace, params, logits_processor, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m logits_processor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_processor(\n\u001b[1;32m    411\u001b[0m     generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[1;32m    412\u001b[0m     input_ids_seq_length\u001b[38;5;241m=\u001b[39minput_ids_seq_length,\n\u001b[1;32m    413\u001b[0m     logits_processor\u001b[38;5;241m=\u001b[39mlogits_processor,\n\u001b[1;32m    414\u001b[0m )\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample \u001b[38;5;129;01mand\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mnum_beams \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_greedy_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample \u001b[38;5;129;01mand\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mnum_beams \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    428\u001b[0m     logits_warper \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config\u001b[38;5;241m=\u001b[39mgeneration_config)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/generation/flax_utils.py:636\u001b[0m, in \u001b[0;36mFlaxGenerationMixin._greedy_search\u001b[0;34m(self, input_ids, max_length, pad_token_id, eos_token_id, logits_processor, trace, params, model_kwargs)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;66;03m# The very first prompt often has sequence length > 1, so run outside of `lax.while_loop` to comply with TPU\u001b[39;00m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 636\u001b[0m     state \u001b[38;5;241m=\u001b[39m \u001b[43mgreedy_search_body_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m trace:\n\u001b[1;32m    639\u001b[0m     state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_loop_in_debug(greedy_search_cond_fn, greedy_search_body_fn, state)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/generation/flax_utils.py:612\u001b[0m, in \u001b[0;36mFlaxGenerationMixin._greedy_search.<locals>.greedy_search_body_fn\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgreedy_search_body_fn\u001b[39m(state):\n\u001b[1;32m    611\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"state update fn.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 612\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m     logits \u001b[38;5;241m=\u001b[39m model_outputs\u001b[38;5;241m.\u001b[39mlogits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    615\u001b[0m     \u001b[38;5;66;03m# apply min_length, ...\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/gpt2/modeling_flax_gpt2.py:507\u001b[0m, in \u001b[0;36mFlaxGPT2PreTrainedModel.__call__\u001b[0;34m(self, input_ids, attention_mask, position_ids, encoder_hidden_states, encoder_attention_mask, params, past_key_values, dropout_rng, train, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    505\u001b[0m     mutable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mi4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mi4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mi4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrngs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrngs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmutable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmutable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;66;03m# add updated cache to model output\u001b[39;00m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m past_key_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m return_dict:\n",
      "    \u001b[0;31m[... skipping hidden 6 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/gpt2/modeling_flax_gpt2.py:703\u001b[0m, in \u001b[0;36mFlaxGPT2LMHeadModule.__call__\u001b[0;34m(self, input_ids, attention_mask, position_ids, encoder_hidden_states, encoder_attention_mask, deterministic, init_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    692\u001b[0m     input_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    701\u001b[0m     return_dict: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    702\u001b[0m ):\n\u001b[0;32m--> 703\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    716\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    718\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtie_word_embeddings:\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/gpt2/modeling_flax_gpt2.py:629\u001b[0m, in \u001b[0;36mFlaxGPT2Module.__call__\u001b[0;34m(self, input_ids, attention_mask, position_ids, encoder_hidden_states, encoder_attention_mask, deterministic, init_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    626\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m input_embeds \u001b[38;5;241m+\u001b[39m position_embeds\n\u001b[1;32m    627\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states, deterministic\u001b[38;5;241m=\u001b[39mdeterministic)\n\u001b[0;32m--> 629\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    641\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    642\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_f(hidden_states)\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/gpt2/modeling_flax_gpt2.py:564\u001b[0m, in \u001b[0;36mFlaxGPT2BlockCollection.__call__\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, deterministic, init_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[1;32m    562\u001b[0m     all_hidden_states \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (hidden_states,)\n\u001b[0;32m--> 564\u001b[0m layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    573\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/gpt2/modeling_flax_gpt2.py:333\u001b[0m, in \u001b[0;36mFlaxGPT2Block.__call__\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, deterministic, init_cache, output_attentions)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    324\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    330\u001b[0m     output_attentions: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m ):\n\u001b[1;32m    332\u001b[0m     residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m--> 333\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m     attn_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn(\n\u001b[1;32m    335\u001b[0m         hidden_states,\n\u001b[1;32m    336\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    339\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    340\u001b[0m     )\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;66;03m# residual connection\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/flax/linen/normalization.py:338\u001b[0m, in \u001b[0;36mLayerNorm.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Applies layer normalization on the input.\u001b[39;00m\n\u001b[1;32m    328\u001b[0m \n\u001b[1;32m    329\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03m  Normalized inputs (the same shape as inputs).\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    335\u001b[0m mean, var \u001b[38;5;241m=\u001b[39m _compute_stats(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction_axes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[1;32m    336\u001b[0m                            \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis_index_groups)\n\u001b[0;32m--> 338\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_normalize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_init\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/flax/linen/normalization.py:149\u001b[0m, in \u001b[0;36m_normalize\u001b[0;34m(mdl, x, mean, var, reduction_axes, feature_axes, dtype, param_dtype, epsilon, use_bias, use_scale, bias_init, scale_init)\u001b[0m\n\u001b[1;32m    147\u001b[0m args \u001b[38;5;241m=\u001b[39m [x]\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_scale:\n\u001b[0;32m--> 149\u001b[0m   scale \u001b[38;5;241m=\u001b[39m \u001b[43mmdl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscale\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduced_feature_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mparam_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(feature_shape)\n\u001b[1;32m    151\u001b[0m   mul \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m scale\n\u001b[1;32m    152\u001b[0m   args\u001b[38;5;241m.\u001b[39mappend(scale)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/flax/core/scope.py:842\u001b[0m, in \u001b[0;36mScope.param\u001b[0;34m(self, name, init_fn, unbox, *init_args)\u001b[0m\n\u001b[1;32m    840\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_collection_empty(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    841\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mScopeCollectionNotFound(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m, name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath_text)\n\u001b[0;32m--> 842\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mScopeParamNotFoundError(name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath_text)\n\u001b[1;32m    843\u001b[0m value \u001b[38;5;241m=\u001b[39m init_fn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_rng(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;241m*\u001b[39minit_args)\n\u001b[1;32m    844\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mput_variable(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m, name, value)\n",
      "\u001b[0;31mScopeParamNotFoundError\u001b[0m: Could not find parameter named \"scale\" in scope \"/transformer/h/0/ln_1\". (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.ScopeParamNotFoundError)"
     ]
    }
   ],
   "source": [
    "from EasyLM.jax_utils import JaxRNG\n",
    "hf_model.generate(\n",
    "    A,\n",
    "    params={'transformer': train_state.params['params']},\n",
    "    max_new_tokens=1,\n",
    "    # num_return_sequences=5,\n",
    "    # beam\n",
    "    prng_key=JaxRNG(key))\n",
    "    # logits_processor=FlaxLogitsProcessorList(\n",
    "    #     [FlaxTemperatureLogitsWarper(temperature)]\n",
    "    # ),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenDict({\n",
       "    attn: {\n",
       "        c_attn: {\n",
       "            bias: Array([-0.00806067, -0.08205216,  0.17712198, ..., -0.03094645,\n",
       "                   -0.02834609,  0.0028557 ], dtype=float32),\n",
       "            kernel: Array([[ 0.16554965,  0.12297295,  0.10031797, ..., -0.00807998,\n",
       "                     0.0106448 , -0.01827521],\n",
       "                   [-0.23444045,  0.14132349,  0.07059898, ..., -0.0105182 ,\n",
       "                     0.02387178, -0.01008427],\n",
       "                   [ 0.1062863 , -0.03969869,  0.10846853, ..., -0.00417321,\n",
       "                     0.01832751, -0.00796596],\n",
       "                   ...,\n",
       "                   [ 0.00202721,  0.12571906, -0.07979144, ...,  0.00236412,\n",
       "                     0.03511722,  0.02043647],\n",
       "                   [-0.11458338, -0.08969299, -0.09247336, ...,  0.00126929,\n",
       "                     0.00066453, -0.0041295 ],\n",
       "                   [ 0.02215027, -0.01706643, -0.04627626, ...,  0.02902106,\n",
       "                     0.02582104, -0.0327217 ]], dtype=float32),\n",
       "        },\n",
       "        c_proj: {\n",
       "            bias: Array([-0.01144728,  0.0365472 , -0.00156556, ...,  0.02736477,\n",
       "                   -0.00746843,  0.03922034], dtype=float32),\n",
       "            kernel: Array([[ 0.01133492,  0.01151626, -0.02100956, ..., -0.01405654,\n",
       "                    -0.00335612,  0.02988927],\n",
       "                   [-0.01268945, -0.02229757, -0.05776289, ...,  0.07052165,\n",
       "                    -0.04539669, -0.01878756],\n",
       "                   [ 0.03793592,  0.01945222,  0.03890876, ...,  0.00468673,\n",
       "                     0.04275589, -0.0749495 ],\n",
       "                   ...,\n",
       "                   [-0.01771595,  0.01020293,  0.01688005, ...,  0.03490546,\n",
       "                     0.01065123,  0.00949867],\n",
       "                   [-0.00328715, -0.01875043,  0.01664503, ...,  0.00446178,\n",
       "                    -0.01593386, -0.02856372],\n",
       "                   [ 0.02454931,  0.00220935, -0.01772885, ...,  0.01188086,\n",
       "                     0.0213084 , -0.03635458]], dtype=float32),\n",
       "        },\n",
       "    },\n",
       "    ln_1: {\n",
       "        bias: Array([ 0.01123354, -0.01417697,  0.00650295, ..., -0.01851034,\n",
       "               -0.01368136, -0.02099491], dtype=float32),\n",
       "        scale: Array([0.28894216, 0.28614348, 0.3010614 , ..., 0.2696827 , 0.2500453 ,\n",
       "               0.17852534], dtype=float32),\n",
       "    },\n",
       "    ln_2: {\n",
       "        bias: Array([-0.03590904, -0.03210072,  0.00026501, ...,  0.09937602,\n",
       "               -0.1393274 , -0.01080626], dtype=float32),\n",
       "        scale: Array([0.5264808 , 0.39997444, 0.36181778, ..., 0.44054303, 0.3055512 ,\n",
       "               0.18258318], dtype=float32),\n",
       "    },\n",
       "    mlp: {\n",
       "        c_fc: {\n",
       "            bias: Array([-0.06916936, -0.07838885, -0.06607128, ..., -0.1051634 ,\n",
       "                   -0.08991828, -0.06540737], dtype=float32),\n",
       "            kernel: Array([[-0.05826445,  0.05596583, -0.04735798, ..., -0.03835429,\n",
       "                    -0.09354223, -0.12613678],\n",
       "                   [-0.02078129, -0.02883946,  0.04853408, ..., -0.00435286,\n",
       "                    -0.11046726,  0.08467893],\n",
       "                   [-0.08321944,  0.04720354,  0.05368477, ...,  0.01881366,\n",
       "                     0.03279455, -0.10345227],\n",
       "                   ...,\n",
       "                   [-0.06757478, -0.07983246,  0.02246903, ..., -0.06725591,\n",
       "                    -0.00235579, -0.03377793],\n",
       "                   [ 0.08242241,  0.03676083, -0.00670699, ...,  0.06006376,\n",
       "                     0.04302322,  0.02327235],\n",
       "                   [ 0.00864029,  0.0176181 ,  0.0452676 , ..., -0.00238721,\n",
       "                    -0.02418141,  0.01996941]], dtype=float32),\n",
       "        },\n",
       "        c_proj: {\n",
       "            bias: Array([ 0.00972492, -0.01897503,  0.0156537 , ...,  0.05783964,\n",
       "                    0.07669863, -0.010941  ], dtype=float32),\n",
       "            kernel: Array([[-0.01274799,  0.02626904, -0.00082694, ..., -0.02880153,\n",
       "                     0.03149987,  0.00739569],\n",
       "                   [ 0.01002527, -0.01385257,  0.0118017 , ..., -0.03952581,\n",
       "                    -0.00903307,  0.02651956],\n",
       "                   [-0.01568741, -0.00441044,  0.00713749, ..., -0.00524011,\n",
       "                    -0.00363431, -0.00045721],\n",
       "                   ...,\n",
       "                   [-0.03739459,  0.02904921, -0.04266255, ...,  0.02816904,\n",
       "                     0.04983811,  0.05676064],\n",
       "                   [ 0.01019448,  0.01065494, -0.00303075, ...,  0.02857824,\n",
       "                    -0.00311145,  0.04820529],\n",
       "                   [-0.03020904, -0.00878521, -0.02111002, ..., -0.04214809,\n",
       "                    -0.00373292,  0.00824505]], dtype=float32),\n",
       "        },\n",
       "    },\n",
       "})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_state.params['params']['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax.core import FrozenDict, freeze, unfreeze\n",
    "params = unfreeze(train_state.params['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'transformer': FrozenDict({\n",
       "     params: {\n",
       "         0: {\n",
       "             attn: {\n",
       "                 c_attn: {\n",
       "                     bias: Array([-0.00806067, -0.08205216,  0.17712198, ..., -0.03094645,\n",
       "                            -0.02834609,  0.0028557 ], dtype=float32),\n",
       "                     kernel: Array([[ 0.16554965,  0.12297295,  0.10031797, ..., -0.00807998,\n",
       "                              0.0106448 , -0.01827521],\n",
       "                            [-0.23444045,  0.14132349,  0.07059898, ..., -0.0105182 ,\n",
       "                              0.02387178, -0.01008427],\n",
       "                            [ 0.1062863 , -0.03969869,  0.10846853, ..., -0.00417321,\n",
       "                              0.01832751, -0.00796596],\n",
       "                            ...,\n",
       "                            [ 0.00202721,  0.12571906, -0.07979144, ...,  0.00236412,\n",
       "                              0.03511722,  0.02043647],\n",
       "                            [-0.11458338, -0.08969299, -0.09247336, ...,  0.00126929,\n",
       "                              0.00066453, -0.0041295 ],\n",
       "                            [ 0.02215027, -0.01706643, -0.04627626, ...,  0.02902106,\n",
       "                              0.02582104, -0.0327217 ]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([-0.01144728,  0.0365472 , -0.00156556, ...,  0.02736477,\n",
       "                            -0.00746843,  0.03922034], dtype=float32),\n",
       "                     kernel: Array([[ 0.01133492,  0.01151626, -0.02100956, ..., -0.01405654,\n",
       "                             -0.00335612,  0.02988927],\n",
       "                            [-0.01268945, -0.02229757, -0.05776289, ...,  0.07052165,\n",
       "                             -0.04539669, -0.01878756],\n",
       "                            [ 0.03793592,  0.01945222,  0.03890876, ...,  0.00468673,\n",
       "                              0.04275589, -0.0749495 ],\n",
       "                            ...,\n",
       "                            [-0.01771595,  0.01020293,  0.01688005, ...,  0.03490546,\n",
       "                              0.01065123,  0.00949867],\n",
       "                            [-0.00328715, -0.01875043,  0.01664503, ...,  0.00446178,\n",
       "                             -0.01593386, -0.02856372],\n",
       "                            [ 0.02454931,  0.00220935, -0.01772885, ...,  0.01188086,\n",
       "                              0.0213084 , -0.03635458]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "             ln_1: {\n",
       "                 bias: Array([ 0.01123354, -0.01417697,  0.00650295, ..., -0.01851034,\n",
       "                        -0.01368136, -0.02099491], dtype=float32),\n",
       "                 scale: Array([0.28894216, 0.28614348, 0.3010614 , ..., 0.2696827 , 0.2500453 ,\n",
       "                        0.17852534], dtype=float32),\n",
       "             },\n",
       "             ln_2: {\n",
       "                 bias: Array([-0.03590904, -0.03210072,  0.00026501, ...,  0.09937602,\n",
       "                        -0.1393274 , -0.01080626], dtype=float32),\n",
       "                 scale: Array([0.5264808 , 0.39997444, 0.36181778, ..., 0.44054303, 0.3055512 ,\n",
       "                        0.18258318], dtype=float32),\n",
       "             },\n",
       "             mlp: {\n",
       "                 c_fc: {\n",
       "                     bias: Array([-0.06916936, -0.07838885, -0.06607128, ..., -0.1051634 ,\n",
       "                            -0.08991828, -0.06540737], dtype=float32),\n",
       "                     kernel: Array([[-0.05826445,  0.05596583, -0.04735798, ..., -0.03835429,\n",
       "                             -0.09354223, -0.12613678],\n",
       "                            [-0.02078129, -0.02883946,  0.04853408, ..., -0.00435286,\n",
       "                             -0.11046726,  0.08467893],\n",
       "                            [-0.08321944,  0.04720354,  0.05368477, ...,  0.01881366,\n",
       "                              0.03279455, -0.10345227],\n",
       "                            ...,\n",
       "                            [-0.06757478, -0.07983246,  0.02246903, ..., -0.06725591,\n",
       "                             -0.00235579, -0.03377793],\n",
       "                            [ 0.08242241,  0.03676083, -0.00670699, ...,  0.06006376,\n",
       "                              0.04302322,  0.02327235],\n",
       "                            [ 0.00864029,  0.0176181 ,  0.0452676 , ..., -0.00238721,\n",
       "                             -0.02418141,  0.01996941]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([ 0.00972492, -0.01897503,  0.0156537 , ...,  0.05783964,\n",
       "                             0.07669863, -0.010941  ], dtype=float32),\n",
       "                     kernel: Array([[-0.01274799,  0.02626904, -0.00082694, ..., -0.02880153,\n",
       "                              0.03149987,  0.00739569],\n",
       "                            [ 0.01002527, -0.01385257,  0.0118017 , ..., -0.03952581,\n",
       "                             -0.00903307,  0.02651956],\n",
       "                            [-0.01568741, -0.00441044,  0.00713749, ..., -0.00524011,\n",
       "                             -0.00363431, -0.00045721],\n",
       "                            ...,\n",
       "                            [-0.03739459,  0.02904921, -0.04266255, ...,  0.02816904,\n",
       "                              0.04983811,  0.05676064],\n",
       "                            [ 0.01019448,  0.01065494, -0.00303075, ...,  0.02857824,\n",
       "                             -0.00311145,  0.04820529],\n",
       "                            [-0.03020904, -0.00878521, -0.02111002, ..., -0.04214809,\n",
       "                             -0.00373292,  0.00824505]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "         },\n",
       "         1: {\n",
       "             attn: {\n",
       "                 c_attn: {\n",
       "                     bias: Array([-0.15221442,  0.01095768, -0.23043919, ..., -0.00835071,\n",
       "                             0.03358821,  0.01850057], dtype=float32),\n",
       "                     kernel: Array([[ 0.05648328, -0.00820094,  0.0184177 , ...,  0.03831045,\n",
       "                              0.03213073,  0.02756165],\n",
       "                            [-0.00723719, -0.05333716,  0.02396652, ..., -0.01274015,\n",
       "                              0.02572118, -0.01649939],\n",
       "                            [ 0.00342849,  0.10700248,  0.10875006, ..., -0.02115568,\n",
       "                             -0.01257164, -0.08181655],\n",
       "                            ...,\n",
       "                            [ 0.00542727,  0.04644989,  0.08896411, ...,  0.01239162,\n",
       "                              0.02527379, -0.05462379],\n",
       "                            [ 0.04328296,  0.00314054, -0.03231358, ..., -0.02769008,\n",
       "                             -0.01280828,  0.02894634],\n",
       "                            [-0.00496276,  0.07774284,  0.0854713 , ..., -0.03763867,\n",
       "                              0.01962829,  0.00598486]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([-0.04615428,  0.017907  , -0.01985262, ...,  0.03903442,\n",
       "                             0.02395037,  0.02489467], dtype=float32),\n",
       "                     kernel: Array([[ 0.00078996, -0.03916684,  0.04177172, ..., -0.00443744,\n",
       "                              0.04831451,  0.00962692],\n",
       "                            [-0.02006885, -0.04995507, -0.00773344, ...,  0.00564303,\n",
       "                              0.00035719, -0.02479497],\n",
       "                            [-0.01078508, -0.04603594,  0.0243956 , ..., -0.03822174,\n",
       "                             -0.01219875, -0.00359934],\n",
       "                            ...,\n",
       "                            [ 0.01995835, -0.0357382 , -0.03967066, ...,  0.00707609,\n",
       "                              0.01422159,  0.01574153],\n",
       "                            [-0.04572298,  0.01973083, -0.02893983, ...,  0.00773961,\n",
       "                              0.02075595,  0.0260431 ],\n",
       "                            [ 0.03402839, -0.00668523,  0.00700167, ..., -0.00115951,\n",
       "                             -0.02514695, -0.01453887]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "             ln_1: {\n",
       "                 bias: Array([-0.02744458, -0.03141211, -0.00919125, ..., -0.08943131,\n",
       "                        -0.0028525 , -0.04665478], dtype=float32),\n",
       "                 scale: Array([0.32519576, 0.29430196, 0.30102807, ..., 0.29273573, 0.31316203,\n",
       "                        0.24549317], dtype=float32),\n",
       "             },\n",
       "             ln_2: {\n",
       "                 bias: Array([-0.05924468, -0.13904998,  0.030359  , ..., -0.06406971,\n",
       "                         0.08530246,  0.0532798 ], dtype=float32),\n",
       "                 scale: Array([0.5187359 , 0.56037366, 0.50791335, ..., 0.47782436, 0.5095422 ,\n",
       "                        0.4608667 ], dtype=float32),\n",
       "             },\n",
       "             mlp: {\n",
       "                 c_fc: {\n",
       "                     bias: Array([-0.07522187, -0.05820139, -0.06714217, ..., -0.0582825 ,\n",
       "                            -0.04431867, -0.05334959], dtype=float32),\n",
       "                     kernel: Array([[-0.0703942 ,  0.01365506,  0.04085029, ..., -0.10386319,\n",
       "                              0.05268864, -0.01472998],\n",
       "                            [ 0.12879956,  0.0080748 ,  0.01101163, ...,  0.00658144,\n",
       "                              0.04330568, -0.08233353],\n",
       "                            [ 0.06688353,  0.07956184, -0.01715781, ..., -0.08282135,\n",
       "                              0.05210731,  0.08956587],\n",
       "                            ...,\n",
       "                            [-0.03726161,  0.06388754,  0.02094175, ..., -0.07959186,\n",
       "                              0.05303093,  0.00329315],\n",
       "                            [ 0.07952193, -0.05651461, -0.02610541, ..., -0.00235022,\n",
       "                             -0.01674673,  0.02773261],\n",
       "                            [ 0.02265811, -0.03944816, -0.02741184, ..., -0.03755923,\n",
       "                             -0.00838341,  0.04821151]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([-0.02518303, -0.03152892,  0.0166734 , ...,  0.0337945 ,\n",
       "                             0.08174776,  0.02485966], dtype=float32),\n",
       "                     kernel: Array([[-0.05596184,  0.07087243,  0.04496761, ..., -0.00850271,\n",
       "                              0.04207072, -0.02529795],\n",
       "                            [-0.02415441,  0.01400976,  0.02816896, ..., -0.03867916,\n",
       "                             -0.03825453, -0.06184343],\n",
       "                            [-0.02115076,  0.01171318, -0.06511842, ...,  0.04453088,\n",
       "                             -0.0122576 , -0.00622782],\n",
       "                            ...,\n",
       "                            [-0.00683815, -0.01605837, -0.0849003 , ..., -0.01226597,\n",
       "                              0.05680716, -0.00716699],\n",
       "                            [ 0.00016359, -0.03679368,  0.00314977, ..., -0.00375592,\n",
       "                             -0.06710148,  0.0506695 ],\n",
       "                            [-0.00996248, -0.07275025, -0.01918012, ..., -0.0437047 ,\n",
       "                             -0.00232847,  0.00581692]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "         },\n",
       "         10: {\n",
       "             attn: {\n",
       "                 c_attn: {\n",
       "                     bias: Array([-0.04080461, -0.07718921, -0.15175544, ..., -0.0220191 ,\n",
       "                             0.00996731, -0.00490939], dtype=float32),\n",
       "                     kernel: Array([[-0.00479335, -0.00132569, -0.04203443, ...,  0.04508255,\n",
       "                              0.00790615,  0.0202021 ],\n",
       "                            [-0.01202896, -0.05051075,  0.04272674, ..., -0.07448006,\n",
       "                              0.0148204 , -0.01263014],\n",
       "                            [ 0.04470937, -0.0774451 ,  0.06933478, ..., -0.01431647,\n",
       "                              0.00207525, -0.03490788],\n",
       "                            ...,\n",
       "                            [-0.17054637,  0.04291749, -0.04544777, ..., -0.06788059,\n",
       "                             -0.0069812 ,  0.03388384],\n",
       "                            [-0.07155348, -0.05328591,  0.01813143, ..., -0.04170485,\n",
       "                             -0.02220802, -0.01291933],\n",
       "                            [ 0.07825941,  0.01665433,  0.00520321, ...,  0.00979957,\n",
       "                             -0.02899147, -0.04879507]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([ 0.00650678, -0.02772267, -0.04727175, ...,  0.01179967,\n",
       "                            -0.03915552, -0.0050743 ], dtype=float32),\n",
       "                     kernel: Array([[ 0.03063137,  0.02845792,  0.00240159, ..., -0.00018538,\n",
       "                              0.09022441,  0.01936903],\n",
       "                            [ 0.02345913,  0.03615752,  0.03355216, ...,  0.00961557,\n",
       "                              0.02655307,  0.00951734],\n",
       "                            [ 0.0199417 ,  0.00896413,  0.03303835, ...,  0.0110226 ,\n",
       "                              0.00855461, -0.03826226],\n",
       "                            ...,\n",
       "                            [-0.03387058, -0.04939462,  0.01545185, ..., -0.08127665,\n",
       "                              0.04799291,  0.00282397],\n",
       "                            [-0.01989695, -0.03137016,  0.01526937, ..., -0.05886317,\n",
       "                              0.00660869,  0.07253707],\n",
       "                            [ 0.03661846, -0.05735151,  0.09407931, ...,  0.01290271,\n",
       "                              0.01282345,  0.09664333]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "             ln_1: {\n",
       "                 bias: Array([-0.06141328,  0.00859376,  0.02491324, ..., -0.09833977,\n",
       "                        -0.05845266, -0.01735953], dtype=float32),\n",
       "                 scale: Array([0.5137233 , 0.56979156, 0.5624747 , ..., 0.50404686, 0.5669546 ,\n",
       "                        0.517687  ], dtype=float32),\n",
       "             },\n",
       "             ln_2: {\n",
       "                 bias: Array([-0.03892346, -0.02554949, -0.00836867, ...,  0.0477081 ,\n",
       "                        -0.02907988,  0.02176111], dtype=float32),\n",
       "                 scale: Array([0.57963824, 0.62132114, 0.62432706, ..., 0.61740416, 0.5914682 ,\n",
       "                        0.58374333], dtype=float32),\n",
       "             },\n",
       "             mlp: {\n",
       "                 c_fc: {\n",
       "                     bias: Array([-0.04945495,  0.01051492, -0.01495147, ..., -0.05225803,\n",
       "                            -0.02489247, -0.05665023], dtype=float32),\n",
       "                     kernel: Array([[-0.01785805,  0.01508116, -0.05762998, ..., -0.01115686,\n",
       "                             -0.02296064,  0.00452235],\n",
       "                            [-0.02689639, -0.02354559,  0.04601995, ..., -0.01112436,\n",
       "                              0.07838295, -0.00160224],\n",
       "                            [ 0.01566927,  0.01166441,  0.00149262, ...,  0.00089247,\n",
       "                              0.09065341, -0.06437218],\n",
       "                            ...,\n",
       "                            [-0.04589159,  0.02365166, -0.01944812, ...,  0.03789217,\n",
       "                             -0.020658  , -0.03684991],\n",
       "                            [ 0.01831101, -0.01951984, -0.04429929, ..., -0.01661546,\n",
       "                              0.01301058,  0.02674057],\n",
       "                            [ 0.03881139, -0.04226046, -0.06425739, ...,  0.0638937 ,\n",
       "                             -0.09095677, -0.00689567]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([-0.01966968,  0.01288934, -0.03721309, ...,  0.01364874,\n",
       "                             0.0628769 ,  0.00912754], dtype=float32),\n",
       "                     kernel: Array([[-0.03900837,  0.03282987, -0.03972655, ..., -0.00122669,\n",
       "                             -0.07839051,  0.09027483],\n",
       "                            [ 0.00055024,  0.03367782, -0.01416857, ..., -0.03295363,\n",
       "                             -0.01269747,  0.0029632 ],\n",
       "                            [ 0.03986463, -0.01264496, -0.01394006, ...,  0.00390149,\n",
       "                             -0.05020611,  0.01596411],\n",
       "                            ...,\n",
       "                            [ 0.01185579, -0.03495461,  0.01480764, ..., -0.04205432,\n",
       "                             -0.02039161, -0.03563129],\n",
       "                            [ 0.04320986, -0.02958493,  0.02765253, ..., -0.03178728,\n",
       "                             -0.09124048, -0.00643804],\n",
       "                            [ 0.0158034 , -0.02507996, -0.00090553, ..., -0.05512653,\n",
       "                              0.03718148, -0.05068055]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "         },\n",
       "         11: {\n",
       "             attn: {\n",
       "                 c_attn: {\n",
       "                     bias: Array([ 0.08216132, -0.2787813 ,  0.00240535, ..., -0.02939795,\n",
       "                            -0.04381726,  0.03517448], dtype=float32),\n",
       "                     kernel: Array([[-2.3641534e-02,  4.8397236e-02,  7.3503517e-02, ...,\n",
       "                              3.5170823e-02, -1.0740984e-03, -2.9485349e-02],\n",
       "                            [ 4.7159624e-06, -1.1939659e-02,  1.0503781e-01, ...,\n",
       "                             -4.8753638e-02, -1.1644880e-02,  4.2994633e-02],\n",
       "                            [ 3.5593044e-02,  1.1499417e-02, -4.0781781e-02, ...,\n",
       "                             -4.0952768e-02,  3.3861399e-02,  3.0423608e-02],\n",
       "                            ...,\n",
       "                            [ 2.3100436e-02, -6.0298208e-02,  4.7042143e-02, ...,\n",
       "                             -4.1135564e-03,  1.4285636e-02,  1.6399583e-02],\n",
       "                            [ 5.1647082e-02, -1.7622488e-02,  6.6187464e-02, ...,\n",
       "                             -6.4344198e-02,  1.5939150e-02, -3.8249495e-03],\n",
       "                            [ 6.0339592e-02,  1.1173524e-02, -1.8148858e-03, ...,\n",
       "                              1.5407859e-02, -8.2472162e-03, -5.2519396e-02]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([ 0.02843465, -0.02680702, -0.01752011, ...,  0.04422934,\n",
       "                            -0.0533591 , -0.01508961], dtype=float32),\n",
       "                     kernel: Array([[-0.07068628, -0.07268307,  0.04269625, ...,  0.00270801,\n",
       "                             -0.02614275, -0.01743949],\n",
       "                            [-0.04725822,  0.04434793,  0.00130237, ...,  0.01302077,\n",
       "                             -0.13991177, -0.02293073],\n",
       "                            [-0.08465846,  0.0723771 ,  0.02100891, ..., -0.01132751,\n",
       "                             -0.00132156,  0.02864205],\n",
       "                            ...,\n",
       "                            [ 0.03447222,  0.02388291, -0.05652814, ..., -0.02078103,\n",
       "                              0.05708794, -0.05843983],\n",
       "                            [ 0.00572036, -0.00387417,  0.0380336 , ..., -0.0357677 ,\n",
       "                              0.0235411 ,  0.07345138],\n",
       "                            [ 0.00492027,  0.05657439, -0.0037644 , ..., -0.00816522,\n",
       "                             -0.07441767, -0.03691623]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "             ln_1: {\n",
       "                 bias: Array([-0.04531281, -0.00116194,  0.01328455, ..., -0.08040501,\n",
       "                        -0.03843191, -0.01640207], dtype=float32),\n",
       "                 scale: Array([0.5306269 , 0.60082746, 0.59228843, ..., 0.5359313 , 0.57682073,\n",
       "                        0.5358808 ], dtype=float32),\n",
       "             },\n",
       "             ln_2: {\n",
       "                 bias: Array([-0.02953761, -0.02844948,  0.00662402, ...,  0.03107951,\n",
       "                        -0.03752177, -0.00972608], dtype=float32),\n",
       "                 scale: Array([0.5842558 , 0.6259466 , 0.61913276, ..., 0.60055494, 0.60199314,\n",
       "                        0.5799073 ], dtype=float32),\n",
       "             },\n",
       "             mlp: {\n",
       "                 c_fc: {\n",
       "                     bias: Array([-0.0224683 , -0.0446638 , -0.02085384, ..., -0.04234136,\n",
       "                            -0.01850928, -0.02669665], dtype=float32),\n",
       "                     kernel: Array([[-0.04481823, -0.00666006,  0.0592739 , ...,  0.00427937,\n",
       "                              0.10478002,  0.0703317 ],\n",
       "                            [-0.0267386 , -0.02322425,  0.07347081, ...,  0.07984737,\n",
       "                              0.0534104 ,  0.00641609],\n",
       "                            [-0.05182305, -0.01090039,  0.00767706, ..., -0.05703215,\n",
       "                             -0.02470314,  0.047876  ],\n",
       "                            ...,\n",
       "                            [ 0.02627215, -0.01555202,  0.00571381, ..., -0.11239578,\n",
       "                             -0.09141164, -0.00065436],\n",
       "                            [ 0.03095721,  0.10020607,  0.03333818, ..., -0.05400025,\n",
       "                             -0.02335504, -0.07823371],\n",
       "                            [-0.04139381, -0.04041535, -0.04743649, ...,  0.01311496,\n",
       "                             -0.0444278 ,  0.03646507]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([-0.03138011,  0.01918339, -0.02343526, ...,  0.06360199,\n",
       "                             0.07930812,  0.01002682], dtype=float32),\n",
       "                     kernel: Array([[ 0.06328346,  0.04802571,  0.00973613, ..., -0.06457866,\n",
       "                             -0.02343956, -0.04323669],\n",
       "                            [-0.08780432, -0.00079652,  0.01067618, ...,  0.00576174,\n",
       "                             -0.06552052,  0.07537213],\n",
       "                            [-0.04725235,  0.04497549,  0.0088134 , ..., -0.01054425,\n",
       "                              0.00491123, -0.00473899],\n",
       "                            ...,\n",
       "                            [ 0.02598622,  0.02766568,  0.0641607 , ...,  0.04874231,\n",
       "                              0.03094967, -0.04911152],\n",
       "                            [ 0.07454233, -0.01582464,  0.05552405, ...,  0.00572374,\n",
       "                              0.02921151, -0.05030822],\n",
       "                            [-0.02923473,  0.02092226, -0.00599086, ...,  0.06672021,\n",
       "                             -0.03474342,  0.01365133]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "         },\n",
       "         12: {\n",
       "             attn: {\n",
       "                 c_attn: {\n",
       "                     bias: Array([ 0.12299426, -0.184287  ,  0.26151222, ..., -0.00683284,\n",
       "                            -0.07544196,  0.00894361], dtype=float32),\n",
       "                     kernel: Array([[-0.03474717,  0.00353902, -0.05712533, ..., -0.04756834,\n",
       "                             -0.02430536, -0.02936494],\n",
       "                            [-0.05852483, -0.02157543, -0.03658486, ...,  0.05035137,\n",
       "                              0.0522799 , -0.02588421],\n",
       "                            [ 0.03179704, -0.1149386 ,  0.07995942, ..., -0.03568374,\n",
       "                              0.06074085, -0.04198913],\n",
       "                            ...,\n",
       "                            [ 0.02931324, -0.10709326, -0.00146191, ...,  0.01639125,\n",
       "                              0.00131351,  0.00801613],\n",
       "                            [-0.00024241,  0.04824437,  0.04238468, ..., -0.01612266,\n",
       "                             -0.06915127,  0.01957951],\n",
       "                            [ 0.0381825 ,  0.10879927, -0.02472522, ...,  0.04368649,\n",
       "                             -0.04482374,  0.00803844]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([ 0.03974715, -0.03452854, -0.03154601, ...,  0.01496288,\n",
       "                            -0.04640816, -0.02962504], dtype=float32),\n",
       "                     kernel: Array([[-0.01172845,  0.00632814, -0.02107371, ..., -0.01418296,\n",
       "                             -0.00778306, -0.03818242],\n",
       "                            [-0.06466147, -0.0394574 ,  0.02690187, ..., -0.00992361,\n",
       "                             -0.0191968 , -0.00242336],\n",
       "                            [ 0.03623599,  0.03072228, -0.04458829, ..., -0.02639194,\n",
       "                              0.01574786, -0.00121706],\n",
       "                            ...,\n",
       "                            [-0.04471008,  0.02216492, -0.02340258, ...,  0.01504582,\n",
       "                             -0.00557137, -0.00079484],\n",
       "                            [-0.00677561,  0.03572289,  0.03940831, ...,  0.0421639 ,\n",
       "                             -0.01860869,  0.07799532],\n",
       "                            [-0.04963832,  0.03140756,  0.01899813, ..., -0.00927565,\n",
       "                              0.03350029, -0.02922556]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "             ln_1: {\n",
       "                 bias: Array([-0.05159141,  0.01105144,  0.00522923, ..., -0.06591412,\n",
       "                        -0.04077315,  0.00055683], dtype=float32),\n",
       "                 scale: Array([0.56447566, 0.6292986 , 0.6230969 , ..., 0.5553503 , 0.6110171 ,\n",
       "                        0.54496133], dtype=float32),\n",
       "             },\n",
       "             ln_2: {\n",
       "                 bias: Array([-0.02517112, -0.02514378, -0.00839094, ...,  0.04163821,\n",
       "                        -0.03537562, -0.00272218], dtype=float32),\n",
       "                 scale: Array([0.5878193 , 0.63076633, 0.6026071 , ..., 0.61274195, 0.5920684 ,\n",
       "                        0.57616824], dtype=float32),\n",
       "             },\n",
       "             mlp: {\n",
       "                 c_fc: {\n",
       "                     bias: Array([-0.04504516, -0.00571183, -0.0468177 , ..., -0.06165791,\n",
       "                            -0.02765983, -0.01686798], dtype=float32),\n",
       "                     kernel: Array([[-0.01947145,  0.06370453, -0.05394315, ...,  0.02050863,\n",
       "                             -0.00283609,  0.09302493],\n",
       "                            [ 0.10826769,  0.01827519,  0.08425028, ...,  0.07435062,\n",
       "                             -0.08223365, -0.03062759],\n",
       "                            [-0.04930572,  0.00732959,  0.05585071, ..., -0.1004809 ,\n",
       "                             -0.11361367,  0.02092138],\n",
       "                            ...,\n",
       "                            [ 0.01292847,  0.01292049, -0.0120545 , ..., -0.06885964,\n",
       "                              0.04187072, -0.00430242],\n",
       "                            [-0.03170065,  0.06560142,  0.04734454, ...,  0.03860266,\n",
       "                              0.04266933,  0.0203819 ],\n",
       "                            [-0.01496349, -0.09963284,  0.08137452, ..., -0.02364421,\n",
       "                              0.0397064 ,  0.0442394 ]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([-0.01845087,  0.0307041 , -0.02624524, ...,  0.05157044,\n",
       "                             0.06732557,  0.01303174], dtype=float32),\n",
       "                     kernel: Array([[ 0.00686402, -0.01500038,  0.02175774, ...,  0.0279593 ,\n",
       "                             -0.02731259, -0.08490762],\n",
       "                            [-0.04589384,  0.01333066,  0.01347873, ...,  0.03463618,\n",
       "                             -0.06065419, -0.01927627],\n",
       "                            [ 0.01356318,  0.06413703,  0.13936496, ...,  0.0234638 ,\n",
       "                             -0.01015852,  0.10115299],\n",
       "                            ...,\n",
       "                            [ 0.04954747,  0.01615694,  0.03055972, ...,  0.12346602,\n",
       "                             -0.00590912, -0.01126262],\n",
       "                            [ 0.02965624,  0.00400169, -0.0379669 , ...,  0.07632636,\n",
       "                             -0.0136329 ,  0.02945822],\n",
       "                            [-0.0666199 , -0.00906846, -0.00801489, ..., -0.0254179 ,\n",
       "                             -0.06497089,  0.00219491]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "         },\n",
       "         13: {\n",
       "             attn: {\n",
       "                 c_attn: {\n",
       "                     bias: Array([-0.0795717 , -0.03023933, -0.13671741, ..., -0.02698805,\n",
       "                            -0.02192132,  0.01308422], dtype=float32),\n",
       "                     kernel: Array([[-0.02415415, -0.02305377, -0.01624553, ...,  0.03782823,\n",
       "                              0.03119259,  0.03190112],\n",
       "                            [ 0.06116689, -0.01990154, -0.08277386, ...,  0.0380396 ,\n",
       "                              0.01675987, -0.04198169],\n",
       "                            [ 0.04433751,  0.02085204,  0.01533541, ...,  0.00381871,\n",
       "                             -0.03204243, -0.03576047],\n",
       "                            ...,\n",
       "                            [-0.01946968, -0.0260176 ,  0.03764519, ...,  0.02787543,\n",
       "                              0.02389436,  0.06573683],\n",
       "                            [ 0.12149373,  0.11523713,  0.04224609, ..., -0.04272938,\n",
       "                              0.02718995,  0.06937455],\n",
       "                            [ 0.08535403,  0.11083972, -0.01973135, ..., -0.02918736,\n",
       "                              0.02367611,  0.02301224]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([ 0.03123099, -0.0347474 , -0.03693533, ...,  0.01940632,\n",
       "                            -0.05731378,  0.00786146], dtype=float32),\n",
       "                     kernel: Array([[ 0.01365361, -0.02699938, -0.01121048, ...,  0.02664542,\n",
       "                             -0.00524798,  0.00144671],\n",
       "                            [ 0.04910294, -0.02686666, -0.05135619, ...,  0.12989976,\n",
       "                              0.01530387,  0.03365735],\n",
       "                            [ 0.00187339, -0.069203  ,  0.03804833, ..., -0.01325484,\n",
       "                             -0.05691804,  0.06903437],\n",
       "                            ...,\n",
       "                            [ 0.00219241,  0.0155016 , -0.01194874, ..., -0.0267779 ,\n",
       "                             -0.02892381,  0.01065322],\n",
       "                            [ 0.05508557, -0.0273806 , -0.00090698, ...,  0.00507875,\n",
       "                             -0.07229756, -0.01807385],\n",
       "                            [-0.01618735, -0.04051318, -0.05699953, ...,  0.05299103,\n",
       "                              0.00624676,  0.0539774 ]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "             ln_1: {\n",
       "                 bias: Array([-0.05322461,  0.01581346,  0.01472449, ..., -0.06996385,\n",
       "                        -0.0399303 , -0.00205303], dtype=float32),\n",
       "                 scale: Array([0.54511493, 0.61186713, 0.5960732 , ..., 0.5309154 , 0.5986662 ,\n",
       "                        0.5449892 ], dtype=float32),\n",
       "             },\n",
       "             ln_2: {\n",
       "                 bias: Array([-0.0090737 , -0.0098378 , -0.00285295, ...,  0.01649527,\n",
       "                        -0.02240202, -0.00646661], dtype=float32),\n",
       "                 scale: Array([0.5842374 , 0.6113272 , 0.5938304 , ..., 0.600974  , 0.60682285,\n",
       "                        0.55696756], dtype=float32),\n",
       "             },\n",
       "             mlp: {\n",
       "                 c_fc: {\n",
       "                     bias: Array([-0.02252994,  0.02165669, -0.04036262, ..., -0.01902207,\n",
       "                            -0.04258557, -0.01639398], dtype=float32),\n",
       "                     kernel: Array([[-0.0330304 ,  0.03866616,  0.0413758 , ..., -0.03505942,\n",
       "                             -0.0112699 ,  0.04805267],\n",
       "                            [ 0.05069845, -0.05950059,  0.03043535, ..., -0.02239985,\n",
       "                              0.04851473,  0.02236566],\n",
       "                            [-0.11180028,  0.00196735,  0.057693  , ...,  0.04116398,\n",
       "                              0.04358735,  0.01583692],\n",
       "                            ...,\n",
       "                            [-0.03732176, -0.00967757,  0.11824278, ..., -0.02827776,\n",
       "                              0.01647307,  0.0274428 ],\n",
       "                            [-0.1233115 , -0.05199094, -0.00291255, ...,  0.07022577,\n",
       "                             -0.0229232 , -0.07045428],\n",
       "                            [ 0.01138512,  0.05295819,  0.01514796, ...,  0.0168984 ,\n",
       "                              0.00742981, -0.02325214]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([-0.0083001 ,  0.03119227, -0.00175285, ...,  0.06413975,\n",
       "                             0.06854547, -0.00148985], dtype=float32),\n",
       "                     kernel: Array([[-0.02870024, -0.01369158, -0.01780003, ..., -0.05608802,\n",
       "                             -0.02154804, -0.0534595 ],\n",
       "                            [-0.03268072,  0.00445412, -0.03081812, ...,  0.00635822,\n",
       "                             -0.0042883 , -0.01849338],\n",
       "                            [-0.01824117,  0.02951688,  0.01239371, ...,  0.05649399,\n",
       "                             -0.02543503,  0.08189747],\n",
       "                            ...,\n",
       "                            [ 0.01664531, -0.03242241, -0.01334182, ...,  0.02023414,\n",
       "                              0.041157  ,  0.01686631],\n",
       "                            [ 0.05035868,  0.07041977,  0.01863884, ..., -0.01447813,\n",
       "                              0.0523393 ,  0.03248092],\n",
       "                            [-0.06847898,  0.02025629, -0.04856956, ..., -0.04566676,\n",
       "                              0.02960534, -0.02913301]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "         },\n",
       "         14: {\n",
       "             attn: {\n",
       "                 c_attn: {\n",
       "                     bias: Array([ 0.06453055, -0.01915104, -0.06481297, ...,  0.05680315,\n",
       "                             0.06605668, -0.10764036], dtype=float32),\n",
       "                     kernel: Array([[ 0.0082178 ,  0.03946479,  0.07691357, ...,  0.01533983,\n",
       "                             -0.01852934, -0.00318308],\n",
       "                            [-0.07713778,  0.0733575 , -0.1172594 , ..., -0.01787006,\n",
       "                             -0.03583342,  0.05803505],\n",
       "                            [-0.10705855,  0.09321598,  0.01190234, ..., -0.05353371,\n",
       "                              0.02076168, -0.00874316],\n",
       "                            ...,\n",
       "                            [ 0.04930817,  0.00845295, -0.03518984, ..., -0.04027263,\n",
       "                              0.02472023,  0.06573605],\n",
       "                            [-0.0944433 ,  0.00701528, -0.07689777, ..., -0.04721559,\n",
       "                             -0.03774257, -0.05152608],\n",
       "                            [-0.04372505,  0.02582836, -0.04927157, ...,  0.00992404,\n",
       "                              0.01347981,  0.02728703]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([ 0.04850525, -0.00549708, -0.03566486, ...,  0.00599957,\n",
       "                            -0.01606129, -0.00509698], dtype=float32),\n",
       "                     kernel: Array([[-0.04593671,  0.00043709, -0.00949151, ..., -0.06699875,\n",
       "                             -0.03052815,  0.05392211],\n",
       "                            [ 0.01529448, -0.01327927,  0.02519834, ..., -0.03133976,\n",
       "                             -0.08716657, -0.06122991],\n",
       "                            [ 0.04940545, -0.04712491,  0.00480456, ...,  0.01158008,\n",
       "                             -0.00265821,  0.01599759],\n",
       "                            ...,\n",
       "                            [-0.07705507, -0.04451011, -0.04477504, ...,  0.01559317,\n",
       "                             -0.06536377, -0.0877334 ],\n",
       "                            [ 0.00800521, -0.01250077,  0.04832309, ...,  0.01541534,\n",
       "                             -0.06269513, -0.0522984 ],\n",
       "                            [ 0.0375923 ,  0.00076821, -0.0057794 , ..., -0.02505491,\n",
       "                             -0.01491661,  0.00698189]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "             ln_1: {\n",
       "                 bias: Array([-0.05442251,  0.00884233,  0.01675545, ..., -0.07400322,\n",
       "                        -0.02734251, -0.00244954], dtype=float32),\n",
       "                 scale: Array([0.5530903 , 0.5996263 , 0.56951386, ..., 0.5407996 , 0.59488213,\n",
       "                        0.54106164], dtype=float32),\n",
       "             },\n",
       "             ln_2: {\n",
       "                 bias: Array([-0.03341951, -0.00097656,  0.00306579, ...,  0.00684461,\n",
       "                        -0.03720633, -0.03209241], dtype=float32),\n",
       "                 scale: Array([0.59452784, 0.61324954, 0.59344107, ..., 0.6097162 , 0.58778185,\n",
       "                        0.57439363], dtype=float32),\n",
       "             },\n",
       "             mlp: {\n",
       "                 c_fc: {\n",
       "                     bias: Array([-0.02596903,  0.00752514, -0.04001932, ..., -0.0031556 ,\n",
       "                            -0.06545924,  0.01854854], dtype=float32),\n",
       "                     kernel: Array([[ 0.01970439,  0.05776422, -0.02099072, ...,  0.01006927,\n",
       "                             -0.06289314,  0.01900682],\n",
       "                            [ 0.02754676, -0.03752163, -0.06945028, ..., -0.0042533 ,\n",
       "                              0.00339496, -0.02196901],\n",
       "                            [-0.01518052,  0.00133392, -0.00644156, ..., -0.01894532,\n",
       "                              0.02369686,  0.04718398],\n",
       "                            ...,\n",
       "                            [-0.06997391,  0.01383703, -0.00709193, ..., -0.01212369,\n",
       "                             -0.00975089,  0.08558717],\n",
       "                            [-0.01469772, -0.01597373,  0.02163299, ..., -0.02035598,\n",
       "                              0.04606923, -0.05357502],\n",
       "                            [ 0.01279896, -0.06627542, -0.00702181, ...,  0.05539121,\n",
       "                              0.00491687,  0.03543013]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([ 0.02960618,  0.038238  , -0.02396906, ...,  0.06158499,\n",
       "                             0.06511803, -0.0183966 ], dtype=float32),\n",
       "                     kernel: Array([[ 0.04590288, -0.00056524,  0.02073927, ...,  0.02033798,\n",
       "                              0.02227766,  0.01956806],\n",
       "                            [-0.00327815, -0.01458263, -0.02820746, ..., -0.01646391,\n",
       "                              0.00254044,  0.00683721],\n",
       "                            [ 0.00381434,  0.01348058, -0.00685968, ...,  0.0032146 ,\n",
       "                             -0.02214511,  0.00042727],\n",
       "                            ...,\n",
       "                            [-0.04050022,  0.02066861,  0.00814438, ...,  0.00667798,\n",
       "                              0.05995517, -0.01025988],\n",
       "                            [ 0.02139532, -0.02788354, -0.01161102, ..., -0.05661378,\n",
       "                             -0.02020786,  0.0857105 ],\n",
       "                            [ 0.00076356,  0.05848559, -0.03887588, ..., -0.10396075,\n",
       "                              0.04996426, -0.03738281]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "         },\n",
       "         15: {\n",
       "             attn: {\n",
       "                 c_attn: {\n",
       "                     bias: Array([ 0.11870369, -0.02603221,  0.07543001, ...,  0.0404244 ,\n",
       "                            -0.01907859,  0.0178868 ], dtype=float32),\n",
       "                     kernel: Array([[ 0.01695829, -0.00066185,  0.03068762, ...,  0.0270441 ,\n",
       "                             -0.00045754, -0.00852193],\n",
       "                            [ 0.0132257 ,  0.02347907, -0.02429088, ..., -0.03103915,\n",
       "                             -0.00520239, -0.00128446],\n",
       "                            [-0.02870679, -0.08449481,  0.01134414, ...,  0.03707617,\n",
       "                             -0.03432263,  0.0332634 ],\n",
       "                            ...,\n",
       "                            [-0.01137821,  0.05304015,  0.04867661, ...,  0.00397715,\n",
       "                              0.02665417,  0.0233299 ],\n",
       "                            [-0.01650468,  0.04730506,  0.003199  , ...,  0.05612289,\n",
       "                             -0.03248368, -0.01855962],\n",
       "                            [-0.00614069,  0.00934816, -0.00894008, ...,  0.0605508 ,\n",
       "                             -0.03170545, -0.02124349]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([ 0.06155164, -0.00807524, -0.00353217, ..., -0.02034208,\n",
       "                            -0.04708524,  0.04220957], dtype=float32),\n",
       "                     kernel: Array([[ 0.02271142, -0.08923359,  0.10694983, ...,  0.11384722,\n",
       "                              0.07934666, -0.04798901],\n",
       "                            [ 0.11411653, -0.02415942, -0.01147235, ...,  0.08637775,\n",
       "                             -0.05839532,  0.0085742 ],\n",
       "                            [-0.03740076,  0.04529724, -0.01218154, ...,  0.03013829,\n",
       "                             -0.0642398 ,  0.00019037],\n",
       "                            ...,\n",
       "                            [-0.0114224 ,  0.00569625,  0.03726863, ..., -0.00908879,\n",
       "                              0.00070547,  0.02712916],\n",
       "                            [ 0.00974896, -0.00087258, -0.03384773, ...,  0.00219826,\n",
       "                             -0.02480491,  0.00830745],\n",
       "                            [-0.00834204, -0.02182596,  0.02740648, ...,  0.02438982,\n",
       "                             -0.0288036 , -0.04255004]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "             ln_1: {\n",
       "                 bias: Array([-0.05903492,  0.02445517,  0.02823275, ..., -0.07865896,\n",
       "                        -0.02088161,  0.00704816], dtype=float32),\n",
       "                 scale: Array([0.5908661 , 0.6499046 , 0.61109954, ..., 0.58359843, 0.6140175 ,\n",
       "                        0.57587576], dtype=float32),\n",
       "             },\n",
       "             ln_2: {\n",
       "                 bias: Array([-0.02505448,  0.0107836 , -0.01206342, ..., -0.01238604,\n",
       "                        -0.03582573, -0.01571521], dtype=float32),\n",
       "                 scale: Array([0.59376204, 0.5953941 , 0.5683013 , ..., 0.5728771 , 0.56655294,\n",
       "                        0.54999816], dtype=float32),\n",
       "             },\n",
       "             mlp: {\n",
       "                 c_fc: {\n",
       "                     bias: Array([ 0.01761072,  0.00519919, -0.03868632, ..., -0.08128701,\n",
       "                            -0.06210105, -0.03857879], dtype=float32),\n",
       "                     kernel: Array([[-0.05338663, -0.07953092,  0.03432579, ...,  0.05949649,\n",
       "                              0.03987937, -0.02754855],\n",
       "                            [ 0.01643579,  0.0344847 ,  0.03582492, ...,  0.05397885,\n",
       "                             -0.01432002,  0.04032346],\n",
       "                            [-0.0389699 ,  0.01989581, -0.00626638, ...,  0.00839486,\n",
       "                             -0.02301051, -0.0220815 ],\n",
       "                            ...,\n",
       "                            [ 0.02679933,  0.0041804 , -0.00459622, ..., -0.07195057,\n",
       "                              0.00034157, -0.00096794],\n",
       "                            [-0.0048221 , -0.0257823 , -0.01225637, ...,  0.0519188 ,\n",
       "                              0.03650193,  0.04320331],\n",
       "                            [-0.02578768, -0.02404713,  0.00246404, ..., -0.03831728,\n",
       "                             -0.02372832,  0.00104902]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([ 0.02591235,  0.03649762, -0.03821463, ...,  0.08037983,\n",
       "                             0.05178582, -0.01730517], dtype=float32),\n",
       "                     kernel: Array([[ 0.03926511, -0.06874361,  0.02263625, ...,  0.03199277,\n",
       "                              0.00505315,  0.03155097],\n",
       "                            [ 0.03686678, -0.02852915, -0.0017131 , ..., -0.00764799,\n",
       "                              0.03699066, -0.00104862],\n",
       "                            [-0.00689905,  0.00652242, -0.00095534, ..., -0.02519274,\n",
       "                             -0.02993399,  0.01641581],\n",
       "                            ...,\n",
       "                            [ 0.03164166,  0.03566644, -0.02583097, ...,  0.02206918,\n",
       "                              0.0161422 ,  0.04939253],\n",
       "                            [-0.00365049,  0.05684779,  0.01478396, ..., -0.05772783,\n",
       "                              0.01182117,  0.03102213],\n",
       "                            [-0.03082839, -0.00160683, -0.04926184, ...,  0.0288926 ,\n",
       "                              0.0171868 ,  0.01267503]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "         },\n",
       "         16: {\n",
       "             attn: {\n",
       "                 c_attn: {\n",
       "                     bias: Array([ 0.00639181,  0.06072955,  0.05966938, ..., -0.02196232,\n",
       "                             0.02728221, -0.04224031], dtype=float32),\n",
       "                     kernel: Array([[-0.14121006, -0.00892309, -0.01498659, ...,  0.08809964,\n",
       "                              0.07396027, -0.01507906],\n",
       "                            [-0.0995715 , -0.02020713, -0.02251327, ..., -0.00812751,\n",
       "                             -0.03500175, -0.04349674],\n",
       "                            [-0.03478828,  0.03832113,  0.06457309, ...,  0.04491388,\n",
       "                             -0.02256962, -0.0189926 ],\n",
       "                            ...,\n",
       "                            [-0.0618427 , -0.04214176, -0.02061741, ...,  0.0025077 ,\n",
       "                             -0.02405658, -0.02064362],\n",
       "                            [ 0.05207313,  0.04275637, -0.14282593, ...,  0.02658203,\n",
       "                              0.06480927, -0.04351247],\n",
       "                            [ 0.10824714,  0.01231172, -0.0449175 , ..., -0.01043625,\n",
       "                             -0.07804974, -0.02235577]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([ 0.01365784, -0.03543274,  0.00737468, ..., -0.03192887,\n",
       "                            -0.05862536, -0.04197381], dtype=float32),\n",
       "                     kernel: Array([[ 0.00227618,  0.04423313,  0.03317413, ..., -0.01892107,\n",
       "                              0.03902429, -0.05447616],\n",
       "                            [ 0.0066689 ,  0.00166163,  0.03472001, ..., -0.05876555,\n",
       "                             -0.02620271, -0.03302837],\n",
       "                            [-0.03581866, -0.03326593,  0.02746015, ...,  0.01593625,\n",
       "                              0.05549764,  0.07745385],\n",
       "                            ...,\n",
       "                            [-0.02139808, -0.02243333, -0.0375087 , ...,  0.0061613 ,\n",
       "                             -0.07461679, -0.06118744],\n",
       "                            [ 0.00941363,  0.00187478, -0.0468309 , ..., -0.02702579,\n",
       "                             -0.02003866,  0.11814936],\n",
       "                            [-0.05192096, -0.01904146,  0.01876338, ..., -0.00101269,\n",
       "                             -0.02746689,  0.08060726]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "             ln_1: {\n",
       "                 bias: Array([-0.05347373,  0.0197357 ,  0.01911828, ..., -0.06983708,\n",
       "                        -0.03281815,  0.0083595 ], dtype=float32),\n",
       "                 scale: Array([0.6288518, 0.6730779, 0.6453713, ..., 0.6248077, 0.6777339,\n",
       "                        0.61138  ], dtype=float32),\n",
       "             },\n",
       "             ln_2: {\n",
       "                 bias: Array([-0.03007049,  0.01163231, -0.00316754, ..., -0.01023257,\n",
       "                        -0.03276125, -0.01160805], dtype=float32),\n",
       "                 scale: Array([0.5876279 , 0.6149644 , 0.57445943, ..., 0.59050316, 0.5870263 ,\n",
       "                        0.56430227], dtype=float32),\n",
       "             },\n",
       "             mlp: {\n",
       "                 c_fc: {\n",
       "                     bias: Array([-0.09317587, -0.01175261, -0.08197883, ..., -0.03274189,\n",
       "                            -0.07742744,  0.02005243], dtype=float32),\n",
       "                     kernel: Array([[-0.017822  , -0.08517778,  0.01205015, ..., -0.04038245,\n",
       "                              0.00630633, -0.02391509],\n",
       "                            [ 0.00684004,  0.0152402 ,  0.15025815, ..., -0.02750612,\n",
       "                             -0.01904979,  0.01954473],\n",
       "                            [-0.04440805,  0.08195857,  0.03047296, ..., -0.06033703,\n",
       "                              0.00494912,  0.06869334],\n",
       "                            ...,\n",
       "                            [-0.06777727, -0.0594143 , -0.03316203, ..., -0.00835208,\n",
       "                             -0.00824004,  0.03024664],\n",
       "                            [ 0.00645468, -0.06832165, -0.11585022, ..., -0.05398583,\n",
       "                             -0.04268971, -0.03210851],\n",
       "                            [ 0.06808531, -0.00159297,  0.03904677, ..., -0.01439121,\n",
       "                             -0.00242565, -0.05615712]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([ 0.04314801,  0.01328817,  0.00931413, ...,  0.0412062 ,\n",
       "                             0.04105235, -0.01653282], dtype=float32),\n",
       "                     kernel: Array([[ 0.04773744,  0.05275173, -0.01161371, ..., -0.00400976,\n",
       "                             -0.05444683, -0.03394293],\n",
       "                            [ 0.03553684,  0.0043891 , -0.01890667, ...,  0.0093612 ,\n",
       "                              0.04311431, -0.02186408],\n",
       "                            [-0.06437965,  0.03343188, -0.01551422, ..., -0.00938171,\n",
       "                              0.0149162 , -0.05418832],\n",
       "                            ...,\n",
       "                            [ 0.01126252,  0.0188484 ,  0.01573417, ...,  0.00117915,\n",
       "                              0.07920576,  0.02808164],\n",
       "                            [-0.00771779, -0.00489788,  0.04154193, ..., -0.01699074,\n",
       "                             -0.00913087, -0.02376481],\n",
       "                            [ 0.02335511, -0.04917582, -0.02138946, ..., -0.09690929,\n",
       "                              0.06635803,  0.0830724 ]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "         },\n",
       "         17: {\n",
       "             attn: {\n",
       "                 c_attn: {\n",
       "                     bias: Array([ 0.00071998, -0.01613391, -0.17948712, ...,  0.03203903,\n",
       "                            -0.03187186, -0.02652574], dtype=float32),\n",
       "                     kernel: Array([[-0.0694878 ,  0.00511119,  0.0235035 , ...,  0.05141085,\n",
       "                              0.06567886, -0.01100306],\n",
       "                            [-0.02267662,  0.02891707, -0.05175071, ..., -0.01247945,\n",
       "                              0.04179609, -0.01529089],\n",
       "                            [-0.0218662 ,  0.07674875,  0.00438768, ...,  0.070268  ,\n",
       "                             -0.04421805,  0.07775529],\n",
       "                            ...,\n",
       "                            [ 0.02389856,  0.07066046,  0.02549063, ..., -0.02283295,\n",
       "                              0.00716813,  0.0054342 ],\n",
       "                            [-0.02551269,  0.05618586, -0.01834482, ...,  0.05318658,\n",
       "                              0.01886856, -0.05218965],\n",
       "                            [ 0.00437198, -0.0746797 , -0.05115125, ..., -0.04718084,\n",
       "                              0.04188555,  0.01378343]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([ 0.03710582,  0.01488926,  0.00043902, ...,  0.01430085,\n",
       "                            -0.06104692,  0.00816788], dtype=float32),\n",
       "                     kernel: Array([[-0.00104211, -0.06221245, -0.0392938 , ...,  0.01794017,\n",
       "                              0.03631407, -0.02966659],\n",
       "                            [-0.03845032, -0.01819961, -0.07782465, ..., -0.05829426,\n",
       "                              0.06949405,  0.07311673],\n",
       "                            [ 0.09464583, -0.02653394, -0.00236862, ...,  0.0115894 ,\n",
       "                             -0.01325264, -0.04875922],\n",
       "                            ...,\n",
       "                            [ 0.05194234, -0.08182575, -0.00753003, ..., -0.10167006,\n",
       "                              0.05943133, -0.02249562],\n",
       "                            [-0.00864504,  0.02910644,  0.01934505, ...,  0.02609634,\n",
       "                              0.03283202, -0.07679246],\n",
       "                            [-0.11790969,  0.00981039, -0.03934215, ...,  0.05205064,\n",
       "                             -0.0783403 ,  0.13516563]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "             ln_1: {\n",
       "                 bias: Array([-0.06407583,  0.01826599,  0.02924397, ..., -0.06410074,\n",
       "                        -0.03086299,  0.015144  ], dtype=float32),\n",
       "                 scale: Array([0.6298144 , 0.68957406, 0.6504488 , ..., 0.6105818 , 0.67192054,\n",
       "                        0.62316364], dtype=float32),\n",
       "             },\n",
       "             ln_2: {\n",
       "                 bias: Array([-0.0216234 ,  0.02913268, -0.00479058, ...,  0.0118608 ,\n",
       "                        -0.03834556, -0.00860099], dtype=float32),\n",
       "                 scale: Array([0.5796966 , 0.57898664, 0.56945974, ..., 0.58569205, 0.5745175 ,\n",
       "                        0.561906  ], dtype=float32),\n",
       "             },\n",
       "             mlp: {\n",
       "                 c_fc: {\n",
       "                     bias: Array([-0.09649502, -0.0619862 , -0.01133945, ..., -0.03724038,\n",
       "                            -0.04673901, -0.0683657 ], dtype=float32),\n",
       "                     kernel: Array([[-0.00823311, -0.05463004,  0.01058197, ..., -0.02467003,\n",
       "                              0.00305868, -0.07250676],\n",
       "                            [ 0.02088449,  0.00608623,  0.00769907, ...,  0.00042661,\n",
       "                             -0.0362816 , -0.02317362],\n",
       "                            [ 0.12649634,  0.01536449, -0.00515037, ...,  0.01656415,\n",
       "                             -0.0811836 ,  0.00608859],\n",
       "                            ...,\n",
       "                            [-0.13625021, -0.07646053, -0.02296142, ...,  0.01003534,\n",
       "                             -0.0302237 ,  0.00240231],\n",
       "                            [-0.00840722, -0.09415565, -0.08553265, ...,  0.08099767,\n",
       "                             -0.03769673, -0.02334525],\n",
       "                            [ 0.01470582,  0.07074888,  0.04022543, ...,  0.01751145,\n",
       "                              0.01721232,  0.02392718]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([ 0.0412831 , -0.00320452,  0.00179836, ...,  0.07294285,\n",
       "                             0.082392  ,  0.00344256], dtype=float32),\n",
       "                     kernel: Array([[ 0.07221501,  0.0411965 ,  0.05427493, ..., -0.07199755,\n",
       "                              0.03508595, -0.01981303],\n",
       "                            [ 0.03732076,  0.06074315, -0.04898985, ...,  0.05305368,\n",
       "                             -0.07415018, -0.00991256],\n",
       "                            [ 0.02742233, -0.00054666, -0.01818961, ...,  0.03069664,\n",
       "                             -0.09340369, -0.06589653],\n",
       "                            ...,\n",
       "                            [-0.05096033,  0.06271947, -0.22732338, ..., -0.04441112,\n",
       "                              0.05656873, -0.00853197],\n",
       "                            [-0.02999182,  0.01816451, -0.03870193, ...,  0.04861374,\n",
       "                             -0.06708219, -0.06374143],\n",
       "                            [-0.04031462, -0.00538038,  0.03670885, ...,  0.00683587,\n",
       "                             -0.00513926, -0.05965139]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "         },\n",
       "         18: {\n",
       "             attn: {\n",
       "                 c_attn: {\n",
       "                     bias: Array([-0.03233382,  0.07745958, -0.03822937, ..., -0.03616275,\n",
       "                            -0.021165  ,  0.06062965], dtype=float32),\n",
       "                     kernel: Array([[ 3.0407999e-02,  1.8394211e-02,  9.6509792e-02, ...,\n",
       "                             -3.9072759e-02, -1.3507064e-02,  4.0177632e-02],\n",
       "                            [-5.7680145e-02, -3.0793375e-03,  5.0896484e-02, ...,\n",
       "                              2.9108694e-02, -2.5975533e-02, -5.2714191e-02],\n",
       "                            [-2.7893297e-02,  2.2674371e-02,  3.2461122e-02, ...,\n",
       "                              6.1742823e-05, -3.8120244e-02, -1.1454638e-02],\n",
       "                            ...,\n",
       "                            [ 1.1341175e-02, -7.8231379e-02, -2.1751937e-03, ...,\n",
       "                              1.4846125e-02, -3.3902250e-02,  4.6803441e-02],\n",
       "                            [-5.3758495e-02,  5.9577718e-02,  1.2541381e-02, ...,\n",
       "                              1.3532378e-01,  5.7842318e-02, -8.4579736e-02],\n",
       "                            [-8.2068294e-03, -6.5364979e-02,  4.3709178e-02, ...,\n",
       "                              5.1707204e-02, -8.0014452e-02, -9.3990557e-02]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([ 0.03836748,  0.00192512, -0.00065614, ...,  0.04117418,\n",
       "                            -0.0691195 , -0.02233579], dtype=float32),\n",
       "                     kernel: Array([[ 2.5510391e-02, -4.1760501e-02,  1.3402016e-01, ...,\n",
       "                              6.1267562e-02, -9.9420995e-03, -1.4646873e-02],\n",
       "                            [-9.1755413e-02, -2.8666025e-02,  5.2615952e-02, ...,\n",
       "                             -4.2940147e-02,  1.7408522e-02, -1.7211799e-01],\n",
       "                            [-2.8677123e-02, -1.4123706e-02,  6.8909168e-02, ...,\n",
       "                             -6.6422679e-02, -2.2093365e-02,  1.2281426e-01],\n",
       "                            ...,\n",
       "                            [-1.2834480e-03, -4.2936806e-02,  9.5716128e-03, ...,\n",
       "                             -8.5431755e-02, -2.3096746e-02, -1.9065773e-02],\n",
       "                            [-3.7113376e-02,  4.9143482e-02, -4.4096813e-02, ...,\n",
       "                              5.8362964e-03, -4.5485295e-02, -8.6950190e-02],\n",
       "                            [-1.2783100e-01,  6.8593904e-02,  3.2267184e-03, ...,\n",
       "                             -1.6092842e-04,  4.0718983e-03,  5.1430274e-02]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "             ln_1: {\n",
       "                 bias: Array([-0.06216381,  0.02386804,  0.03016873, ..., -0.06646825,\n",
       "                        -0.01983959,  0.02264861], dtype=float32),\n",
       "                 scale: Array([0.59219944, 0.66387606, 0.6154    , ..., 0.59571314, 0.66366434,\n",
       "                        0.61156833], dtype=float32),\n",
       "             },\n",
       "             ln_2: {\n",
       "                 bias: Array([-0.01863284,  0.00807315,  0.01065316, ...,  0.0028079 ,\n",
       "                        -0.02941851, -0.00976996], dtype=float32),\n",
       "                 scale: Array([0.5722739 , 0.5828761 , 0.55774754, ..., 0.56788266, 0.56449395,\n",
       "                        0.5504753 ], dtype=float32),\n",
       "             },\n",
       "             mlp: {\n",
       "                 c_fc: {\n",
       "                     bias: Array([-0.04495087, -0.03363988, -0.05435307, ...,  0.00876744,\n",
       "                            -0.00586004, -0.05331377], dtype=float32),\n",
       "                     kernel: Array([[ 0.02842892, -0.09737471,  0.03395555, ...,  0.01507122,\n",
       "                             -0.0724307 , -0.03969477],\n",
       "                            [-0.01098673,  0.01364964,  0.01262944, ..., -0.03378221,\n",
       "                             -0.04665889, -0.055772  ],\n",
       "                            [ 0.00729746, -0.06209824,  0.02972732, ...,  0.00695733,\n",
       "                             -0.01541193,  0.00510645],\n",
       "                            ...,\n",
       "                            [-0.01090001, -0.02025939,  0.01477377, ..., -0.03985728,\n",
       "                              0.01705639, -0.04491648],\n",
       "                            [-0.00615723, -0.02805091, -0.04349489, ...,  0.00481636,\n",
       "                              0.05273592, -0.02314354],\n",
       "                            [ 0.06126055, -0.02600664, -0.02648555, ...,  0.00684697,\n",
       "                              0.02039047,  0.08230286]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([ 0.06682042,  0.06823798, -0.01295821, ...,  0.09248681,\n",
       "                             0.08932009,  0.00507187], dtype=float32),\n",
       "                     kernel: Array([[ 0.00407092, -0.05898391,  0.0477321 , ..., -0.00181254,\n",
       "                              0.02609907,  0.0282247 ],\n",
       "                            [ 0.07703639, -0.07665151, -0.03274092, ..., -0.05748272,\n",
       "                             -0.00126754,  0.0217904 ],\n",
       "                            [-0.0569947 ,  0.01343   , -0.03147991, ..., -0.00778714,\n",
       "                             -0.00879625,  0.06349468],\n",
       "                            ...,\n",
       "                            [-0.01057037, -0.02121291, -0.03304506, ...,  0.01668421,\n",
       "                             -0.00672757, -0.00491053],\n",
       "                            [ 0.04757726,  0.04712413,  0.04192546, ..., -0.01226471,\n",
       "                             -0.03992967,  0.01124191],\n",
       "                            [ 0.0274004 , -0.01945384, -0.03179833, ..., -0.01578506,\n",
       "                              0.00120665,  0.09154343]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "         },\n",
       "         19: {\n",
       "             attn: {\n",
       "                 c_attn: {\n",
       "                     bias: Array([-0.0401274 ,  0.02901323,  0.02661335, ...,  0.03527719,\n",
       "                             0.03490432, -0.00405614], dtype=float32),\n",
       "                     kernel: Array([[ 0.00019005, -0.01780804,  0.01688051, ...,  0.03356944,\n",
       "                             -0.01647487,  0.03101015],\n",
       "                            [-0.03453924,  0.01184113,  0.02187199, ..., -0.01548764,\n",
       "                             -0.02145131,  0.00272494],\n",
       "                            [ 0.03299376,  0.04914204,  0.03558766, ..., -0.01664197,\n",
       "                             -0.0267653 , -0.01266161],\n",
       "                            ...,\n",
       "                            [-0.02907104,  0.02744838, -0.04279735, ...,  0.01865334,\n",
       "                              0.01540189,  0.06154625],\n",
       "                            [-0.05565092,  0.02885303, -0.01284176, ...,  0.05337159,\n",
       "                              0.0785459 ,  0.0371832 ],\n",
       "                            [-0.00336347,  0.00087457, -0.04056559, ...,  0.02463733,\n",
       "                              0.03168684, -0.01386188]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([ 0.00739841,  0.02291334,  0.03135526, ..., -0.02526294,\n",
       "                            -0.08598684,  0.00910766], dtype=float32),\n",
       "                     kernel: Array([[-0.02760983,  0.01559678,  0.02064831, ...,  0.04466895,\n",
       "                             -0.05330049,  0.01965371],\n",
       "                            [-0.03091451,  0.0044714 , -0.01187557, ..., -0.00932265,\n",
       "                             -0.00053786, -0.02449882],\n",
       "                            [-0.08042342,  0.02896799,  0.07027695, ...,  0.04520261,\n",
       "                             -0.01590837, -0.01211134],\n",
       "                            ...,\n",
       "                            [ 0.0560341 , -0.01195883,  0.00218084, ..., -0.00977546,\n",
       "                             -0.01980843, -0.03382503],\n",
       "                            [ 0.00727131, -0.02252855,  0.07645997, ..., -0.0041907 ,\n",
       "                             -0.03566907, -0.00203299],\n",
       "                            [ 0.08552386, -0.02970634, -0.02223345, ..., -0.02467391,\n",
       "                              0.05569396, -0.05212208]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "             ln_1: {\n",
       "                 bias: Array([-0.05598013,  0.02725057,  0.02715684, ..., -0.04546311,\n",
       "                        -0.01908566,  0.02465198], dtype=float32),\n",
       "                 scale: Array([0.650397  , 0.72466475, 0.661052  , ..., 0.62169325, 0.6870737 ,\n",
       "                        0.6077282 ], dtype=float32),\n",
       "             },\n",
       "             ln_2: {\n",
       "                 bias: Array([-0.01278549,  0.0238925 , -0.00551667, ..., -0.00365973,\n",
       "                        -0.04121811,  0.01098477], dtype=float32),\n",
       "                 scale: Array([0.5876468 , 0.5796239 , 0.56266105, ..., 0.5752572 , 0.56829894,\n",
       "                        0.55298626], dtype=float32),\n",
       "             },\n",
       "             mlp: {\n",
       "                 c_fc: {\n",
       "                     bias: Array([-0.03712488, -0.00483959,  0.01888742, ...,  0.011094  ,\n",
       "                            -0.00535347, -0.0355282 ], dtype=float32),\n",
       "                     kernel: Array([[-0.04898314, -0.08533806, -0.03784874, ...,  0.02164795,\n",
       "                              0.05382745,  0.03733215],\n",
       "                            [-0.02420981, -0.1133064 , -0.06353888, ...,  0.02515594,\n",
       "                              0.06566998,  0.01373051],\n",
       "                            [-0.02058152, -0.06859663,  0.00588943, ..., -0.00716065,\n",
       "                             -0.04048412, -0.02344779],\n",
       "                            ...,\n",
       "                            [ 0.04016468, -0.03408762, -0.00724133, ...,  0.0544406 ,\n",
       "                             -0.06537099,  0.02472853],\n",
       "                            [ 0.01692286, -0.06482238, -0.02149581, ..., -0.0129512 ,\n",
       "                              0.03318821, -0.10786003],\n",
       "                            [ 0.08248215,  0.05786666, -0.01419573, ..., -0.03428407,\n",
       "                             -0.02426228, -0.02005746]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([ 0.07625817,  0.05946717,  0.00856928, ...,  0.09098279,\n",
       "                             0.08216641, -0.00985437], dtype=float32),\n",
       "                     kernel: Array([[ 0.00731881,  0.04035351,  0.01534439, ..., -0.0646629 ,\n",
       "                             -0.0477616 , -0.05656299],\n",
       "                            [ 0.03477873,  0.1079493 ,  0.09343147, ...,  0.03663556,\n",
       "                              0.07801089,  0.02330495],\n",
       "                            [ 0.02753427,  0.03135337, -0.02987991, ..., -0.00368082,\n",
       "                              0.05333987,  0.07087154],\n",
       "                            ...,\n",
       "                            [-0.00865622, -0.02876641,  0.05867368, ..., -0.05917093,\n",
       "                              0.01006178, -0.01005119],\n",
       "                            [-0.04463806, -0.05206011,  0.03110574, ...,  0.0919769 ,\n",
       "                              0.02313102, -0.00586023],\n",
       "                            [ 0.01945604, -0.01669936,  0.04248785, ..., -0.01013781,\n",
       "                             -0.07510587,  0.08671254]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "         },\n",
       "         2: {\n",
       "             attn: {\n",
       "                 c_attn: {\n",
       "                     bias: Array([-0.0037225 ,  0.15930444,  0.2573417 , ...,  0.01887068,\n",
       "                             0.02606794, -0.01109411], dtype=float32),\n",
       "                     kernel: Array([[ 0.10980776, -0.05454362,  0.06166609, ..., -0.02192924,\n",
       "                             -0.00167117,  0.00989037],\n",
       "                            [-0.1300498 ,  0.04957176,  0.1084214 , ...,  0.01965105,\n",
       "                             -0.00574821, -0.01381285],\n",
       "                            [-0.07457639,  0.1452709 ,  0.03950999, ..., -0.01450731,\n",
       "                             -0.00142423, -0.0572903 ],\n",
       "                            ...,\n",
       "                            [-0.00406595, -0.11489747, -0.01400878, ...,  0.02475112,\n",
       "                             -0.02712691,  0.02461493],\n",
       "                            [ 0.01723258,  0.02160291,  0.05585353, ...,  0.05609249,\n",
       "                              0.01758058, -0.01602298],\n",
       "                            [ 0.15218931,  0.04726291,  0.04153112, ..., -0.01238774,\n",
       "                             -0.01113807, -0.00501612]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([-0.04071192,  0.01917247, -0.02407753, ...,  0.03696973,\n",
       "                             0.04916125,  0.03314025], dtype=float32),\n",
       "                     kernel: Array([[-0.04255762, -0.02730135,  0.00847522, ...,  0.00544292,\n",
       "                              0.01536868, -0.05019118],\n",
       "                            [-0.04553721, -0.05731921,  0.00875549, ...,  0.01654473,\n",
       "                              0.01737421, -0.04814966],\n",
       "                            [-0.01763841, -0.03783564,  0.03197577, ...,  0.04299101,\n",
       "                             -0.02586422,  0.0567428 ],\n",
       "                            ...,\n",
       "                            [ 0.00252835, -0.02596243,  0.00869395, ..., -0.00131449,\n",
       "                             -0.00879907,  0.02687705],\n",
       "                            [ 0.00436422, -0.03937696, -0.00431576, ...,  0.02424904,\n",
       "                             -0.02043504,  0.01080302],\n",
       "                            [ 0.03086645,  0.00300224, -0.0052103 , ..., -0.05171622,\n",
       "                             -0.02391203,  0.01910842]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "             ln_1: {\n",
       "                 bias: Array([-0.05427139, -0.04227303, -0.01204938, ..., -0.1097537 ,\n",
       "                        -0.038862  , -0.05855361], dtype=float32),\n",
       "                 scale: Array([0.43257567, 0.39508218, 0.40698084, ..., 0.38481307, 0.39379725,\n",
       "                        0.36387727], dtype=float32),\n",
       "             },\n",
       "             ln_2: {\n",
       "                 bias: Array([-0.07686795, -0.08015061,  0.04440914, ..., -0.01351157,\n",
       "                         0.04127807,  0.02596069], dtype=float32),\n",
       "                 scale: Array([0.5488988 , 0.61129797, 0.5718824 , ..., 0.5403103 , 0.5449772 ,\n",
       "                        0.53253084], dtype=float32),\n",
       "             },\n",
       "             mlp: {\n",
       "                 c_fc: {\n",
       "                     bias: Array([-0.03184173, -0.04254674, -0.03903516, ..., -0.0456565 ,\n",
       "                            -0.03783035, -0.05818734], dtype=float32),\n",
       "                     kernel: Array([[ 0.00361701, -0.06078826,  0.05067868, ..., -0.01659531,\n",
       "                             -0.02866374, -0.01075793],\n",
       "                            [-0.00833721,  0.04185065,  0.00857772, ...,  0.05733208,\n",
       "                              0.02134639,  0.06363723],\n",
       "                            [ 0.03327534, -0.03287534,  0.07850912, ...,  0.10681123,\n",
       "                              0.06799982, -0.01180568],\n",
       "                            ...,\n",
       "                            [-0.02717165, -0.00975675,  0.01812913, ..., -0.07019605,\n",
       "                             -0.04283171,  0.0146985 ],\n",
       "                            [ 0.01525042,  0.04374615,  0.05969503, ..., -0.07781681,\n",
       "                              0.0394103 , -0.02346448],\n",
       "                            [ 0.01869788, -0.0071525 ,  0.01756276, ...,  0.03227198,\n",
       "                             -0.04091116, -0.00450289]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([-0.00074415, -0.05791308,  0.00324737, ...,  0.02690194,\n",
       "                             0.06472035,  0.01768493], dtype=float32),\n",
       "                     kernel: Array([[-0.01464489, -0.04455912,  0.03853075, ..., -0.01765415,\n",
       "                              0.00988826,  0.03015346],\n",
       "                            [-0.08239687, -0.02611499, -0.00619018, ..., -0.01965606,\n",
       "                              0.04808074,  0.07970835],\n",
       "                            [ 0.01335014,  0.04332064,  0.08835677, ...,  0.02516834,\n",
       "                              0.01328493, -0.05045637],\n",
       "                            ...,\n",
       "                            [ 0.00113865, -0.04141659,  0.04169558, ..., -0.0497547 ,\n",
       "                             -0.05698247,  0.0104723 ],\n",
       "                            [-0.02441913,  0.04126502,  0.04025186, ..., -0.04302768,\n",
       "                              0.02664223,  0.04661097],\n",
       "                            [-0.01738968, -0.00408405,  0.01639312, ..., -0.01587048,\n",
       "                             -0.01712016,  0.00548111]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "         },\n",
       "         20: {\n",
       "             attn: {\n",
       "                 c_attn: {\n",
       "                     bias: Array([ 0.01694792,  0.25098097, -0.01565121, ..., -0.0442786 ,\n",
       "                            -0.03422501,  0.03552524], dtype=float32),\n",
       "                     kernel: Array([[-0.11303853, -0.01801516, -0.05364752, ...,  0.02596514,\n",
       "                             -0.03330162, -0.01328234],\n",
       "                            [-0.01926287, -0.00692138, -0.02730438, ..., -0.04742912,\n",
       "                             -0.00709859,  0.11016206],\n",
       "                            [ 0.01291378, -0.19345266,  0.01798847, ..., -0.03162902,\n",
       "                              0.07761317,  0.01734852],\n",
       "                            ...,\n",
       "                            [-0.08219276, -0.02380607,  0.01715587, ...,  0.00927377,\n",
       "                             -0.03492774, -0.10055889],\n",
       "                            [-0.09597934,  0.06721583,  0.14177917, ...,  0.03236132,\n",
       "                              0.02051562, -0.0313058 ],\n",
       "                            [ 0.10796029, -0.03339291,  0.01325663, ..., -0.03116154,\n",
       "                             -0.0257631 , -0.1254568 ]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([ 0.00546844,  0.03630459, -0.00679724, ...,  0.01221455,\n",
       "                            -0.02134251,  0.0009127 ], dtype=float32),\n",
       "                     kernel: Array([[ 0.09136143, -0.00123633, -0.02957047, ..., -0.01012535,\n",
       "                              0.09409264, -0.01312061],\n",
       "                            [ 0.07805918,  0.0677435 , -0.00615222, ...,  0.00591185,\n",
       "                             -0.04079337,  0.02202663],\n",
       "                            [-0.06705396, -0.0067831 , -0.04866545, ...,  0.04210012,\n",
       "                             -0.01610059, -0.07472175],\n",
       "                            ...,\n",
       "                            [ 0.00049526, -0.00284597, -0.03479579, ...,  0.07484704,\n",
       "                             -0.04543231, -0.06221571],\n",
       "                            [-0.01176717,  0.01669964, -0.01998932, ...,  0.10027952,\n",
       "                             -0.01809239,  0.08352344],\n",
       "                            [-0.09155133,  0.04719589, -0.02609931, ..., -0.04179786,\n",
       "                              0.02131862,  0.02980467]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "             ln_1: {\n",
       "                 bias: Array([-0.05866297,  0.01507726,  0.02595815, ..., -0.04927147,\n",
       "                        -0.00802293,  0.04432119], dtype=float32),\n",
       "                 scale: Array([0.6244476 , 0.7059541 , 0.63809097, ..., 0.62281626, 0.6580885 ,\n",
       "                        0.6227776 ], dtype=float32),\n",
       "             },\n",
       "             ln_2: {\n",
       "                 bias: Array([-0.01811656,  0.04352317,  0.01986388, ...,  0.00480953,\n",
       "                        -0.01794394,  0.02052977], dtype=float32),\n",
       "                 scale: Array([0.58224165, 0.590063  , 0.5733985 , ..., 0.5819521 , 0.5731372 ,\n",
       "                        0.56433916], dtype=float32),\n",
       "             },\n",
       "             mlp: {\n",
       "                 c_fc: {\n",
       "                     bias: Array([-0.01999176, -0.00733295, -0.043868  , ..., -0.06010745,\n",
       "                            -0.00078688, -0.05141452], dtype=float32),\n",
       "                     kernel: Array([[-0.00231617, -0.02797228, -0.06634542, ..., -0.0361655 ,\n",
       "                             -0.03228201,  0.02439502],\n",
       "                            [-0.06764221,  0.03553   , -0.06718896, ...,  0.08257642,\n",
       "                              0.04516501, -0.00756475],\n",
       "                            [ 0.02321498, -0.00643497, -0.04870152, ..., -0.02624433,\n",
       "                             -0.00062786,  0.05844492],\n",
       "                            ...,\n",
       "                            [-0.01873857, -0.01909558, -0.04877323, ..., -0.07106341,\n",
       "                             -0.02916137, -0.0415982 ],\n",
       "                            [ 0.099681  , -0.04383387,  0.06836814, ..., -0.03194322,\n",
       "                             -0.09354743, -0.04406539],\n",
       "                            [ 0.04532565,  0.08614028,  0.05856068, ..., -0.02840687,\n",
       "                             -0.03381018,  0.00993332]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([ 0.07221841,  0.03157946, -0.00932815, ...,  0.06394753,\n",
       "                             0.07385833, -0.01289019], dtype=float32),\n",
       "                     kernel: Array([[-0.03662813,  0.01541935, -0.04143616, ..., -0.05305426,\n",
       "                             -0.01860558, -0.04538614],\n",
       "                            [-0.00110671,  0.01975891, -0.04098935, ..., -0.02479427,\n",
       "                              0.02761779, -0.06827421],\n",
       "                            [ 0.02724246, -0.05777422,  0.02446338, ...,  0.04539379,\n",
       "                             -0.01752306,  0.00993565],\n",
       "                            ...,\n",
       "                            [-0.05994576,  0.06832061,  0.01235818, ..., -0.02685789,\n",
       "                             -0.04197541,  0.04750784],\n",
       "                            [ 0.02499192, -0.00436813,  0.02475943, ..., -0.02596772,\n",
       "                              0.01855617, -0.01372047],\n",
       "                            [ 0.09309506, -0.02400766,  0.06013433, ...,  0.03298204,\n",
       "                              0.05421961,  0.03052552]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "         },\n",
       "         21: {\n",
       "             attn: {\n",
       "                 c_attn: {\n",
       "                     bias: Array([ 0.02919974, -0.01221279, -0.11400568, ..., -0.03394534,\n",
       "                             0.00427628,  0.0153122 ], dtype=float32),\n",
       "                     kernel: Array([[ 0.02844671,  0.09301382, -0.02017182, ...,  0.04533322,\n",
       "                              0.0702251 , -0.06500772],\n",
       "                            [-0.10619182, -0.06613749,  0.03753158, ..., -0.00134225,\n",
       "                              0.04943746,  0.02158347],\n",
       "                            [ 0.03830815,  0.0241031 ,  0.02541382, ..., -0.05271902,\n",
       "                              0.00438013, -0.02362193],\n",
       "                            ...,\n",
       "                            [-0.05457362,  0.00593679,  0.008295  , ..., -0.06388327,\n",
       "                              0.01010463,  0.00418582],\n",
       "                            [-0.07509951,  0.03588685,  0.00244437, ...,  0.02015472,\n",
       "                              0.0060806 , -0.00505623],\n",
       "                            [ 0.03455823,  0.02554026, -0.0640228 , ...,  0.02396362,\n",
       "                             -0.01011332, -0.04399174]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([ 0.01630458,  0.01890018, -0.03412191, ...,  0.02236038,\n",
       "                            -0.02232495,  0.00437316], dtype=float32),\n",
       "                     kernel: Array([[ 0.03948795, -0.03785078, -0.01536541, ...,  0.0208698 ,\n",
       "                              0.07667107,  0.09581617],\n",
       "                            [ 0.00387049, -0.04527057, -0.06537642, ...,  0.01654273,\n",
       "                              0.07249746, -0.01933064],\n",
       "                            [ 0.00670753,  0.07786912,  0.03051073, ..., -0.03202053,\n",
       "                              0.03838456, -0.00117142],\n",
       "                            ...,\n",
       "                            [-0.00702715, -0.05630141, -0.07491843, ..., -0.04713988,\n",
       "                              0.07683658,  0.12342802],\n",
       "                            [ 0.05887094,  0.011359  ,  0.13479567, ...,  0.02035609,\n",
       "                              0.04081103, -0.06730566],\n",
       "                            [ 0.0104434 ,  0.00578225, -0.00243008, ...,  0.04907991,\n",
       "                              0.00637176,  0.0784311 ]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "             ln_1: {\n",
       "                 bias: Array([-0.04871175,  0.02247001,  0.01290948, ..., -0.05466871,\n",
       "                        -0.01394036,  0.05167119], dtype=float32),\n",
       "                 scale: Array([0.6034055 , 0.6730703 , 0.6188555 , ..., 0.61805576, 0.6372762 ,\n",
       "                        0.5989497 ], dtype=float32),\n",
       "             },\n",
       "             ln_2: {\n",
       "                 bias: Array([-0.00757353,  0.03367659,  0.00477509, ..., -0.01054952,\n",
       "                        -0.02696247, -0.0167887 ], dtype=float32),\n",
       "                 scale: Array([0.596448  , 0.600347  , 0.57950664, ..., 0.5904556 , 0.58764654,\n",
       "                        0.57420874], dtype=float32),\n",
       "             },\n",
       "             mlp: {\n",
       "                 c_fc: {\n",
       "                     bias: Array([-0.02089267, -0.03561738, -0.02525663, ..., -0.00969913,\n",
       "                            -0.0203202 , -0.04599214], dtype=float32),\n",
       "                     kernel: Array([[-0.00504305, -0.05604221, -0.00181415, ..., -0.03897604,\n",
       "                             -0.03967102, -0.03027343],\n",
       "                            [-0.01916372, -0.0152874 ,  0.05617457, ..., -0.02618344,\n",
       "                              0.04377534, -0.01673732],\n",
       "                            [-0.02615963,  0.00479415,  0.01352873, ...,  0.02595214,\n",
       "                              0.05427505,  0.03058844],\n",
       "                            ...,\n",
       "                            [ 0.0179693 , -0.10039305, -0.00379706, ..., -0.0444751 ,\n",
       "                              0.05734526,  0.05574265],\n",
       "                            [ 0.10179993, -0.00086252,  0.02332641, ..., -0.0215953 ,\n",
       "                             -0.00341649,  0.01167666],\n",
       "                            [ 0.03486129,  0.01836153,  0.05000818, ..., -0.00681704,\n",
       "                             -0.022394  , -0.08277243]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([ 0.09261163,  0.00975318, -0.01558575, ...,  0.07571046,\n",
       "                             0.05401323, -0.02973478], dtype=float32),\n",
       "                     kernel: Array([[-0.02022143,  0.00569107,  0.01175001, ...,  0.03252093,\n",
       "                             -0.06632023, -0.09724167],\n",
       "                            [ 0.00825289, -0.02581469, -0.03202711, ...,  0.05768035,\n",
       "                             -0.09794624,  0.0032318 ],\n",
       "                            [-0.01296987,  0.03839521, -0.04518783, ...,  0.03441418,\n",
       "                              0.00296795,  0.01897391],\n",
       "                            ...,\n",
       "                            [ 0.05119143,  0.02853582, -0.0477458 , ..., -0.00184995,\n",
       "                              0.02550353, -0.00109104],\n",
       "                            [ 0.11769976,  0.07796347, -0.01574976, ...,  0.01689333,\n",
       "                             -0.00228433,  0.05129116],\n",
       "                            [-0.02756833,  0.01577945, -0.00915658, ...,  0.0395131 ,\n",
       "                              0.01029188, -0.00063493]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "         },\n",
       "         22: {\n",
       "             attn: {\n",
       "                 c_attn: {\n",
       "                     bias: Array([ 0.13607493,  0.04685204, -0.04391244, ...,  0.01492716,\n",
       "                             0.01846233,  0.03275092], dtype=float32),\n",
       "                     kernel: Array([[ 0.07872644,  0.01023771, -0.04312853, ..., -0.04642517,\n",
       "                             -0.03421288,  0.11493006],\n",
       "                            [ 0.02485411,  0.08548222,  0.07861849, ..., -0.00758659,\n",
       "                             -0.03166668,  0.00284876],\n",
       "                            [ 0.0014311 , -0.01269848,  0.00912594, ...,  0.05239115,\n",
       "                             -0.07837898, -0.01828803],\n",
       "                            ...,\n",
       "                            [ 0.04342844, -0.02462738,  0.03599352, ...,  0.01139068,\n",
       "                              0.06779574, -0.02455051],\n",
       "                            [-0.01145856,  0.03130099, -0.05822335, ..., -0.00712848,\n",
       "                             -0.04774257, -0.02911753],\n",
       "                            [ 0.01411857,  0.06960575, -0.01569333, ...,  0.01524067,\n",
       "                             -0.08108055, -0.03409178]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([ 0.00239929,  0.01294487,  0.01235972, ..., -0.00968236,\n",
       "                            -0.04503226, -0.05384244], dtype=float32),\n",
       "                     kernel: Array([[ 0.08977881,  0.04142887,  0.10564359, ..., -0.05420395,\n",
       "                             -0.02767182, -0.0130657 ],\n",
       "                            [ 0.06843825, -0.0279256 , -0.02500243, ...,  0.04295657,\n",
       "                              0.03840125,  0.0001663 ],\n",
       "                            [ 0.04114043,  0.00044415,  0.04865029, ..., -0.01580736,\n",
       "                              0.0384939 , -0.0372007 ],\n",
       "                            ...,\n",
       "                            [ 0.07426982,  0.00960989, -0.02316997, ...,  0.01558032,\n",
       "                             -0.03408793, -0.05864759],\n",
       "                            [-0.00157117, -0.09032485, -0.05675702, ...,  0.10281228,\n",
       "                              0.01582431,  0.06869458],\n",
       "                            [-0.02996021, -0.04363362, -0.01398348, ..., -0.15164858,\n",
       "                              0.03406266,  0.02994627]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "             ln_1: {\n",
       "                 bias: Array([-0.04531379,  0.03045487,  0.02616123, ..., -0.04850341,\n",
       "                        -0.01495279,  0.05896061], dtype=float32),\n",
       "                 scale: Array([0.6230692 , 0.66806275, 0.6317619 , ..., 0.603238  , 0.6581266 ,\n",
       "                        0.5909449 ], dtype=float32),\n",
       "             },\n",
       "             ln_2: {\n",
       "                 bias: Array([-0.02087952,  0.03995658, -0.01470069, ...,  0.00895961,\n",
       "                        -0.03156648, -0.00585172], dtype=float32),\n",
       "                 scale: Array([0.60836226, 0.59570354, 0.6063196 , ..., 0.6099843 , 0.60674405,\n",
       "                        0.59255886], dtype=float32),\n",
       "             },\n",
       "             mlp: {\n",
       "                 c_fc: {\n",
       "                     bias: Array([-0.0570433 , -0.02322671, -0.06342912, ..., -0.00341037,\n",
       "                            -0.00786042, -0.01386776], dtype=float32),\n",
       "                     kernel: Array([[ 0.08982569,  0.01895569, -0.03554734, ..., -0.00922282,\n",
       "                              0.01708793,  0.02811556],\n",
       "                            [ 0.074959  ,  0.00425424,  0.02895497, ...,  0.02839677,\n",
       "                              0.05904635,  0.00651906],\n",
       "                            [ 0.06275684,  0.03412596,  0.00227118, ..., -0.01528389,\n",
       "                             -0.028851  ,  0.05223334],\n",
       "                            ...,\n",
       "                            [-0.02999853, -0.01299154,  0.00085046, ..., -0.0227606 ,\n",
       "                             -0.06462733, -0.01680464],\n",
       "                            [ 0.03627067, -0.0451975 ,  0.06351455, ..., -0.00237602,\n",
       "                              0.0405568 , -0.04717528],\n",
       "                            [-0.02556182, -0.02516484,  0.01838954, ..., -0.01576437,\n",
       "                             -0.0267796 , -0.0571578 ]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([ 0.08661888,  0.02154408,  0.00231346, ...,  0.09936658,\n",
       "                             0.04432339, -0.03243301], dtype=float32),\n",
       "                     kernel: Array([[ 0.09761712,  0.0380118 ,  0.01022819, ...,  0.00331025,\n",
       "                              0.03995302,  0.0357035 ],\n",
       "                            [-0.01547683,  0.03588755, -0.01004461, ..., -0.0039545 ,\n",
       "                              0.03064988,  0.05496456],\n",
       "                            [ 0.04384137, -0.0028001 ,  0.08869299, ...,  0.05640132,\n",
       "                              0.07671471,  0.05096716],\n",
       "                            ...,\n",
       "                            [ 0.00238317, -0.03219098,  0.05088168, ...,  0.0495422 ,\n",
       "                             -0.00387203, -0.07834072],\n",
       "                            [-0.00187271, -0.08689595, -0.0548289 , ...,  0.041515  ,\n",
       "                             -0.04509289, -0.02262975],\n",
       "                            [ 0.03674988,  0.0355045 , -0.0894437 , ...,  0.00412325,\n",
       "                              0.00772006, -0.02226596]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "         },\n",
       "         23: {\n",
       "             attn: {\n",
       "                 c_attn: {\n",
       "                     bias: Array([ 0.01130435, -0.2119545 , -0.06985862, ...,  0.00220974,\n",
       "                            -0.00682779, -0.01599673], dtype=float32),\n",
       "                     kernel: Array([[-0.05319105,  0.01753275,  0.0068251 , ...,  0.08997379,\n",
       "                              0.03709013, -0.05603239],\n",
       "                            [-0.03606088, -0.0673921 ,  0.03333364, ...,  0.0083128 ,\n",
       "                             -0.05825535,  0.03620552],\n",
       "                            [ 0.00045205,  0.03135101, -0.06476827, ...,  0.07201437,\n",
       "                             -0.00928433,  0.0358778 ],\n",
       "                            ...,\n",
       "                            [ 0.10220575,  0.03422525,  0.13289107, ...,  0.05318826,\n",
       "                             -0.0109406 ,  0.01089965],\n",
       "                            [-0.05208635, -0.05785751,  0.03448314, ...,  0.02890046,\n",
       "                             -0.02564199, -0.01917307],\n",
       "                            [-0.02310997, -0.09195558,  0.02649854, ..., -0.01156144,\n",
       "                              0.03046608, -0.01276849]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([ 0.02220725,  0.04424297,  0.01857724, ...,  0.0359815 ,\n",
       "                            -0.0053433 ,  0.01506631], dtype=float32),\n",
       "                     kernel: Array([[-0.02952477, -0.00846766,  0.07088155, ..., -0.0234778 ,\n",
       "                             -0.01688745,  0.02147029],\n",
       "                            [ 0.001619  ,  0.01171794,  0.05283532, ...,  0.11499456,\n",
       "                             -0.14075033, -0.02134434],\n",
       "                            [ 0.11324086,  0.00467748, -0.04864896, ...,  0.012159  ,\n",
       "                             -0.01168178,  0.00792744],\n",
       "                            ...,\n",
       "                            [-0.04661903,  0.00098595, -0.00937891, ..., -0.08157411,\n",
       "                             -0.03293565,  0.09749755],\n",
       "                            [ 0.00115191,  0.0698342 , -0.04090013, ...,  0.00431963,\n",
       "                             -0.02148944,  0.0063989 ],\n",
       "                            [ 0.08280032, -0.03542862, -0.02088439, ...,  0.03997981,\n",
       "                              0.08258989,  0.0454039 ]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "             ln_1: {\n",
       "                 bias: Array([-0.03856424,  0.02757837,  0.02446362, ..., -0.04247794,\n",
       "                        -0.00295823,  0.05280547], dtype=float32),\n",
       "                 scale: Array([0.58749133, 0.6352261 , 0.6042309 , ..., 0.5993141 , 0.6150768 ,\n",
       "                        0.5879631 ], dtype=float32),\n",
       "             },\n",
       "             ln_2: {\n",
       "                 bias: Array([-0.01005258,  0.05768003, -0.01568844, ...,  0.00984851,\n",
       "                        -0.02073039,  0.00820559], dtype=float32),\n",
       "                 scale: Array([0.6124049, 0.6115721, 0.6185084, ..., 0.6059691, 0.6108979,\n",
       "                        0.5885283], dtype=float32),\n",
       "             },\n",
       "             mlp: {\n",
       "                 c_fc: {\n",
       "                     bias: Array([-0.02993259, -0.01956174, -0.02127114, ..., -0.06169824,\n",
       "                            -0.008979  , -0.06398452], dtype=float32),\n",
       "                     kernel: Array([[-0.06166868, -0.04657903, -0.02274296, ..., -0.022193  ,\n",
       "                             -0.0436533 , -0.03043951],\n",
       "                            [-0.07992615,  0.07589023,  0.08089419, ..., -0.03614556,\n",
       "                             -0.00356165,  0.07402747],\n",
       "                            [ 0.0163006 ,  0.05898637,  0.0924417 , ..., -0.06690408,\n",
       "                              0.0406982 ,  0.03552123],\n",
       "                            ...,\n",
       "                            [ 0.09782213, -0.00053469,  0.04059136, ..., -0.05366432,\n",
       "                             -0.02707705, -0.04793151],\n",
       "                            [ 0.00866576, -0.01542873,  0.01160415, ..., -0.04350932,\n",
       "                              0.01651531, -0.00725376],\n",
       "                            [ 0.0398337 ,  0.0047906 , -0.03044674, ..., -0.04213767,\n",
       "                             -0.02560407,  0.00473585]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([ 0.10084744,  0.02022708,  0.02151616, ...,  0.0892951 ,\n",
       "                             0.06733526, -0.03571665], dtype=float32),\n",
       "                     kernel: Array([[ 0.04985581,  0.07883004, -0.00901213, ...,  0.02571049,\n",
       "                             -0.06257552,  0.02362835],\n",
       "                            [ 0.00954937, -0.03026714,  0.06135548, ...,  0.09132899,\n",
       "                             -0.01781857, -0.02898302],\n",
       "                            [-0.04250561, -0.03366736, -0.05901612, ..., -0.03372746,\n",
       "                             -0.09077298,  0.05186401],\n",
       "                            ...,\n",
       "                            [-0.09106388,  0.02234585, -0.01804745, ...,  0.01363148,\n",
       "                             -0.14233747, -0.04362331],\n",
       "                            [ 0.02952355, -0.01800693, -0.0233512 , ...,  0.05100125,\n",
       "                             -0.01204858,  0.04575884],\n",
       "                            [ 0.09953583, -0.01731489, -0.04036103, ...,  0.01293761,\n",
       "                             -0.01477395,  0.05601399]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "         },\n",
       "         24: {\n",
       "             attn: {\n",
       "                 c_attn: {\n",
       "                     bias: Array([-0.08682323, -0.08953819, -0.11071985, ...,  0.02331354,\n",
       "                            -0.02578703,  0.04642415], dtype=float32),\n",
       "                     kernel: Array([[-4.0798085e-03, -6.6940702e-02, -6.5720603e-02, ...,\n",
       "                             -7.0099615e-02,  3.3964656e-02,  5.5221796e-02],\n",
       "                            [-2.8782269e-02, -4.1684538e-02, -4.9125995e-02, ...,\n",
       "                             -7.9411842e-02,  2.2540517e-02,  2.0979846e-02],\n",
       "                            [-2.6679351e-03, -3.1292882e-02,  4.7914028e-02, ...,\n",
       "                              2.1068621e-02,  2.3961950e-03, -1.4893824e-02],\n",
       "                            ...,\n",
       "                            [-3.9574956e-03,  1.2713085e-02,  6.2645577e-02, ...,\n",
       "                              4.3617687e-03,  7.6970235e-02, -4.0249113e-02],\n",
       "                            [-1.7912544e-02, -4.8080739e-05, -1.7821465e-02, ...,\n",
       "                              3.1842146e-02,  3.2799296e-02, -7.5935595e-02],\n",
       "                            [-8.6035738e-03, -8.1000246e-02,  1.6519738e-02, ...,\n",
       "                             -1.4105981e-02, -2.5064223e-03,  3.2830898e-02]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([ 0.00306068, -0.0101853 , -0.01169661, ...,  0.02975926,\n",
       "                            -0.03308051, -0.03953887], dtype=float32),\n",
       "                     kernel: Array([[ 4.7471199e-02, -1.3141521e-03,  8.4509835e-02, ...,\n",
       "                             -1.1610147e-01,  4.9873631e-02, -3.4062959e-02],\n",
       "                            [-8.3750807e-02, -2.7741704e-02, -5.0398293e-03, ...,\n",
       "                             -1.0410378e-01, -2.3173122e-02,  7.5347371e-02],\n",
       "                            [-6.4737700e-02, -4.6096630e-02,  5.3840637e-02, ...,\n",
       "                              1.3343090e-02,  4.4627659e-02,  2.5758801e-02],\n",
       "                            ...,\n",
       "                            [-4.9841043e-02, -6.6350900e-02, -5.4778200e-05, ...,\n",
       "                              4.8151039e-02,  2.1904401e-02,  8.0025112e-03],\n",
       "                            [-2.1928551e-03,  1.7220614e-02, -4.7714639e-02, ...,\n",
       "                              7.5748138e-02,  1.2565204e-02, -1.7223077e-02],\n",
       "                            [ 6.8119869e-02,  1.6709473e-02, -2.5535058e-02, ...,\n",
       "                              8.4734987e-04, -4.8272781e-02,  2.6017347e-02]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "             ln_1: {\n",
       "                 bias: Array([-0.07041842,  0.03658365,  0.03611098, ..., -0.05139793,\n",
       "                        -0.00183388,  0.06711528], dtype=float32),\n",
       "                 scale: Array([0.60152185, 0.6454774 , 0.60627806, ..., 0.6035101 , 0.6446214 ,\n",
       "                        0.5669173 ], dtype=float32),\n",
       "             },\n",
       "             ln_2: {\n",
       "                 bias: Array([ 0.0007526 ,  0.03722879, -0.00329777, ...,  0.01269235,\n",
       "                        -0.03723563, -0.00786825], dtype=float32),\n",
       "                 scale: Array([0.63392276, 0.6322577 , 0.6232098 , ..., 0.6090939 , 0.6040574 ,\n",
       "                        0.60642153], dtype=float32),\n",
       "             },\n",
       "             mlp: {\n",
       "                 c_fc: {\n",
       "                     bias: Array([-0.01518947, -0.02644247,  0.03825267, ..., -0.0180012 ,\n",
       "                            -0.03271184,  0.23103924], dtype=float32),\n",
       "                     kernel: Array([[ 0.06258313,  0.05570807,  0.039972  , ..., -0.02027707,\n",
       "                             -0.04625286, -0.02190025],\n",
       "                            [ 0.04280059,  0.04065907, -0.00347291, ...,  0.09130964,\n",
       "                              0.02542553, -0.03375586],\n",
       "                            [ 0.07635804, -0.00301646, -0.01825454, ...,  0.04780808,\n",
       "                              0.10534018, -0.01884848],\n",
       "                            ...,\n",
       "                            [ 0.05052608, -0.00749221, -0.05530138, ...,  0.00047893,\n",
       "                             -0.02239023,  0.02722043],\n",
       "                            [-0.10669386,  0.03108924, -0.06048281, ..., -0.04183437,\n",
       "                              0.02208386, -0.01503669],\n",
       "                            [ 0.0834569 , -0.03601144, -0.01764772, ..., -0.0458272 ,\n",
       "                              0.04223731, -0.0397881 ]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([ 0.09988715,  0.02506278, -0.04435882, ...,  0.1153741 ,\n",
       "                             0.05896715, -0.04909685], dtype=float32),\n",
       "                     kernel: Array([[-1.11183882e-01,  4.88946959e-02, -1.15311965e-01, ...,\n",
       "                             -4.33988310e-03,  1.76954921e-02, -1.37121037e-01],\n",
       "                            [-2.27758605e-02, -6.11481853e-02, -9.47163068e-03, ...,\n",
       "                             -2.91282265e-03, -2.92960275e-02,  5.79026081e-02],\n",
       "                            [ 3.55743580e-02,  7.20156636e-03,  3.32421181e-03, ...,\n",
       "                              8.35759056e-06,  1.95386410e-02,  1.37276798e-01],\n",
       "                            ...,\n",
       "                            [ 3.13811600e-02, -4.04134616e-02,  4.68873186e-04, ...,\n",
       "                             -9.16434750e-02,  1.35253882e-02,  1.46682132e-02],\n",
       "                            [-4.44362946e-02, -3.01277749e-02,  3.00026070e-02, ...,\n",
       "                             -9.66222305e-03,  8.51506889e-02, -9.66528058e-02],\n",
       "                            [ 7.65936822e-03,  1.00845076e-01, -3.23497243e-02, ...,\n",
       "                              4.23948169e-02,  6.60993978e-02,  2.48202272e-02]],      dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "         },\n",
       "         25: {\n",
       "             attn: {\n",
       "                 c_attn: {\n",
       "                     bias: Array([-0.1289455 ,  0.16330567, -0.13653997, ..., -0.02351029,\n",
       "                             0.02553339, -0.00962968], dtype=float32),\n",
       "                     kernel: Array([[-0.04226483,  0.00967922, -0.00736656, ...,  0.00826818,\n",
       "                              0.07587086,  0.08316439],\n",
       "                            [ 0.08340012,  0.0466021 , -0.02631287, ...,  0.00098422,\n",
       "                              0.01323479,  0.03120746],\n",
       "                            [-0.02413506, -0.01285716,  0.06582233, ...,  0.02804967,\n",
       "                             -0.02344988, -0.02174537],\n",
       "                            ...,\n",
       "                            [-0.01796046,  0.04168903,  0.01571544, ..., -0.03382203,\n",
       "                              0.03717886, -0.06103807],\n",
       "                            [-0.00199184,  0.04865253,  0.02830883, ...,  0.03022796,\n",
       "                             -0.10839099, -0.00991654],\n",
       "                            [-0.02101414,  0.00481257, -0.08193987, ...,  0.02314355,\n",
       "                             -0.06680232,  0.03654501]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([ 0.04510463, -0.0124182 ,  0.02549286, ...,  0.04824359,\n",
       "                            -0.02837574, -0.05003877], dtype=float32),\n",
       "                     kernel: Array([[ 2.0352980e-02,  4.5279372e-02,  2.2953384e-02, ...,\n",
       "                              3.7086832e-03, -1.1105346e-02, -1.7830441e-02],\n",
       "                            [ 8.6942568e-02, -9.9768089e-03, -7.8985408e-02, ...,\n",
       "                              4.2044472e-02,  3.5176031e-02,  6.7568459e-02],\n",
       "                            [ 1.8315267e-02,  3.8303226e-02, -5.6982595e-02, ...,\n",
       "                              6.8408191e-02,  8.0332816e-02,  5.2971609e-02],\n",
       "                            ...,\n",
       "                            [ 7.6855890e-02,  7.6475409e-03,  9.0712821e-03, ...,\n",
       "                             -8.5192136e-02,  6.7820218e-03,  2.3423731e-02],\n",
       "                            [ 1.2482508e-02, -3.5793406e-03, -6.0341194e-02, ...,\n",
       "                              5.5297349e-02, -5.3664122e-02, -2.4174204e-02],\n",
       "                            [ 2.8141361e-02,  4.9107555e-02, -5.9210039e-03, ...,\n",
       "                             -2.9841131e-02,  1.2767939e-02, -8.4757041e-05]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "             ln_1: {\n",
       "                 bias: Array([-0.03921745,  0.02636211,  0.01889313, ..., -0.03588245,\n",
       "                        -0.00611736,  0.0573645 ], dtype=float32),\n",
       "                 scale: Array([0.63787705, 0.6559116 , 0.63281626, ..., 0.61730695, 0.6296161 ,\n",
       "                        0.56823313], dtype=float32),\n",
       "             },\n",
       "             ln_2: {\n",
       "                 bias: Array([-0.00521318,  0.06340391, -0.00695922, ..., -0.00719447,\n",
       "                        -0.02020623,  0.00540914], dtype=float32),\n",
       "                 scale: Array([0.6383911 , 0.63081783, 0.63396037, ..., 0.62248564, 0.6175139 ,\n",
       "                        0.60810435], dtype=float32),\n",
       "             },\n",
       "             mlp: {\n",
       "                 c_fc: {\n",
       "                     bias: Array([-0.0530381 , -0.03362967, -0.00787082, ..., -0.00289591,\n",
       "                            -0.05509384, -0.01189748], dtype=float32),\n",
       "                     kernel: Array([[-0.04979947, -0.01980531, -0.04885153, ..., -0.02901112,\n",
       "                              0.08301324, -0.0631896 ],\n",
       "                            [-0.00124944, -0.03650594,  0.04416089, ..., -0.06746771,\n",
       "                              0.00181281, -0.00386533],\n",
       "                            [-0.03025898, -0.05494162, -0.07810567, ...,  0.02740075,\n",
       "                             -0.010994  ,  0.01122028],\n",
       "                            ...,\n",
       "                            [ 0.05347668,  0.00393496, -0.05030884, ...,  0.00608242,\n",
       "                             -0.02283068, -0.03247952],\n",
       "                            [-0.01647436,  0.03838442,  0.03212191, ...,  0.04711544,\n",
       "                             -0.01209802, -0.01548866],\n",
       "                            [-0.00412397, -0.00648593, -0.06445888, ..., -0.05515492,\n",
       "                             -0.00255188,  0.01997395]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([ 0.10919188,  0.01121176, -0.02566492, ...,  0.09167251,\n",
       "                             0.06151072, -0.04206697], dtype=float32),\n",
       "                     kernel: Array([[ 0.02792775,  0.03400238, -0.00532731, ..., -0.06215054,\n",
       "                             -0.03930965, -0.00450816],\n",
       "                            [ 0.0168865 ,  0.08554682, -0.10881495, ...,  0.03189874,\n",
       "                             -0.07873329,  0.02678603],\n",
       "                            [ 0.05588805, -0.06132621,  0.0125571 , ..., -0.08130085,\n",
       "                              0.03474858,  0.03805121],\n",
       "                            ...,\n",
       "                            [ 0.10883   ,  0.07253934,  0.01150866, ..., -0.00345478,\n",
       "                             -0.00423129,  0.00084098],\n",
       "                            [-0.00892446, -0.0263825 , -0.03558468, ..., -0.02195606,\n",
       "                             -0.00128071, -0.02007642],\n",
       "                            [ 0.02374345, -0.05495197, -0.01534608, ...,  0.02014706,\n",
       "                              0.011052  ,  0.02925046]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "         },\n",
       "         26: {\n",
       "             attn: {\n",
       "                 c_attn: {\n",
       "                     bias: Array([ 0.02581429, -0.05454099,  0.00436157, ..., -0.0349655 ,\n",
       "                            -0.00665687, -0.05161881], dtype=float32),\n",
       "                     kernel: Array([[ 0.02244196,  0.02434135, -0.01557714, ...,  0.02720675,\n",
       "                             -0.06495118, -0.04963401],\n",
       "                            [-0.02757564, -0.03397835, -0.03644016, ...,  0.04092177,\n",
       "                             -0.07341589,  0.02504244],\n",
       "                            [-0.07903367,  0.01988593, -0.03886601, ...,  0.07283146,\n",
       "                              0.04240632, -0.01659592],\n",
       "                            ...,\n",
       "                            [-0.00771886, -0.00648043,  0.00413921, ...,  0.02936266,\n",
       "                              0.02465579,  0.00196146],\n",
       "                            [ 0.06376086, -0.08960963, -0.05332879, ...,  0.08281332,\n",
       "                              0.03815353, -0.04164173],\n",
       "                            [-0.0655084 , -0.04425504, -0.01144423, ..., -0.03820125,\n",
       "                              0.05517291, -0.05927392]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([ 0.01554102,  0.02720675,  0.05152647, ...,  0.03434435,\n",
       "                            -0.02765088, -0.04317724], dtype=float32),\n",
       "                     kernel: Array([[ 0.03706594,  0.0112928 , -0.03322989, ...,  0.02793203,\n",
       "                              0.03547444,  0.05720019],\n",
       "                            [ 0.00545072,  0.0283393 ,  0.05348562, ..., -0.08307636,\n",
       "                             -0.09272406, -0.03739393],\n",
       "                            [ 0.03684866, -0.00839204, -0.01648543, ...,  0.02982544,\n",
       "                             -0.01030634, -0.00968889],\n",
       "                            ...,\n",
       "                            [-0.0045019 , -0.07963221, -0.01779494, ..., -0.04812842,\n",
       "                             -0.01823154,  0.03654918],\n",
       "                            [ 0.02950233,  0.05435333, -0.06562749, ..., -0.02976582,\n",
       "                              0.00025267,  0.01827693],\n",
       "                            [-0.00689772,  0.01836124, -0.03657914, ..., -0.01536883,\n",
       "                             -0.01173077,  0.04103055]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "             ln_1: {\n",
       "                 bias: Array([-0.06901766,  0.04800751,  0.04390771, ..., -0.03014532,\n",
       "                        -0.01849931,  0.09053411], dtype=float32),\n",
       "                 scale: Array([0.62477386, 0.6582557 , 0.6385177 , ..., 0.6309743 , 0.6441703 ,\n",
       "                        0.5812812 ], dtype=float32),\n",
       "             },\n",
       "             ln_2: {\n",
       "                 bias: Array([-0.02031913,  0.06555955, -0.00822894, ...,  0.01335153,\n",
       "                        -0.03249934,  0.02670768], dtype=float32),\n",
       "                 scale: Array([0.659243  , 0.64845353, 0.65309596, ..., 0.6191399 , 0.62382764,\n",
       "                        0.61132747], dtype=float32),\n",
       "             },\n",
       "             mlp: {\n",
       "                 c_fc: {\n",
       "                     bias: Array([-0.00633441, -0.04594286, -0.02174013, ..., -0.04559875,\n",
       "                            -0.03158432, -0.00711211], dtype=float32),\n",
       "                     kernel: Array([[-0.03183161, -0.0299914 , -0.00205787, ..., -0.06204181,\n",
       "                             -0.02145538,  0.0526646 ],\n",
       "                            [ 0.02356382,  0.03149422,  0.0396849 , ...,  0.03640375,\n",
       "                              0.03741847,  0.07865856],\n",
       "                            [ 0.0429712 ,  0.05447725,  0.08667465, ...,  0.00490768,\n",
       "                              0.01216048,  0.02898181],\n",
       "                            ...,\n",
       "                            [-0.03673457,  0.07216199, -0.05016424, ...,  0.00367197,\n",
       "                              0.02676814, -0.00631639],\n",
       "                            [-0.04069392,  0.02792463, -0.01425844, ..., -0.07295031,\n",
       "                             -0.01980137,  0.07057261],\n",
       "                            [ 0.06424533,  0.03303708, -0.00665926, ..., -0.00391456,\n",
       "                              0.00112222,  0.07107647]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([ 0.1244736 ,  0.01406779, -0.03167156, ...,  0.10849836,\n",
       "                             0.07519187, -0.08478455], dtype=float32),\n",
       "                     kernel: Array([[-0.01968852,  0.04497705, -0.03997092, ...,  0.11892828,\n",
       "                             -0.04230844,  0.0415731 ],\n",
       "                            [ 0.09489341,  0.03460022, -0.03469254, ..., -0.15056716,\n",
       "                              0.02452694,  0.01104123],\n",
       "                            [ 0.01909725,  0.00264112, -0.0293805 , ..., -0.04516771,\n",
       "                              0.02065708,  0.0632309 ],\n",
       "                            ...,\n",
       "                            [-0.02065447, -0.05794155, -0.02304376, ...,  0.05574768,\n",
       "                              0.01659188, -0.04844369],\n",
       "                            [ 0.02511849,  0.06121323, -0.02173042, ..., -0.00254218,\n",
       "                              0.08363768,  0.02662364],\n",
       "                            [-0.00209621, -0.13314883, -0.0625385 , ...,  0.01462454,\n",
       "                             -0.0718931 , -0.06971475]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "         },\n",
       "         27: {\n",
       "             attn: {\n",
       "                 c_attn: {\n",
       "                     bias: Array([ 0.18031748, -0.03621631,  0.04615216, ..., -0.01316749,\n",
       "                             0.01838915,  0.03005741], dtype=float32),\n",
       "                     kernel: Array([[ 0.09107968, -0.01154158, -0.04174169, ..., -0.00518121,\n",
       "                              0.00610641, -0.00322865],\n",
       "                            [ 0.08234366, -0.03017472, -0.04114359, ...,  0.0464556 ,\n",
       "                              0.01406244,  0.01993613],\n",
       "                            [-0.0029447 ,  0.01008877,  0.03627313, ..., -0.00706738,\n",
       "                              0.03087416,  0.01078075],\n",
       "                            ...,\n",
       "                            [ 0.0137574 ,  0.06666136, -0.08058833, ..., -0.01218237,\n",
       "                             -0.03574141,  0.01473121],\n",
       "                            [ 0.07159632, -0.01518889, -0.01170235, ...,  0.04352067,\n",
       "                             -0.00790837, -0.01977403],\n",
       "                            [-0.06641539,  0.00587102,  0.0272095 , ..., -0.00843361,\n",
       "                              0.02857258, -0.0168533 ]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([-0.0437433 , -0.00789087,  0.01361091, ...,  0.01327209,\n",
       "                             0.00980487, -0.02389253], dtype=float32),\n",
       "                     kernel: Array([[-0.02128172, -0.00767041,  0.02922211, ...,  0.01179373,\n",
       "                              0.10493954,  0.05735696],\n",
       "                            [-0.03369264, -0.01253813, -0.0074418 , ..., -0.06458379,\n",
       "                              0.02519838,  0.00335785],\n",
       "                            [ 0.04339097,  0.01884186, -0.04292892, ...,  0.0015187 ,\n",
       "                              0.02408279, -0.04888967],\n",
       "                            ...,\n",
       "                            [ 0.01483284,  0.03718988, -0.02335863, ..., -0.01113205,\n",
       "                              0.06920952,  0.03004962],\n",
       "                            [ 0.13422854, -0.07996015, -0.01691975, ...,  0.00721085,\n",
       "                             -0.00744147, -0.08529509],\n",
       "                            [-0.01042583,  0.08435161,  0.01266286, ..., -0.03900534,\n",
       "                             -0.04061443, -0.09002167]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "             ln_1: {\n",
       "                 bias: Array([-0.03935993,  0.04210049,  0.03791028, ..., -0.01414481,\n",
       "                         0.00725579,  0.08701499], dtype=float32),\n",
       "                 scale: Array([0.64697015, 0.6598356 , 0.6296415 , ..., 0.6235519 , 0.63929147,\n",
       "                        0.5605473 ], dtype=float32),\n",
       "             },\n",
       "             ln_2: {\n",
       "                 bias: Array([ 0.0142786 ,  0.04832748,  0.00169814, ...,  0.02434055,\n",
       "                        -0.02847543,  0.02292089], dtype=float32),\n",
       "                 scale: Array([0.68103963, 0.66046387, 0.6647597 , ..., 0.6455879 , 0.6442979 ,\n",
       "                        0.63077784], dtype=float32),\n",
       "             },\n",
       "             mlp: {\n",
       "                 c_fc: {\n",
       "                     bias: Array([-0.03138945, -0.02544568,  0.02454551, ..., -0.07833876,\n",
       "                            -0.03669316, -0.00373337], dtype=float32),\n",
       "                     kernel: Array([[-0.01572742, -0.0072501 ,  0.06276424, ...,  0.02060526,\n",
       "                             -0.00532918,  0.0071026 ],\n",
       "                            [-0.01332407,  0.00877468,  0.04324963, ...,  0.04668441,\n",
       "                              0.021214  ,  0.10060051],\n",
       "                            [-0.09169116, -0.05342892,  0.02303477, ..., -0.01233622,\n",
       "                             -0.04687798,  0.01470434],\n",
       "                            ...,\n",
       "                            [ 0.02295444, -0.02797161, -0.01148873, ..., -0.01321255,\n",
       "                             -0.0499148 , -0.03617289],\n",
       "                            [ 0.064367  ,  0.03254566, -0.00423425, ...,  0.00764993,\n",
       "                             -0.00751952,  0.01903526],\n",
       "                            [-0.00466183, -0.00439861, -0.04890677, ...,  0.00661942,\n",
       "                             -0.0386942 ,  0.02449425]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([ 0.13186419,  0.03070578, -0.02087319, ...,  0.11900023,\n",
       "                             0.08503728, -0.06235469], dtype=float32),\n",
       "                     kernel: Array([[ 0.00961129,  0.06459115, -0.0057068 , ...,  0.04327742,\n",
       "                              0.03207821,  0.01733139],\n",
       "                            [ 0.02803318,  0.01142326,  0.09936376, ...,  0.11124674,\n",
       "                             -0.03095932,  0.02084947],\n",
       "                            [ 0.04780394,  0.01632296, -0.00124211, ...,  0.07517614,\n",
       "                             -0.00166773, -0.00552338],\n",
       "                            ...,\n",
       "                            [ 0.12412778,  0.07669675,  0.04671932, ...,  0.18074535,\n",
       "                              0.02515819,  0.02037663],\n",
       "                            [ 0.02932805, -0.04011674,  0.08285222, ...,  0.0535056 ,\n",
       "                             -0.10065029, -0.03230719],\n",
       "                            [ 0.00644633, -0.18921001,  0.00765976, ...,  0.01420581,\n",
       "                              0.01696899,  0.01759938]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "         },\n",
       "         28: {\n",
       "             attn: {\n",
       "                 c_attn: {\n",
       "                     bias: Array([-0.0029152 , -0.03091265,  0.09329583, ..., -0.03354475,\n",
       "                             0.02203763, -0.00267745], dtype=float32),\n",
       "                     kernel: Array([[ 0.00706738,  0.09748875,  0.0009915 , ...,  0.02441038,\n",
       "                             -0.0593266 ,  0.0642813 ],\n",
       "                            [ 0.04088077,  0.00228497,  0.03690389, ..., -0.0298638 ,\n",
       "                             -0.01181031, -0.04552187],\n",
       "                            [-0.04400874, -0.03202424, -0.01202633, ...,  0.03101915,\n",
       "                              0.02184749,  0.01237838],\n",
       "                            ...,\n",
       "                            [-0.06035401,  0.06210288, -0.01766469, ..., -0.08617727,\n",
       "                              0.03673136, -0.09884647],\n",
       "                            [ 0.03404038,  0.01777626,  0.00796143, ...,  0.10897094,\n",
       "                             -0.01102099,  0.04511466],\n",
       "                            [-0.08335302,  0.14630537,  0.06059798, ...,  0.03800319,\n",
       "                             -0.0394122 ,  0.01938132]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([-0.00966813, -0.00192081,  0.01525487, ..., -0.02853198,\n",
       "                            -0.02402867, -0.06698362], dtype=float32),\n",
       "                     kernel: Array([[-0.06178613, -0.07032565, -0.03513376, ...,  0.03529928,\n",
       "                             -0.0741185 , -0.08269883],\n",
       "                            [-0.02231484,  0.01906584,  0.07621469, ..., -0.00207866,\n",
       "                             -0.00104101, -0.04729763],\n",
       "                            [-0.04971511, -0.03679726, -0.0644962 , ..., -0.06790421,\n",
       "                             -0.12373959,  0.05511543],\n",
       "                            ...,\n",
       "                            [-0.01312885, -0.00591554,  0.01366898, ...,  0.08229617,\n",
       "                             -0.04982107,  0.04832614],\n",
       "                            [ 0.01681469, -0.06390781, -0.13968655, ...,  0.00674789,\n",
       "                             -0.00624019,  0.06472278],\n",
       "                            [-0.09490924,  0.00667255, -0.03415025, ...,  0.01763641,\n",
       "                              0.03430586, -0.01165899]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "             ln_1: {\n",
       "                 bias: Array([-0.03606706,  0.03778488,  0.04421993, ..., -0.02354234,\n",
       "                         0.02217534,  0.09670716], dtype=float32),\n",
       "                 scale: Array([0.6661242 , 0.6782926 , 0.6349123 , ..., 0.6261518 , 0.6628982 ,\n",
       "                        0.58533615], dtype=float32),\n",
       "             },\n",
       "             ln_2: {\n",
       "                 bias: Array([-0.02438473,  0.06023987, -0.00225281, ...,  0.00029614,\n",
       "                        -0.0168546 ,  0.02977363], dtype=float32),\n",
       "                 scale: Array([0.6774901 , 0.6649628 , 0.67258304, ..., 0.6548463 , 0.6465535 ,\n",
       "                        0.63670355], dtype=float32),\n",
       "             },\n",
       "             mlp: {\n",
       "                 c_fc: {\n",
       "                     bias: Array([-0.01206196, -0.02394314, -0.02664112, ..., -0.03623279,\n",
       "                            -0.0159948 , -0.02100796], dtype=float32),\n",
       "                     kernel: Array([[-0.05659195, -0.0158085 ,  0.0060962 , ...,  0.0350351 ,\n",
       "                             -0.01078128, -0.00998559],\n",
       "                            [ 0.09228021, -0.0487381 ,  0.02292343, ...,  0.00796392,\n",
       "                             -0.05485405,  0.02752681],\n",
       "                            [ 0.05883615, -0.05510887, -0.02635392, ..., -0.0800201 ,\n",
       "                             -0.02581288,  0.04288635],\n",
       "                            ...,\n",
       "                            [-0.06560693, -0.01492309,  0.04117934, ..., -0.0043043 ,\n",
       "                              0.04221445, -0.01469602],\n",
       "                            [-0.01607635,  0.00806978, -0.00446994, ..., -0.06016924,\n",
       "                             -0.02600466, -0.00869363],\n",
       "                            [-0.00159084,  0.0529605 ,  0.08014967, ..., -0.02234514,\n",
       "                              0.09506532, -0.01711546]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([ 0.10363264, -0.03172447, -0.03195671, ...,  0.08797346,\n",
       "                             0.01619527, -0.05649939], dtype=float32),\n",
       "                     kernel: Array([[ 0.0641858 ,  0.06738296,  0.02373474, ...,  0.10414805,\n",
       "                              0.0194329 , -0.01112255],\n",
       "                            [ 0.09295705,  0.15221433, -0.13802534, ...,  0.02763773,\n",
       "                              0.02888024, -0.00029989],\n",
       "                            [-0.07474239,  0.02317366, -0.01360125, ...,  0.0439614 ,\n",
       "                             -0.02199297,  0.01585953],\n",
       "                            ...,\n",
       "                            [-0.0274353 , -0.03407631, -0.00170163, ...,  0.01189011,\n",
       "                             -0.02656321,  0.00544691],\n",
       "                            [ 0.01265528, -0.01284876,  0.0541671 , ...,  0.02403335,\n",
       "                             -0.01993543,  0.01771096],\n",
       "                            [-0.00489229, -0.02122924, -0.06137764, ...,  0.02456915,\n",
       "                             -0.09437401,  0.07504216]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "         },\n",
       "         29: {\n",
       "             attn: {\n",
       "                 c_attn: {\n",
       "                     bias: Array([-6.5492317e-02,  7.6594202e-05, -8.1142344e-02, ...,\n",
       "                            -1.4974673e-02,  2.4560306e-03, -3.6610391e-02], dtype=float32),\n",
       "                     kernel: Array([[-0.02878206, -0.04092327,  0.00786334, ...,  0.05979552,\n",
       "                             -0.05206965,  0.05490621],\n",
       "                            [-0.00050478, -0.00802543,  0.01585814, ..., -0.0076446 ,\n",
       "                              0.02137084, -0.01566425],\n",
       "                            [-0.00068938,  0.01285715,  0.01846122, ...,  0.00045941,\n",
       "                              0.03031413, -0.03258632],\n",
       "                            ...,\n",
       "                            [ 0.05659772, -0.05006389,  0.02181705, ..., -0.00997181,\n",
       "                             -0.05008129,  0.01242909],\n",
       "                            [ 0.10286622, -0.06702061, -0.11346908, ...,  0.01817758,\n",
       "                             -0.03092838, -0.01207771],\n",
       "                            [ 0.03055191,  0.13532507, -0.00642909, ..., -0.02669538,\n",
       "                             -0.05159999, -0.02411988]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([-0.01254634, -0.0132088 ,  0.02160191, ...,  0.00906816,\n",
       "                            -0.03575642, -0.0845812 ], dtype=float32),\n",
       "                     kernel: Array([[ 0.05700509,  0.00497324, -0.01456862, ..., -0.03619868,\n",
       "                              0.08638845, -0.15162478],\n",
       "                            [-0.00502365,  0.00219955, -0.00636662, ..., -0.09527145,\n",
       "                              0.03006193,  0.00340957],\n",
       "                            [ 0.02584223, -0.00296134, -0.06226911, ..., -0.03202894,\n",
       "                              0.02279687,  0.04561101],\n",
       "                            ...,\n",
       "                            [-0.00196089,  0.0287503 , -0.03057995, ...,  0.02343622,\n",
       "                             -0.04834866,  0.00552493],\n",
       "                            [ 0.0512859 , -0.00306344, -0.05811785, ...,  0.00573064,\n",
       "                             -0.08609475,  0.01212737],\n",
       "                            [ 0.03737817, -0.00241087,  0.05330568, ..., -0.00038502,\n",
       "                              0.12874474, -0.0006802 ]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "             ln_1: {\n",
       "                 bias: Array([-0.02455145,  0.03058603,  0.03719166, ..., -0.01994837,\n",
       "                         0.01836141,  0.08534354], dtype=float32),\n",
       "                 scale: Array([0.66571313, 0.6793051 , 0.6584979 , ..., 0.66018856, 0.66855776,\n",
       "                        0.59982806], dtype=float32),\n",
       "             },\n",
       "             ln_2: {\n",
       "                 bias: Array([-0.00092424,  0.05684006,  0.00719578, ...,  0.01077093,\n",
       "                        -0.02484591,  0.01966389], dtype=float32),\n",
       "                 scale: Array([0.6958831 , 0.68425065, 0.7045131 , ..., 0.66469365, 0.65222967,\n",
       "                        0.65411067], dtype=float32),\n",
       "             },\n",
       "             mlp: {\n",
       "                 c_fc: {\n",
       "                     bias: Array([-0.05829044, -0.02374266, -0.01468315, ..., -0.03270705,\n",
       "                            -0.00469313, -0.02370166], dtype=float32),\n",
       "                     kernel: Array([[-0.00165362, -0.070602  ,  0.03418419, ..., -0.0709442 ,\n",
       "                             -0.10003561, -0.07287399],\n",
       "                            [-0.02038668, -0.08704021, -0.02241413, ..., -0.01922433,\n",
       "                              0.02820271,  0.06017419],\n",
       "                            [ 0.01434412, -0.04531473,  0.03240838, ...,  0.05578468,\n",
       "                              0.01741475, -0.05678108],\n",
       "                            ...,\n",
       "                            [-0.01774768,  0.05846839,  0.03169994, ..., -0.05929279,\n",
       "                              0.04063675,  0.03293695],\n",
       "                            [ 0.00702227, -0.04457054, -0.02520382, ..., -0.08201456,\n",
       "                             -0.02052411,  0.09332031],\n",
       "                            [ 0.05559367,  0.05515191, -0.047586  , ...,  0.01981721,\n",
       "                             -0.02444832, -0.01336194]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([ 0.12699813, -0.00794126, -0.04286527, ...,  0.08063866,\n",
       "                             0.04633417, -0.09016827], dtype=float32),\n",
       "                     kernel: Array([[ 0.0784732 , -0.07666142,  0.01368152, ..., -0.04555255,\n",
       "                             -0.11178143,  0.10755516],\n",
       "                            [-0.04570652, -0.13268942,  0.02192058, ...,  0.02403388,\n",
       "                             -0.01525486, -0.04137135],\n",
       "                            [-0.03219367, -0.0091955 , -0.02592765, ..., -0.03820977,\n",
       "                              0.03621497,  0.06109991],\n",
       "                            ...,\n",
       "                            [-0.02078742,  0.02292055, -0.04030523, ..., -0.00163809,\n",
       "                              0.0087313 ,  0.01009073],\n",
       "                            [ 0.03662073,  0.08739969,  0.09527498, ..., -0.01411021,\n",
       "                             -0.04835924,  0.05394901],\n",
       "                            [ 0.0894089 , -0.03392917, -0.01061959, ...,  0.01566046,\n",
       "                             -0.11367717,  0.07338622]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "         },\n",
       "         3: {\n",
       "             attn: {\n",
       "                 c_attn: {\n",
       "                     bias: Array([ 0.1845229 , -0.00281118,  0.096673  , ..., -0.00667497,\n",
       "                            -0.005991  ,  0.00726198], dtype=float32),\n",
       "                     kernel: Array([[ 0.02560152, -0.00467859, -0.06944604, ...,  0.01192849,\n",
       "                              0.02425067, -0.01342591],\n",
       "                            [-0.00692974, -0.00426727,  0.09353615, ..., -0.01939737,\n",
       "                              0.04342277,  0.01377604],\n",
       "                            [ 0.00408478,  0.07869735, -0.00962142, ...,  0.01014984,\n",
       "                             -0.00889346, -0.00949982],\n",
       "                            ...,\n",
       "                            [ 0.05423979, -0.02228798,  0.06130129, ..., -0.01267134,\n",
       "                              0.02359089,  0.01019178],\n",
       "                            [ 0.04828317, -0.02266806,  0.04084509, ...,  0.02143092,\n",
       "                              0.03602462,  0.03675512],\n",
       "                            [-0.04384729,  0.03462821, -0.1237605 , ..., -0.03729232,\n",
       "                             -0.0225767 , -0.02363221]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([-0.05469384,  0.03945774, -0.03383378, ...,  0.03936506,\n",
       "                             0.02620739,  0.02831275], dtype=float32),\n",
       "                     kernel: Array([[-0.04776809,  0.01282799, -0.04497882, ...,  0.04638562,\n",
       "                             -0.00864599, -0.00445575],\n",
       "                            [ 0.02163986, -0.01251436, -0.00652038, ..., -0.01409613,\n",
       "                              0.03312163, -0.02769929],\n",
       "                            [ 0.03640869, -0.02414897, -0.00497156, ...,  0.03191787,\n",
       "                              0.0248321 ,  0.01002653],\n",
       "                            ...,\n",
       "                            [ 0.05189879,  0.02473487,  0.02943767, ..., -0.00167179,\n",
       "                              0.05292583, -0.0287055 ],\n",
       "                            [-0.00311479,  0.01840742,  0.03878686, ..., -0.03478032,\n",
       "                             -0.01744408, -0.01010828],\n",
       "                            [-0.023813  ,  0.03249106, -0.03948287, ...,  0.03684202,\n",
       "                             -0.01500207, -0.02208531]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "             ln_1: {\n",
       "                 bias: Array([-0.05879219, -0.03812889,  0.00097701, ..., -0.12151992,\n",
       "                        -0.05717241, -0.05302386], dtype=float32),\n",
       "                 scale: Array([0.42416787, 0.43461952, 0.41767725, ..., 0.4230136 , 0.44517362,\n",
       "                        0.36690018], dtype=float32),\n",
       "             },\n",
       "             ln_2: {\n",
       "                 bias: Array([-0.05657151, -0.07421769,  0.03027099, ...,  0.04805579,\n",
       "                         0.01161695,  0.02118138], dtype=float32),\n",
       "                 scale: Array([0.5440578 , 0.6009363 , 0.5861723 , ..., 0.5579305 , 0.52946264,\n",
       "                        0.5604176 ], dtype=float32),\n",
       "             },\n",
       "             mlp: {\n",
       "                 c_fc: {\n",
       "                     bias: Array([ 0.02008365, -0.04335994, -0.04811539, ..., -0.0369886 ,\n",
       "                            -0.02763673, -0.03615285], dtype=float32),\n",
       "                     kernel: Array([[-4.87263128e-02,  3.04449257e-02,  3.76069173e-02, ...,\n",
       "                              2.41025258e-02,  4.95651783e-03,  7.12151378e-02],\n",
       "                            [-6.64168000e-02,  9.78267789e-02, -9.36485827e-02, ...,\n",
       "                              4.11840640e-02,  5.40478751e-02,  8.44381899e-02],\n",
       "                            [ 3.15614715e-02, -3.19348797e-02,  2.03962978e-02, ...,\n",
       "                              1.35037629e-03, -1.36509746e-01, -5.62309511e-02],\n",
       "                            ...,\n",
       "                            [ 3.05820741e-02,  6.89434214e-03, -5.27304830e-03, ...,\n",
       "                             -6.91576004e-02, -3.72570790e-02, -1.20530903e-01],\n",
       "                            [-1.61442626e-02, -7.11905882e-02, -1.28716370e-02, ...,\n",
       "                             -8.41329992e-03, -5.06377146e-02, -5.05314544e-02],\n",
       "                            [-2.87453271e-02, -3.28882597e-03, -1.04226045e-01, ...,\n",
       "                              2.22939122e-02,  9.58900855e-05, -3.11482307e-02]],      dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([-0.02024017, -0.05440358, -0.01548452, ...,  0.02491841,\n",
       "                             0.06844142,  0.02859765], dtype=float32),\n",
       "                     kernel: Array([[ 0.03331364,  0.06400297, -0.01855358, ..., -0.03832754,\n",
       "                              0.01542173, -0.0048696 ],\n",
       "                            [-0.05146594,  0.02185625,  0.05930527, ..., -0.03747976,\n",
       "                             -0.02957374, -0.07287274],\n",
       "                            [ 0.00588947, -0.03667685,  0.01135078, ..., -0.02363698,\n",
       "                             -0.03470327, -0.00713065],\n",
       "                            ...,\n",
       "                            [-0.06172661, -0.01876316, -0.00136118, ...,  0.01576167,\n",
       "                             -0.01589264,  0.06185005],\n",
       "                            [-0.01635051, -0.05677294, -0.05716744, ..., -0.00058858,\n",
       "                             -0.00435702,  0.05391692],\n",
       "                            [-0.01593222,  0.01524191, -0.06790785, ..., -0.07336605,\n",
       "                              0.03944391,  0.00866679]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "         },\n",
       "         30: {\n",
       "             attn: {\n",
       "                 c_attn: {\n",
       "                     bias: Array([ 0.08429743, -0.05830116, -0.11457928, ..., -0.02350396,\n",
       "                             0.01723482, -0.01162391], dtype=float32),\n",
       "                     kernel: Array([[-0.13391183, -0.07271236,  0.00893132, ...,  0.01888596,\n",
       "                              0.01062317, -0.03884715],\n",
       "                            [ 0.03476079,  0.01682665,  0.05608271, ...,  0.03457185,\n",
       "                             -0.03449567, -0.01777866],\n",
       "                            [ 0.00437559,  0.09642181,  0.1429662 , ..., -0.07718874,\n",
       "                             -0.04206378,  0.00135385],\n",
       "                            ...,\n",
       "                            [ 0.00469365, -0.0653531 ,  0.00311756, ...,  0.0242859 ,\n",
       "                             -0.0472205 ,  0.01812416],\n",
       "                            [-0.04331171, -0.00360207, -0.08306351, ..., -0.0602349 ,\n",
       "                             -0.02768464,  0.0094314 ],\n",
       "                            [ 0.04474568, -0.04057062,  0.02861446, ..., -0.00661448,\n",
       "                             -0.02611531,  0.01623613]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([-0.00979887,  0.0020738 , -0.01520485, ..., -0.00950568,\n",
       "                            -0.01995552, -0.06765304], dtype=float32),\n",
       "                     kernel: Array([[ 0.07731675, -0.03610476,  0.08210012, ...,  0.06080029,\n",
       "                             -0.0389224 , -0.03253014],\n",
       "                            [-0.12535688,  0.00635177, -0.09322337, ...,  0.02202126,\n",
       "                             -0.10716021,  0.013812  ],\n",
       "                            [-0.0852044 , -0.10821837, -0.07315638, ...,  0.02744699,\n",
       "                              0.07516274, -0.07353078],\n",
       "                            ...,\n",
       "                            [ 0.0124803 ,  0.04094421,  0.01842416, ..., -0.03486301,\n",
       "                              0.01281179,  0.02014803],\n",
       "                            [ 0.03919418,  0.05436638,  0.02971482, ...,  0.09978142,\n",
       "                             -0.01307707,  0.00939483],\n",
       "                            [-0.06314261,  0.03445994, -0.02607337, ..., -0.02183816,\n",
       "                              0.08511609, -0.00759155]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "             ln_1: {\n",
       "                 bias: Array([-0.038782  ,  0.03198827,  0.04679318, ..., -0.01971343,\n",
       "                         0.01430554,  0.10981038], dtype=float32),\n",
       "                 scale: Array([0.6817928, 0.7200065, 0.6913661, ..., 0.6892894, 0.7052865,\n",
       "                        0.6082412], dtype=float32),\n",
       "             },\n",
       "             ln_2: {\n",
       "                 bias: Array([ 0.01136859,  0.05388467,  0.01352031, ...,  0.00956906,\n",
       "                        -0.02010782, -0.00218282], dtype=float32),\n",
       "                 scale: Array([0.7068323 , 0.69375074, 0.71402675, ..., 0.68601996, 0.67731   ,\n",
       "                        0.67097664], dtype=float32),\n",
       "             },\n",
       "             mlp: {\n",
       "                 c_fc: {\n",
       "                     bias: Array([-0.02404595, -0.04133944, -0.04853708, ..., -0.02018493,\n",
       "                            -0.03288653, -0.06636956], dtype=float32),\n",
       "                     kernel: Array([[ 0.03618062,  0.07752635, -0.03100723, ..., -0.0481842 ,\n",
       "                              0.00597818, -0.09052283],\n",
       "                            [ 0.0155154 ,  0.0203889 , -0.06064181, ...,  0.02899469,\n",
       "                              0.05039908, -0.02304267],\n",
       "                            [-0.00252103,  0.09770602,  0.02824152, ..., -0.00806757,\n",
       "                              0.02829338, -0.06197393],\n",
       "                            ...,\n",
       "                            [ 0.00466659, -0.01640653,  0.06151908, ...,  0.02649108,\n",
       "                              0.05165996, -0.03628633],\n",
       "                            [-0.01857468,  0.01578962,  0.01326492, ..., -0.00947275,\n",
       "                              0.06011204,  0.01193252],\n",
       "                            [ 0.05231229, -0.00329985, -0.01439339, ..., -0.02041088,\n",
       "                              0.01473408, -0.08531725]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([ 0.04913253, -0.04145812, -0.02983723, ...,  0.06165254,\n",
       "                             0.03158101, -0.09936002], dtype=float32),\n",
       "                     kernel: Array([[ 0.01805865,  0.04208896,  0.04477213, ...,  0.07314653,\n",
       "                             -0.11545854,  0.04769914],\n",
       "                            [ 0.01732761,  0.06979176, -0.00941007, ...,  0.05031838,\n",
       "                              0.04056159, -0.12081973],\n",
       "                            [ 0.02240677,  0.00080301, -0.12210792, ..., -0.02863373,\n",
       "                             -0.08989441,  0.03179786],\n",
       "                            ...,\n",
       "                            [ 0.0872535 , -0.06845548,  0.01014377, ...,  0.05958569,\n",
       "                             -0.02840745,  0.02032521],\n",
       "                            [ 0.03249578, -0.09748071, -0.02042417, ..., -0.04920047,\n",
       "                             -0.08113247, -0.01306583],\n",
       "                            [ 0.09720913,  0.04699811,  0.02557297, ...,  0.0071223 ,\n",
       "                              0.04391241,  0.07948188]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "         },\n",
       "         31: {\n",
       "             attn: {\n",
       "                 c_attn: {\n",
       "                     bias: Array([ 0.05363272,  0.04470649, -0.02060365, ..., -0.07785188,\n",
       "                            -0.04952186, -0.05489444], dtype=float32),\n",
       "                     kernel: Array([[-0.05583104, -0.01492386, -0.00143732, ..., -0.01518343,\n",
       "                              0.0503323 , -0.01592775],\n",
       "                            [-0.02267788, -0.01050765,  0.01312723, ..., -0.08813708,\n",
       "                             -0.01890859,  0.03947265],\n",
       "                            [ 0.01519271, -0.02480238,  0.10329616, ...,  0.08349813,\n",
       "                             -0.00586374, -0.01937306],\n",
       "                            ...,\n",
       "                            [ 0.12258042,  0.01187363,  0.00828306, ..., -0.00294191,\n",
       "                              0.03865072, -0.03171575],\n",
       "                            [-0.00137203,  0.01714638, -0.00948514, ...,  0.01562135,\n",
       "                             -0.0625431 ,  0.04900201],\n",
       "                            [-0.07108207, -0.01360727, -0.00427834, ...,  0.01437691,\n",
       "                              0.06776626,  0.06081424]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([-0.00143474, -0.03984059, -0.04358477, ..., -0.01376859,\n",
       "                            -0.01267096, -0.09593121], dtype=float32),\n",
       "                     kernel: Array([[ 0.00365323,  0.00064703,  0.07230619, ...,  0.00120284,\n",
       "                             -0.08096784, -0.02423728],\n",
       "                            [ 0.0099964 , -0.01656508, -0.03108179, ..., -0.0002104 ,\n",
       "                             -0.01161549,  0.03549656],\n",
       "                            [ 0.03240053, -0.01084892, -0.03249314, ..., -0.09491397,\n",
       "                              0.04340025, -0.03390358],\n",
       "                            ...,\n",
       "                            [-0.05043704,  0.01233246, -0.06048167, ...,  0.00498784,\n",
       "                             -0.09345889, -0.03671709],\n",
       "                            [-0.05751621, -0.06559609,  0.05711509, ..., -0.08646408,\n",
       "                             -0.01307047,  0.04855187],\n",
       "                            [-0.01327409, -0.00596458,  0.20792015, ...,  0.08888407,\n",
       "                              0.0712983 , -0.01276477]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "             ln_1: {\n",
       "                 bias: Array([-0.02565054,  0.03710667,  0.04284472, ..., -0.01352755,\n",
       "                         0.03547335,  0.10461047], dtype=float32),\n",
       "                 scale: Array([0.6999537 , 0.6973407 , 0.6782628 , ..., 0.67372465, 0.71513313,\n",
       "                        0.5958037 ], dtype=float32),\n",
       "             },\n",
       "             ln_2: {\n",
       "                 bias: Array([-0.02524331,  0.03848087,  0.00815174, ..., -0.00091769,\n",
       "                        -0.0347187 ,  0.01413824], dtype=float32),\n",
       "                 scale: Array([0.720677  , 0.7147764 , 0.73635095, ..., 0.6930876 , 0.6883207 ,\n",
       "                        0.69933707], dtype=float32),\n",
       "             },\n",
       "             mlp: {\n",
       "                 c_fc: {\n",
       "                     bias: Array([-0.0209803 ,  0.0056089 , -0.06438298, ..., -0.03993744,\n",
       "                            -0.02354826, -0.04569088], dtype=float32),\n",
       "                     kernel: Array([[ 0.01208657, -0.03630368, -0.06595644, ...,  0.03241472,\n",
       "                             -0.04705668, -0.07289916],\n",
       "                            [-0.0467273 ,  0.06553193,  0.05594027, ..., -0.02006175,\n",
       "                             -0.01814622,  0.02059317],\n",
       "                            [ 0.02341745, -0.05758198,  0.00348262, ...,  0.05763493,\n",
       "                             -0.01350194,  0.01931915],\n",
       "                            ...,\n",
       "                            [-0.04206286, -0.06037206, -0.04510919, ...,  0.02883088,\n",
       "                              0.0410428 ,  0.07049103],\n",
       "                            [ 0.03370439, -0.00254738,  0.0139206 , ...,  0.0030047 ,\n",
       "                              0.0670585 ,  0.00390613],\n",
       "                            [ 0.02782555,  0.06851137,  0.02699052, ..., -0.02313562,\n",
       "                              0.04433988,  0.05926879]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([ 0.04895862, -0.04614296, -0.01100057, ...,  0.04160379,\n",
       "                             0.03887564, -0.07190683], dtype=float32),\n",
       "                     kernel: Array([[-0.06011198,  0.08267825, -0.05946245, ...,  0.06301598,\n",
       "                              0.01981795, -0.13698745],\n",
       "                            [-0.07160041,  0.03877124, -0.12817717, ...,  0.00064674,\n",
       "                             -0.08773091, -0.01933561],\n",
       "                            [ 0.03302591, -0.07777894, -0.03973036, ..., -0.01433645,\n",
       "                              0.04641065,  0.0543719 ],\n",
       "                            ...,\n",
       "                            [-0.03565973,  0.05407067,  0.03819638, ...,  0.13422792,\n",
       "                             -0.01921384,  0.03342029],\n",
       "                            [-0.08496131,  0.08259168,  0.04657582, ..., -0.05674708,\n",
       "                              0.03407416,  0.06477432],\n",
       "                            [ 0.04521272, -0.09748528,  0.02166946, ..., -0.01812674,\n",
       "                              0.0925191 ,  0.01862499]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "         },\n",
       "         32: {\n",
       "             attn: {\n",
       "                 c_attn: {\n",
       "                     bias: Array([-0.03307068,  0.02606189,  0.09285385, ...,  0.03946564,\n",
       "                            -0.0643611 ,  0.00805469], dtype=float32),\n",
       "                     kernel: Array([[-0.00145975,  0.02412769,  0.02215521, ...,  0.01222602,\n",
       "                             -0.00986082,  0.01830527],\n",
       "                            [ 0.01262663,  0.03751126,  0.06690375, ..., -0.06209905,\n",
       "                              0.01113719, -0.05953255],\n",
       "                            [ 0.0359463 ,  0.0263348 , -0.07519151, ..., -0.03475087,\n",
       "                             -0.01690562, -0.09095476],\n",
       "                            ...,\n",
       "                            [-0.06297299,  0.06113301, -0.04374489, ..., -0.01082396,\n",
       "                              0.04442675,  0.02084813],\n",
       "                            [-0.05077701, -0.02262486, -0.04232273, ..., -0.00640277,\n",
       "                             -0.04997208,  0.05727479],\n",
       "                            [-0.00776452,  0.04565614,  0.02647939, ..., -0.02973026,\n",
       "                              0.06761345,  0.04771074]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([-0.00968172,  0.00038596, -0.02517687, ...,  0.01785674,\n",
       "                            -0.0418346 , -0.07013009], dtype=float32),\n",
       "                     kernel: Array([[-0.03494884,  0.03993143, -0.03080796, ..., -0.07365181,\n",
       "                              0.05982768,  0.11761339],\n",
       "                            [-0.01954028,  0.0439932 , -0.02145702, ..., -0.05158426,\n",
       "                              0.03631309, -0.0208006 ],\n",
       "                            [-0.10927285, -0.02157442,  0.06608862, ..., -0.02277267,\n",
       "                              0.06054484, -0.05616161],\n",
       "                            ...,\n",
       "                            [ 0.00240588, -0.0288355 , -0.06209933, ...,  0.1074271 ,\n",
       "                              0.12223399, -0.00280291],\n",
       "                            [-0.08989687,  0.03885918, -0.04199269, ...,  0.02480021,\n",
       "                              0.02421033,  0.02862101],\n",
       "                            [ 0.00836129, -0.03494814, -0.03726269, ...,  0.03247691,\n",
       "                              0.01970705, -0.05202568]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "             ln_1: {\n",
       "                 bias: Array([-0.03937627,  0.01736795,  0.07128249, ..., -0.00525955,\n",
       "                         0.02922151,  0.15695216], dtype=float32),\n",
       "                 scale: Array([0.7393604 , 0.7243636 , 0.71846795, ..., 0.72165096, 0.73436385,\n",
       "                        0.6113669 ], dtype=float32),\n",
       "             },\n",
       "             ln_2: {\n",
       "                 bias: Array([-0.01913837,  0.03769106,  0.03873805, ...,  0.01682572,\n",
       "                        -0.0167734 ,  0.06779825], dtype=float32),\n",
       "                 scale: Array([0.7729825 , 0.74042827, 0.7619212 , ..., 0.73205596, 0.71675694,\n",
       "                        0.7172146 ], dtype=float32),\n",
       "             },\n",
       "             mlp: {\n",
       "                 c_fc: {\n",
       "                     bias: Array([-0.05157207, -0.01632785, -0.05868624, ..., -0.03159672,\n",
       "                            -0.03277741, -0.01612134], dtype=float32),\n",
       "                     kernel: Array([[-0.02650844,  0.00910586, -0.03654279, ..., -0.03824143,\n",
       "                              0.03938806,  0.05871569],\n",
       "                            [-0.01369379, -0.11950094, -0.01916006, ...,  0.09913996,\n",
       "                              0.02192364,  0.02260602],\n",
       "                            [ 0.11770221,  0.03795262, -0.01798439, ...,  0.02181018,\n",
       "                              0.02267023, -0.0348535 ],\n",
       "                            ...,\n",
       "                            [-0.103702  ,  0.02396538, -0.06423165, ..., -0.03573612,\n",
       "                             -0.00450901, -0.04308296],\n",
       "                            [ 0.02092757, -0.04663444,  0.08477122, ..., -0.05400546,\n",
       "                             -0.01303286,  0.00593208],\n",
       "                            [ 0.01000099, -0.03624744, -0.00462268, ..., -0.03262231,\n",
       "                             -0.04854048,  0.003518  ]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([ 0.01268117, -0.02152368, -0.02365021, ...,  0.04702277,\n",
       "                             0.06652512, -0.09389737], dtype=float32),\n",
       "                     kernel: Array([[ 0.04716757, -0.00138097,  0.09986909, ...,  0.07634432,\n",
       "                              0.04002401, -0.14681305],\n",
       "                            [ 0.0282362 ,  0.11445709, -0.00056564, ..., -0.09340932,\n",
       "                              0.07322723,  0.04385628],\n",
       "                            [-0.04316388,  0.06103801,  0.01697063, ..., -0.04121768,\n",
       "                             -0.00583862, -0.00817998],\n",
       "                            ...,\n",
       "                            [-0.10662364, -0.07482271,  0.00437223, ..., -0.06212508,\n",
       "                              0.02689055,  0.00293528],\n",
       "                            [ 0.01092316,  0.06512947, -0.04861206, ...,  0.15936983,\n",
       "                              0.06836116,  0.03615707],\n",
       "                            [-0.00351674, -0.00555157,  0.00805685, ..., -0.05418671,\n",
       "                             -0.00566504, -0.04916792]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "         },\n",
       "         33: {\n",
       "             attn: {\n",
       "                 c_attn: {\n",
       "                     bias: Array([ 0.08019159, -0.05550566, -0.08294931, ..., -0.00505162,\n",
       "                             0.04751274,  0.00016638], dtype=float32),\n",
       "                     kernel: Array([[-9.09981579e-02, -2.38397252e-02,  2.79141273e-02, ...,\n",
       "                              1.03753977e-01, -3.26105244e-02,  1.90077983e-02],\n",
       "                            [-2.19855504e-03, -2.32820753e-02,  4.97876992e-03, ...,\n",
       "                              9.76230585e-05, -5.71397990e-02,  1.26305353e-02],\n",
       "                            [-2.95837433e-03,  5.63627109e-03,  2.75246855e-02, ...,\n",
       "                              7.32750073e-02,  2.34715734e-02,  4.03528176e-02],\n",
       "                            ...,\n",
       "                            [-4.03120257e-02, -5.54936752e-02,  1.43254185e-02, ...,\n",
       "                              6.15056157e-02,  7.46457418e-03, -1.23202158e-02],\n",
       "                            [-8.94789025e-02, -1.00225061e-01,  4.13575359e-02, ...,\n",
       "                             -3.41857318e-03,  6.99253157e-02,  4.20725308e-02],\n",
       "                            [-5.51584810e-02, -8.42775684e-03, -2.38568429e-02, ...,\n",
       "                             -4.55375426e-02,  8.24421868e-02, -2.09721196e-02]],      dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([-0.00255889, -0.02231706, -0.03688794, ..., -0.01279729,\n",
       "                            -0.01456975, -0.09353462], dtype=float32),\n",
       "                     kernel: Array([[-0.02389243, -0.03326515,  0.02099557, ..., -0.08703519,\n",
       "                             -0.00510575,  0.03027746],\n",
       "                            [-0.01111967,  0.07276513,  0.03634189, ...,  0.05876042,\n",
       "                             -0.06106663,  0.07723432],\n",
       "                            [-0.003543  , -0.01092419,  0.00635857, ..., -0.04019722,\n",
       "                             -0.0104675 ,  0.01801922],\n",
       "                            ...,\n",
       "                            [ 0.09516279, -0.02976481, -0.0001094 , ...,  0.06123344,\n",
       "                             -0.01636778, -0.07010609],\n",
       "                            [-0.0015726 , -0.07134487,  0.05885371, ...,  0.00114775,\n",
       "                             -0.0107918 ,  0.08548597],\n",
       "                            [ 0.03654855,  0.07481954,  0.0259254 , ..., -0.03114425,\n",
       "                             -0.00414623,  0.10213037]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "             ln_1: {\n",
       "                 bias: Array([ 0.0065318 ,  0.0621434 ,  0.05607066, ..., -0.00405358,\n",
       "                         0.06332005,  0.24486126], dtype=float32),\n",
       "                 scale: Array([0.7445609 , 0.7314716 , 0.71594286, ..., 0.72006756, 0.7365728 ,\n",
       "                        0.5842943 ], dtype=float32),\n",
       "             },\n",
       "             ln_2: {\n",
       "                 bias: Array([-0.03170985,  0.03891659,  0.06727333, ..., -0.00807863,\n",
       "                        -0.03187126,  0.07273062], dtype=float32),\n",
       "                 scale: Array([0.7643458 , 0.76709527, 0.7828115 , ..., 0.7519485 , 0.7728321 ,\n",
       "                        0.7849268 ], dtype=float32),\n",
       "             },\n",
       "             mlp: {\n",
       "                 c_fc: {\n",
       "                     bias: Array([-0.07448751,  0.00502267, -0.02223524, ..., -0.02232803,\n",
       "                            -0.03565744, -0.00186472], dtype=float32),\n",
       "                     kernel: Array([[-0.05907745, -0.00313817,  0.03776214, ...,  0.01648805,\n",
       "                             -0.07643111, -0.04185036],\n",
       "                            [-0.02254804,  0.02869022, -0.01478436, ...,  0.06543326,\n",
       "                             -0.03872447,  0.036624  ],\n",
       "                            [ 0.02325147,  0.0023306 ,  0.02243963, ...,  0.0364932 ,\n",
       "                              0.09830233,  0.07103858],\n",
       "                            ...,\n",
       "                            [ 0.00481702, -0.08770789, -0.05370535, ..., -0.01987054,\n",
       "                             -0.06828987,  0.02705899],\n",
       "                            [ 0.07106697, -0.03375266,  0.00268838, ...,  0.02922538,\n",
       "                              0.07970886,  0.02654402],\n",
       "                            [-0.04054485, -0.01039694, -0.04406393, ...,  0.01583953,\n",
       "                              0.03771379, -0.00951228]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([ 0.03794361, -0.01317359,  0.00590369, ...,  0.00055473,\n",
       "                             0.0659118 , -0.09589231], dtype=float32),\n",
       "                     kernel: Array([[ 0.07746609, -0.07838836,  0.01663261, ...,  0.02980066,\n",
       "                              0.0763176 ,  0.03306967],\n",
       "                            [ 0.01066165, -0.0684946 ,  0.02256688, ..., -0.16303696,\n",
       "                             -0.02614482,  0.03776973],\n",
       "                            [ 0.07303086, -0.02430726,  0.05700187, ..., -0.01143149,\n",
       "                              0.04525625,  0.06422871],\n",
       "                            ...,\n",
       "                            [-0.06418292, -0.04343323, -0.0177804 , ...,  0.16900586,\n",
       "                             -0.05047669,  0.03035475],\n",
       "                            [-0.10506169, -0.01111558, -0.0187216 , ..., -0.0581541 ,\n",
       "                             -0.00037782, -0.07751212],\n",
       "                            [ 0.01498937,  0.01224207,  0.07743364, ..., -0.1387174 ,\n",
       "                             -0.05958399, -0.00688512]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "         },\n",
       "         34: {\n",
       "             attn: {\n",
       "                 c_attn: {\n",
       "                     bias: Array([ 0.04653252,  0.11117557,  0.1465371 , ..., -0.03141013,\n",
       "                             0.04534077, -0.01573305], dtype=float32),\n",
       "                     kernel: Array([[ 0.0577656 , -0.04904472,  0.00396245, ...,  0.0209093 ,\n",
       "                             -0.01358769,  0.06634523],\n",
       "                            [-0.04765114,  0.07839862, -0.08519921, ...,  0.01736996,\n",
       "                              0.05157791,  0.02647349],\n",
       "                            [-0.0719003 , -0.05033021, -0.05188488, ..., -0.02907584,\n",
       "                              0.00708278,  0.07059519],\n",
       "                            ...,\n",
       "                            [ 0.07268663, -0.00641885, -0.00231561, ...,  0.00497882,\n",
       "                              0.00518141,  0.06267006],\n",
       "                            [-0.06491241,  0.01944273, -0.02942328, ..., -0.04541402,\n",
       "                             -0.01917718, -0.08103538],\n",
       "                            [ 0.06098956,  0.05167803, -0.07135229, ...,  0.02421294,\n",
       "                             -0.00247891,  0.03719468]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([ 0.02752047, -0.00997857, -0.01121363, ...,  0.004429  ,\n",
       "                             0.03572601, -0.13616571], dtype=float32),\n",
       "                     kernel: Array([[-0.01487441,  0.04225869,  0.02756711, ...,  0.0928435 ,\n",
       "                              0.02409357, -0.06637318],\n",
       "                            [-0.03032298,  0.11849419,  0.0345354 , ..., -0.05981131,\n",
       "                             -0.04772716, -0.04658309],\n",
       "                            [ 0.06687593, -0.02962398,  0.07125906, ...,  0.05176169,\n",
       "                              0.01561277, -0.04190934],\n",
       "                            ...,\n",
       "                            [-0.09689871,  0.09437846, -0.07354639, ..., -0.05033918,\n",
       "                             -0.02777584, -0.03760841],\n",
       "                            [-0.0075871 ,  0.02339577, -0.04993774, ..., -0.02829297,\n",
       "                              0.01387835,  0.03799865],\n",
       "                            [-0.05994433, -0.03261816, -0.02032659, ...,  0.04698608,\n",
       "                             -0.03483654,  0.00039377]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "             ln_1: {\n",
       "                 bias: Array([-0.00490377,  0.08854575,  0.10918922, ...,  0.01566559,\n",
       "                         0.02741098,  0.24888472], dtype=float32),\n",
       "                 scale: Array([0.824154  , 0.7676502 , 0.73273474, ..., 0.7676916 , 0.7833274 ,\n",
       "                        0.6200537 ], dtype=float32),\n",
       "             },\n",
       "             ln_2: {\n",
       "                 bias: Array([-0.0335305 ,  0.05199316,  0.07366975, ..., -0.02146054,\n",
       "                         0.01295749,  0.05832179], dtype=float32),\n",
       "                 scale: Array([0.8023742 , 0.79813755, 0.81366843, ..., 0.78184885, 0.801361  ,\n",
       "                        0.8304475 ], dtype=float32),\n",
       "             },\n",
       "             mlp: {\n",
       "                 c_fc: {\n",
       "                     bias: Array([ 0.0613433 , -0.06424464, -0.04960312, ...,  0.07853626,\n",
       "                            -0.02784527,  0.00840594], dtype=float32),\n",
       "                     kernel: Array([[-0.06709976,  0.08567328, -0.00690073, ..., -0.00289524,\n",
       "                              0.00073432, -0.05853608],\n",
       "                            [ 0.00205029, -0.01678838, -0.05873349, ..., -0.07712848,\n",
       "                              0.01073796, -0.01858617],\n",
       "                            [ 0.09078659,  0.05454991, -0.08571021, ..., -0.03222253,\n",
       "                              0.08378122, -0.0234529 ],\n",
       "                            ...,\n",
       "                            [ 0.06370633,  0.0367955 ,  0.00842804, ...,  0.06172397,\n",
       "                              0.04715695,  0.09943502],\n",
       "                            [ 0.00732956,  0.02306081,  0.05105698, ..., -0.01126649,\n",
       "                             -0.01031718,  0.01758654],\n",
       "                            [ 0.04211526,  0.04325444,  0.03819659, ...,  0.06326035,\n",
       "                              0.11477079,  0.04402977]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([ 0.00205509,  0.0449319 ,  0.05404347, ...,  0.04565461,\n",
       "                             0.07448976, -0.06576829], dtype=float32),\n",
       "                     kernel: Array([[ 0.01819025,  0.00414369,  0.01371908, ..., -0.03385716,\n",
       "                             -0.03338538,  0.00088588],\n",
       "                            [ 0.04275306,  0.0114273 ,  0.08471283, ..., -0.04082907,\n",
       "                             -0.10733314,  0.18153532],\n",
       "                            [ 0.12345343, -0.06369196, -0.08069129, ..., -0.05238955,\n",
       "                             -0.00322452, -0.10305966],\n",
       "                            ...,\n",
       "                            [ 0.04864234,  0.00906529,  0.03676454, ..., -0.08923694,\n",
       "                             -0.02375241, -0.06153123],\n",
       "                            [-0.02554117, -0.0620223 ,  0.05377237, ..., -0.05534874,\n",
       "                             -0.06233791, -0.10992616],\n",
       "                            [-0.02501219,  0.02429077, -0.03077015, ..., -0.10313419,\n",
       "                             -0.00133802,  0.10285872]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "         },\n",
       "         35: {\n",
       "             attn: {\n",
       "                 c_attn: {\n",
       "                     bias: Array([-0.01823208, -0.00705104,  0.04333788, ..., -0.0226221 ,\n",
       "                            -0.02781406, -0.04043519], dtype=float32),\n",
       "                     kernel: Array([[-0.01646764,  0.03892892, -0.03283568, ..., -0.03309586,\n",
       "                              0.02790978, -0.05996922],\n",
       "                            [-0.02040652,  0.02906768, -0.04357047, ...,  0.00980339,\n",
       "                             -0.00569449, -0.04386063],\n",
       "                            [-0.02707166,  0.06915474,  0.04990809, ..., -0.02942114,\n",
       "                              0.01490593, -0.02451561],\n",
       "                            ...,\n",
       "                            [ 0.01579889,  0.00106831,  0.09546958, ...,  0.05471499,\n",
       "                              0.07629736,  0.02937812],\n",
       "                            [-0.05979258, -0.0067527 , -0.0649633 , ..., -0.00788496,\n",
       "                              0.02308321,  0.01674038],\n",
       "                            [-0.03050321,  0.10465658, -0.05571888, ..., -0.00265523,\n",
       "                             -0.00217973, -0.02356367]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([-0.05256285,  0.0129461 ,  0.02626646, ..., -0.02648602,\n",
       "                             0.05540956, -0.05084242], dtype=float32),\n",
       "                     kernel: Array([[ 8.9390695e-02,  1.2735709e-02,  6.4483196e-02, ...,\n",
       "                              1.7487863e-02,  1.8322594e-02,  2.2817943e-03],\n",
       "                            [ 2.8400191e-03, -1.8615700e-02, -2.8300904e-02, ...,\n",
       "                              5.0938658e-02,  5.6345537e-02,  4.5294531e-02],\n",
       "                            [ 5.2296497e-02,  5.8221016e-03, -3.2770166e-03, ...,\n",
       "                              4.5368526e-02,  1.7353324e-03, -7.1588499e-03],\n",
       "                            ...,\n",
       "                            [-4.5529348e-03, -2.3827283e-02, -1.4360434e-02, ...,\n",
       "                              5.1633727e-02, -8.8003020e-05, -2.2621753e-03],\n",
       "                            [ 2.6329523e-02,  8.5401917e-03,  3.1600583e-02, ...,\n",
       "                              4.2993143e-02, -3.4025639e-02, -5.1993851e-02],\n",
       "                            [-6.4225301e-02, -2.7574448e-02, -2.7861346e-02, ...,\n",
       "                              1.0828513e-02,  4.0624649e-03, -6.9130041e-02]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "             ln_1: {\n",
       "                 bias: Array([ 0.06001949,  0.0820421 ,  0.10388365, ..., -0.02005779,\n",
       "                         0.0866721 ,  0.01320362], dtype=float32),\n",
       "                 scale: Array([0.89640445, 0.76618737, 0.73279095, ..., 0.7406818 , 0.80267304,\n",
       "                        0.6120113 ], dtype=float32),\n",
       "             },\n",
       "             ln_2: {\n",
       "                 bias: Array([-0.01921526,  0.02777417,  0.03965041, ...,  0.00617342,\n",
       "                         0.03711232,  0.02046289], dtype=float32),\n",
       "                 scale: Array([0.78589815, 0.8103485 , 0.8251189 , ..., 0.77700436, 0.82788396,\n",
       "                        0.8162474 ], dtype=float32),\n",
       "             },\n",
       "             mlp: {\n",
       "                 c_fc: {\n",
       "                     bias: Array([ 0.03183742,  0.0063898 , -0.01041382, ...,  0.00444355,\n",
       "                            -0.01485589, -0.08979724], dtype=float32),\n",
       "                     kernel: Array([[-3.15435454e-02, -8.65822658e-02, -6.53442461e-03, ...,\n",
       "                             -2.39895862e-02, -4.97939363e-02, -4.24929373e-02],\n",
       "                            [ 7.16458187e-02,  1.04952462e-01,  4.65278700e-02, ...,\n",
       "                              3.28582600e-02,  5.98572718e-04,  3.42269763e-02],\n",
       "                            [ 1.27285972e-01, -4.73787524e-02, -9.41602699e-03, ...,\n",
       "                              1.13633275e-02,  1.17350714e-02,  2.77635138e-02],\n",
       "                            ...,\n",
       "                            [ 3.95873524e-02,  6.44777715e-02, -2.47738305e-02, ...,\n",
       "                              8.40405375e-02,  2.31328867e-02, -5.88666722e-02],\n",
       "                            [-7.65519589e-02, -6.59621845e-04, -3.47744040e-02, ...,\n",
       "                              5.50189316e-02,  2.79350113e-02,  9.81730968e-03],\n",
       "                            [ 4.79330483e-05,  4.94122729e-02,  8.12866315e-02, ...,\n",
       "                              2.88493279e-02,  2.18834188e-02,  7.92060196e-02]],      dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([-0.07014966,  0.05316421,  0.06517939, ..., -0.06303681,\n",
       "                             0.00690162,  0.0243021 ], dtype=float32),\n",
       "                     kernel: Array([[-0.03113414, -0.0223851 , -0.0325468 , ..., -0.02999196,\n",
       "                             -0.03268393, -0.04977654],\n",
       "                            [ 0.04327399,  0.00341201,  0.01518328, ..., -0.02756528,\n",
       "                             -0.04118546, -0.01646632],\n",
       "                            [ 0.01862692, -0.02589181, -0.00795203, ..., -0.01365562,\n",
       "                              0.05050663,  0.05256918],\n",
       "                            ...,\n",
       "                            [-0.05056141,  0.02222843,  0.01891076, ..., -0.11752863,\n",
       "                              0.01681285, -0.02619553],\n",
       "                            [ 0.0258526 ,  0.00723438, -0.1434966 , ...,  0.0513082 ,\n",
       "                              0.0413675 , -0.07115071],\n",
       "                            [-0.22459218,  0.13616686, -0.05702484, ..., -0.06848068,\n",
       "                              0.0436574 , -0.1583476 ]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "         },\n",
       "         4: {\n",
       "             attn: {\n",
       "                 c_attn: {\n",
       "                     bias: Array([-0.15584368, -0.03115769,  0.0076082 , ...,  0.011075  ,\n",
       "                            -0.0186197 , -0.01646918], dtype=float32),\n",
       "                     kernel: Array([[ 0.02009324,  0.01788855,  0.04853028, ...,  0.02108964,\n",
       "                              0.0275238 , -0.02091816],\n",
       "                            [ 0.12557538, -0.03672549, -0.03193895, ...,  0.02729534,\n",
       "                              0.04001398,  0.01661992],\n",
       "                            [-0.01436681,  0.09452249,  0.03963681, ..., -0.01370146,\n",
       "                             -0.00546793, -0.052413  ],\n",
       "                            ...,\n",
       "                            [ 0.10439191,  0.03850477,  0.0580476 , ...,  0.00489299,\n",
       "                              0.0139361 ,  0.02608674],\n",
       "                            [-0.05118633,  0.01768917,  0.02584602, ...,  0.05044579,\n",
       "                              0.00087429,  0.00074154],\n",
       "                            [-0.00842119, -0.03331684,  0.04225206, ...,  0.00560888,\n",
       "                             -0.05276818, -0.00738007]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([-0.06517354, -0.01272765, -0.0406375 , ...,  0.03072599,\n",
       "                             0.04463629,  0.02829543], dtype=float32),\n",
       "                     kernel: Array([[ 0.04383808, -0.00373392,  0.05120749, ...,  0.04138723,\n",
       "                              0.03937856, -0.03335271],\n",
       "                            [-0.05093312, -0.03645835, -0.02259934, ..., -0.03041131,\n",
       "                             -0.01493014,  0.00067221],\n",
       "                            [ 0.03903314,  0.03628195,  0.03631692, ..., -0.02499551,\n",
       "                             -0.05348953, -0.02771871],\n",
       "                            ...,\n",
       "                            [-0.03604553,  0.01762424,  0.07234077, ...,  0.0217192 ,\n",
       "                             -0.13344395, -0.03401301],\n",
       "                            [-0.04417718, -0.05754839,  0.01973586, ...,  0.00794533,\n",
       "                             -0.03911776,  0.03903804],\n",
       "                            [-0.0220811 ,  0.06112589,  0.02617789, ..., -0.05551509,\n",
       "                              0.0067581 , -0.01834612]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "             ln_1: {\n",
       "                 bias: Array([-0.07091203, -0.03285463, -0.00678125, ..., -0.12365352,\n",
       "                        -0.05221586, -0.04389175], dtype=float32),\n",
       "                 scale: Array([0.4555789 , 0.43769747, 0.44311044, ..., 0.41739604, 0.44294515,\n",
       "                        0.36960799], dtype=float32),\n",
       "             },\n",
       "             ln_2: {\n",
       "                 bias: Array([-0.04312595, -0.04667905,  0.01050436, ...,  0.04560779,\n",
       "                         0.02702828,  0.02667057], dtype=float32),\n",
       "                 scale: Array([0.55275404, 0.5938398 , 0.58006996, ..., 0.5560262 , 0.55249226,\n",
       "                        0.5664071 ], dtype=float32),\n",
       "             },\n",
       "             mlp: {\n",
       "                 c_fc: {\n",
       "                     bias: Array([ 0.00447719, -0.05640866, -0.04195549, ..., -0.01211083,\n",
       "                            -0.04948987, -0.03319852], dtype=float32),\n",
       "                     kernel: Array([[-3.97660956e-02, -2.70968508e-02, -1.99761055e-02, ...,\n",
       "                              4.85571548e-02, -3.42556275e-02, -2.05111522e-02],\n",
       "                            [ 1.09043519e-03, -2.59902403e-02, -4.44905013e-02, ...,\n",
       "                             -2.53267772e-05,  8.08596388e-02,  2.91905161e-02],\n",
       "                            [ 1.21668205e-02, -4.22107056e-02, -1.65849235e-02, ...,\n",
       "                              3.73340100e-02,  2.47183908e-02,  1.91598549e-03],\n",
       "                            ...,\n",
       "                            [ 1.11442776e-02,  4.92828526e-02, -4.04728949e-02, ...,\n",
       "                             -7.81536028e-02,  4.06562760e-02, -6.78381249e-02],\n",
       "                            [ 2.10903622e-02,  3.22190970e-02, -3.77858579e-02, ...,\n",
       "                              3.89352418e-03, -4.76702489e-02,  1.78155710e-03],\n",
       "                            [-5.87442555e-02,  7.47891190e-03, -4.39381301e-02, ...,\n",
       "                             -1.22242598e-02, -5.49349189e-02, -4.29034904e-02]],      dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([-0.0449779 , -0.0704695 , -0.01426516, ...,  0.01757827,\n",
       "                             0.03152857,  0.01374066], dtype=float32),\n",
       "                     kernel: Array([[-4.6833324e-05, -4.9676370e-02, -3.1957038e-02, ...,\n",
       "                             -5.8701518e-03, -3.8436290e-02,  3.4740329e-02],\n",
       "                            [-1.9414758e-02, -1.9887013e-02, -4.8532605e-02, ...,\n",
       "                              7.6311827e-02,  4.2039994e-02,  5.8949705e-02],\n",
       "                            [ 3.9324220e-02,  5.6841969e-02, -1.6164023e-02, ...,\n",
       "                             -9.4758961e-03,  3.6896862e-02, -2.4063326e-03],\n",
       "                            ...,\n",
       "                            [ 3.0959649e-02, -3.3497315e-02, -4.4253417e-03, ...,\n",
       "                              5.0677624e-02, -1.4082119e-02,  6.6556767e-02],\n",
       "                            [-2.2975773e-02,  1.0904163e-02,  1.0225729e-02, ...,\n",
       "                              1.9130018e-03, -1.2732424e-01,  1.3314171e-02],\n",
       "                            [-1.7534704e-04, -6.9117576e-02,  8.7280255e-03, ...,\n",
       "                             -7.5024121e-02, -2.5385976e-02,  2.5669618e-02]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "         },\n",
       "         5: {\n",
       "             attn: {\n",
       "                 c_attn: {\n",
       "                     bias: Array([-0.05991891,  0.09209378,  0.18313739, ..., -0.02843136,\n",
       "                            -0.02186791, -0.02741874], dtype=float32),\n",
       "                     kernel: Array([[ 0.07986934,  0.03417845,  0.03368404, ...,  0.03741684,\n",
       "                             -0.01829761,  0.00612948],\n",
       "                            [ 0.00287583,  0.05243669, -0.03166894, ...,  0.02166171,\n",
       "                              0.02133459,  0.0128652 ],\n",
       "                            [-0.08285053, -0.00325441,  0.0673096 , ..., -0.02398112,\n",
       "                             -0.00383257, -0.00023507],\n",
       "                            ...,\n",
       "                            [ 0.10252706, -0.03313284,  0.03599275, ...,  0.02796862,\n",
       "                             -0.00296252,  0.01519919],\n",
       "                            [ 0.05401446,  0.06364493, -0.01721767, ..., -0.01102749,\n",
       "                             -0.04338709,  0.01824662],\n",
       "                            [-0.03503622, -0.01310909,  0.02556717, ..., -0.00591368,\n",
       "                             -0.02304456, -0.06491799]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([-0.10667528, -0.02087569, -0.13459854, ..., -0.02583467,\n",
       "                            -0.04365133, -0.037639  ], dtype=float32),\n",
       "                     kernel: Array([[-0.0454527 , -0.03756623, -0.00996125, ...,  0.01774191,\n",
       "                              0.05915402, -0.01991046],\n",
       "                            [-0.0773588 ,  0.01184169, -0.03342244, ..., -0.01952463,\n",
       "                              0.01865123, -0.00042777],\n",
       "                            [-0.04218002,  0.08049747,  0.03447296, ..., -0.05698434,\n",
       "                             -0.01487553,  0.03443108],\n",
       "                            ...,\n",
       "                            [-0.00761743, -0.00448893, -0.01174557, ..., -0.02331702,\n",
       "                              0.02478284, -0.03442949],\n",
       "                            [ 0.02706977,  0.02453105,  0.02901128, ..., -0.00681713,\n",
       "                             -0.04510468, -0.03344509],\n",
       "                            [ 0.04749607,  0.01590694, -0.01879269, ...,  0.0284119 ,\n",
       "                             -0.01874462,  0.02722923]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "             ln_1: {\n",
       "                 bias: Array([-0.05507437, -0.00705871, -0.01307785, ..., -0.10780647,\n",
       "                        -0.03426628, -0.02278687], dtype=float32),\n",
       "                 scale: Array([0.4639785 , 0.4692464 , 0.46269813, ..., 0.43467554, 0.46700343,\n",
       "                        0.4191973 ], dtype=float32),\n",
       "             },\n",
       "             ln_2: {\n",
       "                 bias: Array([-0.05329974, -0.04183547,  0.0092372 , ...,  0.05273798,\n",
       "                         0.02077561,  0.01371794], dtype=float32),\n",
       "                 scale: Array([0.5585169 , 0.5990462 , 0.5952116 , ..., 0.55428344, 0.5463971 ,\n",
       "                        0.5719195 ], dtype=float32),\n",
       "             },\n",
       "             mlp: {\n",
       "                 c_fc: {\n",
       "                     bias: Array([-0.05083077, -0.05065287, -0.04592918, ..., -0.04889327,\n",
       "                            -0.04490309, -0.05157655], dtype=float32),\n",
       "                     kernel: Array([[ 0.02670166,  0.04627665, -0.05425115, ...,  0.03797359,\n",
       "                             -0.07425579, -0.09114971],\n",
       "                            [-0.03560339, -0.06373557, -0.02213182, ...,  0.07049659,\n",
       "                              0.02422452,  0.02501049],\n",
       "                            [-0.00803817, -0.0010536 ,  0.04017933, ..., -0.05111392,\n",
       "                             -0.06640511,  0.02623408],\n",
       "                            ...,\n",
       "                            [-0.03743941,  0.00051922, -0.09242121, ..., -0.00707373,\n",
       "                             -0.03042156, -0.01609664],\n",
       "                            [ 0.05673642,  0.00981409,  0.00192433, ..., -0.03698526,\n",
       "                              0.03937789,  0.05378222],\n",
       "                            [ 0.06357799, -0.00513491, -0.00210245, ...,  0.02632932,\n",
       "                              0.04906955, -0.02882431]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([-0.01661152, -0.05858715,  0.01045536, ...,  0.02563945,\n",
       "                             0.01620406, -0.02168833], dtype=float32),\n",
       "                     kernel: Array([[-4.0028682e-03, -5.0617494e-02, -2.6171872e-02, ...,\n",
       "                              6.7084553e-03,  2.0793317e-02, -4.8651166e-02],\n",
       "                            [ 1.3657477e-02, -6.0725633e-02, -1.2680143e-02, ...,\n",
       "                             -5.1260579e-02, -1.1487183e-04,  1.4487465e-02],\n",
       "                            [-4.3669339e-02,  6.0532458e-02, -1.4673164e-02, ...,\n",
       "                              1.5826197e-02, -2.1518677e-02,  6.6853866e-02],\n",
       "                            ...,\n",
       "                            [ 2.2249396e-03,  7.0769854e-02, -1.1555984e-01, ...,\n",
       "                              5.8127087e-02,  1.4431236e-03, -2.3503767e-02],\n",
       "                            [-2.3793070e-02,  1.7198373e-02, -3.8885109e-02, ...,\n",
       "                              8.7083198e-02, -9.6804630e-03,  8.7320190e-03],\n",
       "                            [-1.7699972e-02,  3.4846492e-02,  1.9887082e-02, ...,\n",
       "                             -3.1234419e-02,  5.4690275e-02, -2.4760887e-04]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "         },\n",
       "         6: {\n",
       "             attn: {\n",
       "                 c_attn: {\n",
       "                     bias: Array([-2.1025190e-02, -6.5294638e-02,  1.3117197e-01, ...,\n",
       "                            -1.6084848e-02, -6.9789312e-05,  5.0536986e-03], dtype=float32),\n",
       "                     kernel: Array([[ 0.02510746,  0.05192959, -0.01834534, ..., -0.00847279,\n",
       "                              0.04676345,  0.03653533],\n",
       "                            [ 0.00314555, -0.04005811, -0.01853693, ..., -0.00305113,\n",
       "                             -0.00226277,  0.00964973],\n",
       "                            [ 0.02592668,  0.05327516, -0.07191984, ..., -0.02998094,\n",
       "                             -0.02008121,  0.01769364],\n",
       "                            ...,\n",
       "                            [-0.03466029,  0.08356169, -0.02044036, ...,  0.01290515,\n",
       "                             -0.01365946, -0.01493345],\n",
       "                            [ 0.00124076, -0.02024482,  0.00945589, ..., -0.0083211 ,\n",
       "                             -0.00654358,  0.03031241],\n",
       "                            [ 0.04404623,  0.02430957,  0.03043554, ..., -0.00242982,\n",
       "                              0.02136947, -0.00885458]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([-0.07144774, -0.06150627, -0.08048222, ...,  0.03141351,\n",
       "                            -0.00437286,  0.00287902], dtype=float32),\n",
       "                     kernel: Array([[-0.00358297, -0.01574394,  0.05565945, ...,  0.00327568,\n",
       "                              0.02875859,  0.01088226],\n",
       "                            [-0.00042688, -0.00217927, -0.04081167, ..., -0.03038251,\n",
       "                              0.06588871,  0.00956441],\n",
       "                            [ 0.03027754,  0.01728291, -0.04774858, ..., -0.05795099,\n",
       "                             -0.05814271,  0.00189964],\n",
       "                            ...,\n",
       "                            [-0.00438771,  0.03305306, -0.01894551, ...,  0.02405886,\n",
       "                              0.04236657,  0.02709883],\n",
       "                            [-0.06406033,  0.0229806 , -0.00232294, ..., -0.07962226,\n",
       "                              0.00797269, -0.00196071],\n",
       "                            [-0.01716177, -0.00685615, -0.04998295, ..., -0.00744182,\n",
       "                              0.00035705,  0.03945499]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "             ln_1: {\n",
       "                 bias: Array([-0.05949144, -0.0088863 ,  0.01455621, ..., -0.10991936,\n",
       "                        -0.06308698, -0.03669648], dtype=float32),\n",
       "                 scale: Array([0.49515593, 0.51040286, 0.5157133 , ..., 0.4554947 , 0.50683415,\n",
       "                        0.45022097], dtype=float32),\n",
       "             },\n",
       "             ln_2: {\n",
       "                 bias: Array([-0.02192825, -0.05296227,  0.04249497, ...,  0.0550698 ,\n",
       "                         0.00597038, -0.00265939], dtype=float32),\n",
       "                 scale: Array([0.54796636, 0.6117323 , 0.59223187, ..., 0.55264324, 0.55387026,\n",
       "                        0.56053007], dtype=float32),\n",
       "             },\n",
       "             mlp: {\n",
       "                 c_fc: {\n",
       "                     bias: Array([-0.0513222 , -0.02345812, -0.05572915, ..., -0.02963179,\n",
       "                             0.00274558, -0.04337298], dtype=float32),\n",
       "                     kernel: Array([[-0.00726941, -0.00887887,  0.00394151, ...,  0.07586908,\n",
       "                              0.01472049,  0.08576325],\n",
       "                            [-0.00203698,  0.00518325,  0.03943422, ..., -0.01674147,\n",
       "                             -0.0248828 ,  0.07707714],\n",
       "                            [ 0.00572958,  0.0486902 , -0.00702602, ...,  0.07913765,\n",
       "                             -0.02892132, -0.09423419],\n",
       "                            ...,\n",
       "                            [ 0.11529796, -0.00244201, -0.00578063, ...,  0.00709837,\n",
       "                              0.01860272, -0.00316936],\n",
       "                            [-0.00636364, -0.00976295,  0.00484541, ...,  0.0357224 ,\n",
       "                             -0.04371319, -0.04114801],\n",
       "                            [-0.06106075, -0.04287627, -0.02721791, ..., -0.04662515,\n",
       "                             -0.02025851, -0.02581596]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([-0.01532736, -0.04333122,  0.0204799 , ...,  0.02354101,\n",
       "                             0.0377645 ,  0.00480528], dtype=float32),\n",
       "                     kernel: Array([[ 0.05331428,  0.05947155,  0.03838469, ...,  0.1105593 ,\n",
       "                             -0.02681934, -0.08708123],\n",
       "                            [-0.05275977,  0.01297764, -0.03644893, ...,  0.05109471,\n",
       "                             -0.00421695, -0.03745387],\n",
       "                            [ 0.03072249,  0.03551528,  0.00044389, ...,  0.00248518,\n",
       "                             -0.01876887, -0.00960014],\n",
       "                            ...,\n",
       "                            [-0.02164341,  0.02171504, -0.05258961, ..., -0.02722054,\n",
       "                             -0.04121805,  0.0235965 ],\n",
       "                            [-0.00323043,  0.00422649, -0.00245179, ..., -0.00802896,\n",
       "                              0.00484087,  0.01622337],\n",
       "                            [-0.01052073, -0.01825089, -0.00150801, ...,  0.00436167,\n",
       "                              0.03270919, -0.04291553]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "         },\n",
       "         7: {\n",
       "             attn: {\n",
       "                 c_attn: {\n",
       "                     bias: Array([-0.1456209 , -0.10654703,  0.19125481, ...,  0.0134125 ,\n",
       "                            -0.00251369, -0.0352665 ], dtype=float32),\n",
       "                     kernel: Array([[ 0.02407897,  0.01130344, -0.10630146, ..., -0.00224684,\n",
       "                              0.00492945,  0.0209324 ],\n",
       "                            [ 0.02836968,  0.06873965,  0.06803875, ..., -0.03004183,\n",
       "                              0.00017003,  0.03439822],\n",
       "                            [-0.00133358,  0.03486673,  0.03850715, ...,  0.01382911,\n",
       "                             -0.05069152, -0.00693086],\n",
       "                            ...,\n",
       "                            [-0.00016605, -0.02443217,  0.01749589, ...,  0.00271833,\n",
       "                              0.00279771,  0.00027919],\n",
       "                            [-0.0171778 ,  0.00614266, -0.09528558, ..., -0.0299244 ,\n",
       "                             -0.01171676,  0.00259264],\n",
       "                            [ 0.02053555, -0.12813944,  0.05617889, ...,  0.00979239,\n",
       "                             -0.00742148,  0.05845666]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([-0.03437637, -0.08575556, -0.05495815, ...,  0.0455075 ,\n",
       "                             0.01371082,  0.02294296], dtype=float32),\n",
       "                     kernel: Array([[-0.05546406, -0.00800102,  0.07160492, ...,  0.01946951,\n",
       "                              0.01706916,  0.06660131],\n",
       "                            [-0.02347722, -0.03403772, -0.0097297 , ...,  0.01489229,\n",
       "                              0.06178812, -0.00999728],\n",
       "                            [ 0.03728683, -0.02924848,  0.02168028, ...,  0.04164321,\n",
       "                             -0.02121477, -0.00772833],\n",
       "                            ...,\n",
       "                            [ 0.06540916,  0.05253676,  0.01664068, ...,  0.03266221,\n",
       "                              0.00853084, -0.00163145],\n",
       "                            [-0.05249988,  0.00214228,  0.01404332, ..., -0.02876578,\n",
       "                             -0.00434248,  0.00507366],\n",
       "                            [-0.02917978, -0.00393457, -0.03626981, ...,  0.09339397,\n",
       "                              0.02362407, -0.05107974]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "             ln_1: {\n",
       "                 bias: Array([-0.05468993,  0.00384614,  0.01125048, ..., -0.10045572,\n",
       "                        -0.04907476, -0.0344546 ], dtype=float32),\n",
       "                 scale: Array([0.49838054, 0.5136357 , 0.5156126 , ..., 0.4716875 , 0.51739603,\n",
       "                        0.46055257], dtype=float32),\n",
       "             },\n",
       "             ln_2: {\n",
       "                 bias: Array([-0.03473024, -0.0609557 ,  0.03014146, ...,  0.06880938,\n",
       "                        -0.01111679, -0.01407559], dtype=float32),\n",
       "                 scale: Array([0.56374145, 0.6323684 , 0.6141106 , ..., 0.5810025 , 0.5865285 ,\n",
       "                        0.56570995], dtype=float32),\n",
       "             },\n",
       "             mlp: {\n",
       "                 c_fc: {\n",
       "                     bias: Array([-0.05328875, -0.04480583, -0.04806983, ..., -0.04308449,\n",
       "                            -0.04766614, -0.04274686], dtype=float32),\n",
       "                     kernel: Array([[-0.05199312,  0.1330179 , -0.00068449, ...,  0.01589899,\n",
       "                             -0.07292419, -0.01244664],\n",
       "                            [ 0.02362397,  0.07204516, -0.12373085, ...,  0.04920593,\n",
       "                             -0.01465448,  0.00490957],\n",
       "                            [ 0.01133643,  0.01127343,  0.00681238, ...,  0.02092207,\n",
       "                              0.04281255, -0.1076139 ],\n",
       "                            ...,\n",
       "                            [ 0.05498346,  0.06879666, -0.02584079, ..., -0.04518759,\n",
       "                              0.05043862,  0.00662697],\n",
       "                            [ 0.01457549, -0.06930564, -0.0439569 , ..., -0.08943457,\n",
       "                              0.01441242, -0.00040483],\n",
       "                            [ 0.01635533,  0.01797921, -0.01524868, ..., -0.02069951,\n",
       "                             -0.00250995,  0.00480486]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([-0.00532598, -0.03325615, -0.00032559, ...,  0.01668363,\n",
       "                             0.03364056,  0.00126889], dtype=float32),\n",
       "                     kernel: Array([[-0.03369693, -0.01732242, -0.03527671, ..., -0.04059463,\n",
       "                             -0.03135568, -0.02686165],\n",
       "                            [ 0.06877829,  0.05591284,  0.00179074, ..., -0.07280646,\n",
       "                             -0.02273418,  0.04696989],\n",
       "                            [-0.03041854,  0.09648414,  0.03292932, ...,  0.01325771,\n",
       "                              0.0412843 ,  0.02278946],\n",
       "                            ...,\n",
       "                            [-0.04123535,  0.00412633,  0.02639603, ...,  0.04715068,\n",
       "                              0.01050141, -0.02663278],\n",
       "                            [-0.03844079, -0.04056539,  0.11173131, ...,  0.03291775,\n",
       "                              0.01044532, -0.01178486],\n",
       "                            [-0.00973321,  0.02568605, -0.05401955, ...,  0.05085724,\n",
       "                              0.00078806,  0.06685871]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "         },\n",
       "         8: {\n",
       "             attn: {\n",
       "                 c_attn: {\n",
       "                     bias: Array([-0.01173885,  0.13326836, -0.05054136, ..., -0.00190065,\n",
       "                             0.00839357, -0.0002598 ], dtype=float32),\n",
       "                     kernel: Array([[-0.08468234, -0.07085327,  0.05818424, ..., -0.02513969,\n",
       "                             -0.00493855,  0.01296574],\n",
       "                            [-0.06062659, -0.01021664, -0.04146817, ..., -0.04629397,\n",
       "                              0.01375891,  0.00255859],\n",
       "                            [-0.00559876,  0.08422388,  0.00671157, ..., -0.01464027,\n",
       "                             -0.02780931, -0.04303579],\n",
       "                            ...,\n",
       "                            [-0.08461291, -0.02157283,  0.04177459, ..., -0.04394135,\n",
       "                              0.02366032,  0.00074148],\n",
       "                            [-0.08057892, -0.10108374,  0.05241186, ...,  0.00555836,\n",
       "                             -0.04079631,  0.00025009],\n",
       "                            [-0.02886738,  0.06783401,  0.01306549, ..., -0.03133645,\n",
       "                             -0.03155024, -0.02779569]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([-0.03133995, -0.04081205, -0.08265745, ..., -0.01254424,\n",
       "                            -0.05853035, -0.00197752], dtype=float32),\n",
       "                     kernel: Array([[-0.00636956, -0.02878766,  0.01909958, ..., -0.0224709 ,\n",
       "                             -0.01617917, -0.033026  ],\n",
       "                            [ 0.04314052,  0.02377085,  0.03454667, ...,  0.03794894,\n",
       "                              0.01205498, -0.07643931],\n",
       "                            [ 0.05534453, -0.09516454,  0.03321391, ..., -0.01151838,\n",
       "                             -0.01930913,  0.02549305],\n",
       "                            ...,\n",
       "                            [-0.01179547, -0.00528355,  0.05211147, ...,  0.03236581,\n",
       "                              0.04144614,  0.03548167],\n",
       "                            [-0.01238077, -0.02445081, -0.00891595, ...,  0.00681227,\n",
       "                              0.05465172,  0.05985662],\n",
       "                            [ 0.02058069,  0.0183666 ,  0.07114077, ..., -0.00294836,\n",
       "                             -0.00679923, -0.00441737]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "             ln_1: {\n",
       "                 bias: Array([-0.03483892, -0.00329283,  0.03022123, ..., -0.08873575,\n",
       "                        -0.0410151 , -0.01324603], dtype=float32),\n",
       "                 scale: Array([0.4841917 , 0.53279054, 0.5321487 , ..., 0.48091662, 0.52553624,\n",
       "                        0.49217203], dtype=float32),\n",
       "             },\n",
       "             ln_2: {\n",
       "                 bias: Array([-0.03417087, -0.05503681,  0.03418307, ...,  0.05463273,\n",
       "                        -0.02120833,  0.00310488], dtype=float32),\n",
       "                 scale: Array([0.563637  , 0.64318347, 0.6074251 , ..., 0.58007365, 0.5830381 ,\n",
       "                        0.56370324], dtype=float32),\n",
       "             },\n",
       "             mlp: {\n",
       "                 c_fc: {\n",
       "                     bias: Array([-0.03531602, -0.02679597, -0.07158306, ..., -0.0265601 ,\n",
       "                            -0.04462031, -0.02720697], dtype=float32),\n",
       "                     kernel: Array([[ 0.02174225, -0.02829929,  0.02151309, ..., -0.04954825,\n",
       "                             -0.08082572,  0.03612174],\n",
       "                            [ 0.0544328 , -0.05930048,  0.07934989, ..., -0.00999511,\n",
       "                              0.1034288 ,  0.02538439],\n",
       "                            [-0.06848788, -0.04551249, -0.09622971, ...,  0.09033757,\n",
       "                             -0.0129648 ,  0.00753873],\n",
       "                            ...,\n",
       "                            [ 0.00517934, -0.00108308,  0.08419678, ...,  0.01298593,\n",
       "                              0.0093583 ,  0.00865765],\n",
       "                            [-0.03762262, -0.02359089, -0.01426265, ..., -0.05687205,\n",
       "                             -0.14162266,  0.04682595],\n",
       "                            [ 0.04673976,  0.04596692, -0.04365601, ...,  0.04812708,\n",
       "                             -0.01986469, -0.12010836]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([ 0.01023365, -0.016442  , -0.03909723, ...,  0.01781337,\n",
       "                             0.03773139, -0.00825455], dtype=float32),\n",
       "                     kernel: Array([[-0.01774104,  0.00843976,  0.04822189, ..., -0.05071041,\n",
       "                             -0.01933133,  0.01463472],\n",
       "                            [-0.02841729, -0.03823257,  0.00405333, ..., -0.01454593,\n",
       "                              0.02640232,  0.07927064],\n",
       "                            [ 0.03816459, -0.0136351 , -0.01247866, ..., -0.05286407,\n",
       "                              0.0508052 , -0.01091394],\n",
       "                            ...,\n",
       "                            [-0.00723636, -0.0050352 ,  0.03806635, ...,  0.03073597,\n",
       "                             -0.00794225, -0.04792085],\n",
       "                            [-0.01885991, -0.04323349, -0.02646614, ...,  0.05545561,\n",
       "                             -0.03365228, -0.04363329],\n",
       "                            [ 0.04115453, -0.02959258, -0.0072873 , ..., -0.02231471,\n",
       "                             -0.00903808, -0.01450868]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "         },\n",
       "         9: {\n",
       "             attn: {\n",
       "                 c_attn: {\n",
       "                     bias: Array([-0.04277876, -0.06818724, -0.09869727, ..., -0.00135973,\n",
       "                            -0.0048161 , -0.01077853], dtype=float32),\n",
       "                     kernel: Array([[ 0.02516848, -0.06959037, -0.17734927, ..., -0.01501723,\n",
       "                             -0.05363854,  0.0396672 ],\n",
       "                            [-0.06245829,  0.00204335,  0.00409712, ...,  0.04122163,\n",
       "                             -0.04370447, -0.04631596],\n",
       "                            [-0.07086102,  0.01809686, -0.07457864, ..., -0.02424765,\n",
       "                              0.03228455, -0.02993347],\n",
       "                            ...,\n",
       "                            [ 0.0646265 , -0.0908712 , -0.00183535, ..., -0.00237504,\n",
       "                             -0.0122423 , -0.01434586],\n",
       "                            [ 0.00371932, -0.00667866, -0.05289409, ..., -0.06781968,\n",
       "                              0.01917772, -0.01072659],\n",
       "                            [ 0.04758763, -0.01296958, -0.02192018, ...,  0.00376835,\n",
       "                             -0.02524021, -0.03555339]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([ 0.01920359, -0.02317817, -0.07730135, ...,  0.01123958,\n",
       "                            -0.04868112, -0.01842665], dtype=float32),\n",
       "                     kernel: Array([[ 0.05541898,  0.07908107, -0.02474583, ..., -0.04240261,\n",
       "                              0.07147417, -0.03817447],\n",
       "                            [ 0.02891323, -0.08763725,  0.03703124, ...,  0.06440807,\n",
       "                             -0.01185452, -0.03951773],\n",
       "                            [-0.0599082 ,  0.00221367, -0.05397188, ..., -0.08323388,\n",
       "                              0.01006231,  0.05283359],\n",
       "                            ...,\n",
       "                            [-0.01246343, -0.05082306,  0.09341454, ..., -0.04815929,\n",
       "                              0.12355918, -0.05662627],\n",
       "                            [-0.01462707,  0.04733894,  0.01958623, ..., -0.00254575,\n",
       "                              0.02825813,  0.03331137],\n",
       "                            [-0.03751362,  0.03646212,  0.00142817, ...,  0.01439473,\n",
       "                             -0.02896075,  0.03677345]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "             ln_1: {\n",
       "                 bias: Array([-0.04936757,  0.00616127,  0.01160615, ..., -0.07772851,\n",
       "                        -0.05312387, -0.0207131 ], dtype=float32),\n",
       "                 scale: Array([0.50076646, 0.5488624 , 0.5550506 , ..., 0.49127194, 0.5516152 ,\n",
       "                        0.5188756 ], dtype=float32),\n",
       "             },\n",
       "             ln_2: {\n",
       "                 bias: Array([-0.03236543, -0.04413556,  0.01114574, ...,  0.04701756,\n",
       "                        -0.02319888,  0.01793663], dtype=float32),\n",
       "                 scale: Array([0.56993455, 0.63676834, 0.61884815, ..., 0.59393996, 0.5913593 ,\n",
       "                        0.5683644 ], dtype=float32),\n",
       "             },\n",
       "             mlp: {\n",
       "                 c_fc: {\n",
       "                     bias: Array([ 0.03351539, -0.05149357, -0.05349788, ..., -0.02977525,\n",
       "                            -0.05779917, -0.03245061], dtype=float32),\n",
       "                     kernel: Array([[-1.5635893e-02, -4.6759644e-03, -1.5298983e-02, ...,\n",
       "                              3.4473225e-02,  2.7057849e-02, -2.3169245e-05],\n",
       "                            [ 5.6944992e-02, -1.2288002e-03,  7.1575627e-02, ...,\n",
       "                             -1.7195927e-02,  2.3470996e-02,  1.6559944e-02],\n",
       "                            [ 5.8706474e-02,  1.5319863e-02, -4.2173818e-02, ...,\n",
       "                              1.3464266e-02,  1.1177760e-02, -9.8895701e-03],\n",
       "                            ...,\n",
       "                            [ 4.0517431e-02,  1.4150462e-01, -5.6961760e-02, ...,\n",
       "                              1.5056266e-02,  3.7555955e-02, -2.0519335e-02],\n",
       "                            [-2.7001632e-02,  4.7750022e-02, -1.3083477e-02, ...,\n",
       "                              8.0434196e-02,  4.1775849e-02, -1.6830092e-02],\n",
       "                            [-1.4061823e-02,  1.4456229e-02,  1.3458365e-01, ...,\n",
       "                             -7.3919713e-02,  4.8055548e-02,  9.0943212e-03]], dtype=float32),\n",
       "                 },\n",
       "                 c_proj: {\n",
       "                     bias: Array([-0.00758245,  0.00614548, -0.04472281, ...,  0.00680034,\n",
       "                             0.04879486,  0.01374959], dtype=float32),\n",
       "                     kernel: Array([[ 0.01231434, -0.04490128, -0.01530279, ..., -0.04247779,\n",
       "                             -0.02339749, -0.00540675],\n",
       "                            [ 0.06834887,  0.06019654,  0.0381416 , ...,  0.01033414,\n",
       "                              0.04572955, -0.01533173],\n",
       "                            [-0.02837222, -0.04734134,  0.02612038, ...,  0.05903548,\n",
       "                             -0.08085645,  0.03761077],\n",
       "                            ...,\n",
       "                            [-0.04401831, -0.06048104, -0.0403959 , ..., -0.03182922,\n",
       "                             -0.06443729, -0.03919089],\n",
       "                            [ 0.05859979, -0.00790275,  0.06030363, ..., -0.01472107,\n",
       "                             -0.01064102, -0.02403709],\n",
       "                            [-0.04117184, -0.03076264, -0.01164124, ..., -0.00695894,\n",
       "                              0.02612539, -0.04728494]], dtype=float32),\n",
       "                 },\n",
       "             },\n",
       "         },\n",
       "         ln_f: {\n",
       "             bias: Array([-0.0177378 ,  0.03218177, -0.04121364, ...,  0.04586753,\n",
       "                     0.0147974 , -0.07349386], dtype=float32),\n",
       "             scale: Array([1.1928456, 1.1837783, 1.3633441, ..., 1.1690326, 1.1669235,\n",
       "                    1.3815583], dtype=float32),\n",
       "         },\n",
       "         wpe: {\n",
       "             embedding: Array([[ 0.00907944,  0.00058785,  0.00159346, ..., -0.03401913,\n",
       "                     -0.0053568 , -0.00563951],\n",
       "                    [-0.00454083,  0.00297051, -0.0066255 , ...,  0.00451538,\n",
       "                      0.01274661, -0.00312695],\n",
       "                    [-0.00079973,  0.00312586, -0.00186703, ...,  0.00581723,\n",
       "                     -0.00158472,  0.00317201],\n",
       "                    ...,\n",
       "                    [-0.00557327, -0.0007401 , -0.01307584, ...,  0.00109094,\n",
       "                      0.00076556,  0.00606313],\n",
       "                    [ 0.00200112, -0.00040912, -0.00385755, ..., -0.00655925,\n",
       "                     -0.00587326,  0.00012956],\n",
       "                    [ 0.00306661,  0.00109863, -0.00449043, ..., -0.00205312,\n",
       "                     -0.00599036, -0.00189639]], dtype=float32),\n",
       "         },\n",
       "         wte: {\n",
       "             embedding: Array([[-0.01491644, -0.02086054,  0.0021202 , ...,  0.03362218,\n",
       "                     -0.00054191, -0.00898338],\n",
       "                    [ 0.00546552, -0.04377642,  0.00134842, ...,  0.06712282,\n",
       "                      0.03294637, -0.03985127],\n",
       "                    [ 0.0585402 ,  0.06026442,  0.03023641, ..., -0.10414282,\n",
       "                     -0.05661995, -0.03297632],\n",
       "                    ...,\n",
       "                    [-0.01075445, -0.09077371,  0.06236218, ..., -0.03369946,\n",
       "                      0.0776626 ,  0.02926068],\n",
       "                    [ 0.01951103, -0.03178071,  0.01820766, ...,  0.01913727,\n",
       "                     -0.04542878, -0.01392519],\n",
       "                    [-0.04187777,  0.08481726, -0.05120016, ..., -0.0083037 ,\n",
       "                     -0.04468034, -0.02740996]], dtype=float32),\n",
       "         },\n",
       "     },\n",
       " })}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'transformer': train_state.params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
